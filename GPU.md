# [è§£æžæŽ¢ç´¢å¤§åž‹èªžè¨€æ¨¡åž‹ï¼šæ¨¡åž‹ç™¼å±•æ­·å²ã€è¨“ç·´åŠå¾®èª¿æŠ€è¡“çš„ VRAM ä¼°ç®—](https://deep-learning-101.github.io/)

**ä½œè€…**ï¼š[TonTon Huang Ph.D.](https://www.twman.org/)   
**æ—¥æœŸ**ï¼š2023å¹´4æœˆ12æ—¥  
**åŽŸæ–‡ç¶²å€**ï¼š[https://blog.twman.org/2023/04/GPT.html](https://blog.twman.org/2023/04/GPT.html)

---

## æ–‡ç« æ¦‚è¿°

æœ¬æ–‡æ·±å…¥æŽ¢è¨Žå¤§åž‹èªžè¨€æ¨¡åž‹ï¼ˆLLMï¼‰çš„ç™¼å±•æ­·å²ã€è¨“ç·´èˆ‡å¾®èª¿æŠ€è¡“ï¼Œä¸¦è©³ç´°è§£æžåœ¨ä¸åŒç²¾åº¦èˆ‡è¨“ç·´ç­–ç•¥ä¸‹ï¼Œæ‰€éœ€çš„ GPU VRAM ä¼°ç®—æ–¹æ³•ï¼Œç‚ºå¾žæ¥­è€…æä¾›å¯¦ä½œåƒè€ƒã€‚

---

## ä¸»è¦å…§å®¹æ‘˜è¦

### 1. æ¨¡åž‹åƒæ•¸èˆ‡ VRAM ä¼°ç®—åŸºç¤Ž

- **åƒæ•¸æ•¸é‡èˆ‡è¨˜æ†¶é«”éœ€æ±‚**ï¼š
  - 1Bï¼ˆ10å„„ï¼‰åƒæ•¸ç´„éœ€ 4GB VRAMï¼ˆFP32 ç²¾åº¦ï¼‰ã€‚
  - ç²¾åº¦é™ä½Žï¼ˆå¦‚ FP16ï¼‰å‰‡è¨˜æ†¶é«”éœ€æ±‚æ¸›åŠã€‚
- **å¸¸è¦‹ç²¾åº¦æ ¼å¼**ï¼š
  - FP32ï¼ˆå–®ç²¾åº¦ï¼‰ï¼šæ¯åƒæ•¸ä½” 4 bytesã€‚
  - FP16/BF16ï¼ˆåŠç²¾åº¦ï¼‰ï¼šæ¯åƒæ•¸ä½” 2 bytesã€‚
  - INT8ï¼ˆ8ä½æ•´æ•¸ï¼‰ï¼šæ¯åƒæ•¸ä½” 1 byteï¼Œå¸¸ç”¨æ–¼æŽ¨ç†éšŽæ®µã€‚

### 2. è¨“ç·´èˆ‡å¾®èª¿çš„ VRAM éœ€æ±‚ä¼°ç®—

#### å…¨åƒæ•¸è¨“ç·´ï¼ˆFull Parameter Trainingï¼‰

- **FP32 ç²¾åº¦**ï¼š
  - æ¨¡åž‹æ¬Šé‡ï¼š4X GB
  - æ¢¯åº¦ï¼š4X GB
  - å„ªåŒ–å™¨ç‹€æ…‹ï¼ˆå¦‚ AdamWï¼‰ï¼š8X GB
  - **ç¸½è¨ˆ**ï¼š16X GB + å•Ÿå‹•å€¼èˆ‡å…¶ä»–é–‹éŠ·
- **FP16/BF16 ç²¾åº¦**ï¼š
  - æ¨¡åž‹æ¬Šé‡ï¼š2X GB
  - æ¢¯åº¦ï¼š2X GB
  - å„ªåŒ–å™¨ç‹€æ…‹ï¼š8X GB
  - **ç¸½è¨ˆ**ï¼š12X GB + å•Ÿå‹•å€¼èˆ‡å…¶ä»–é–‹éŠ·

#### å…¨åƒæ•¸å¾®èª¿ï¼ˆFull Fine-tuningï¼‰

- èˆ‡å…¨åƒæ•¸è¨“ç·´ç›¸ä¼¼ï¼Œä½†é€šå¸¸ batch size è¼ƒå°ï¼Œå•Ÿå‹•å€¼éœ€æ±‚è¼ƒä½Žã€‚
- **ä¼°ç®—**ï¼š
  - 7B æ¨¡åž‹ï¼šç´„ 100â€“140 GB VRAM
  - 70B æ¨¡åž‹ï¼šè¶…éŽ 1 TB VRAM

#### LoRA å¾®èª¿ï¼ˆLow-Rank Adaptationï¼‰

- åƒ…è¨“ç·´å°‘é‡é©é…å™¨åƒæ•¸ï¼Œå‡çµåŽŸå§‹æ¨¡åž‹å¤§éƒ¨åˆ†åƒæ•¸ã€‚
- **ä¼°ç®—**ï¼š
  - 7B æ¨¡åž‹ï¼šç´„ 16â€“24 GB VRAM
  - 70B æ¨¡åž‹ï¼šç´„ 140â€“200 GB VRAM

---

## å¯¦ä½œç¶“é©—åˆ†äº«

ä½œè€…åˆ†äº«äº†å°‡ Deep Learning Book çš„ PDF é€²è¡Œé‡é»žæ‘˜è¦ï¼Œä¸¦å°å½±ç‰‡é€²è¡ŒèªžéŸ³è¾¨è­˜èˆ‡é€å­—ç¨¿ç”Ÿæˆçš„ç¶“é©—ï¼Œå±•ç¤ºäº†å¤§åž‹èªžè¨€æ¨¡åž‹åœ¨å¯¦éš›æ‡‰ç”¨ä¸­çš„æ½›åŠ›èˆ‡æŒ‘æˆ°ã€‚

---

## çµèªž

å¤§åž‹èªžè¨€æ¨¡åž‹çš„è¨“ç·´èˆ‡å¾®èª¿å°ç¡¬é«”è³‡æºæœ‰è‘—æ¥µé«˜çš„éœ€æ±‚ï¼Œé€éŽåˆç†çš„ç²¾åº¦é¸æ“‡èˆ‡è¨“ç·´ç­–ç•¥ï¼Œå¯ä»¥æœ‰æ•ˆé™ä½Ž VRAM çš„ä½¿ç”¨ï¼Œæå‡è¨“ç·´æ•ˆçŽ‡ã€‚æœ¬æ–‡æä¾›çš„ä¼°ç®—æ–¹æ³•èˆ‡å¯¦ä½œç¶“é©—ï¼Œå°æ–¼å¾žäº‹ LLM é–‹ç™¼èˆ‡æ‡‰ç”¨çš„å¾žæ¥­è€…å…·æœ‰é‡è¦åƒè€ƒåƒ¹å€¼ã€‚

---

> ðŸ“– å¦‚éœ€é€²ä¸€æ­¥äº†è§£ï¼Œè«‹åƒé–±åŽŸæ–‡ï¼š  
> [https://blog.twman.org/2023/04/GPT.html](https://blog.twman.org/2023/04/GPT.html)
