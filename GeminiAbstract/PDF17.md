---
layout: default
title: Deep Learning 101, 台灣曾經最高最早發起的深度學習社群 @ 83F, 台北101
---

<p align="center">
  <strong>Deep Learning 101, The top private AI Meetup in Taiwan, launched on 2016/11/11 @ 83F, Taipei 101</strong>  
</p>
<p align="center">
  <strong>Deep Learning 101, 台灣曾經最高最早發起的深度學習社群 @ 83F, 台北101</strong><br><br>
  AI是條寂寞且惶恐的道路，花俏的收費課程或活動絕不會是條捷徑<br>
  本頁內容為過往實名分享制的讀書會，感謝來自不同公司參與者的支持；如欲移除資訊還請告知。<br>
  Deep Learning 101 只由 TonTon Huang Ph.D. 及其當時任職公司無償贊助場地及茶水點心，無 Co-organizer<br>
</p>  
<p align="center">
  <a href="https://huggingface.co/spaces/DeepLearning101/Deep-Learning-101-FAQ" target="_blank">
    <img src="https://github.com/Deep-Learning-101/.github/blob/main/images/DeepLearning101.JPG?raw=true" alt="Deep Learning 101" width="400">
  </a>
</p>
<p align="center">
  <a href="https://www.youtube.com/@DeepLearning101" target="_blank">YouTube</a> |
  <a href="https://www.facebook.com/groups/525579498272187/" target="_blank">台灣人工智慧社團 FB</a> |
  <a href="https://www.twman.org/" target="_blank">TonTon Huang Ph.D.</a> |
  <a href="http://DeepLearning101.TWMAN.ORG" target="_blank">台灣人工智慧社團 網站</a> |
  <a href="https://huggingface.co/DeepLearning101" target="_blank">Hugging Face</a>
</p>
<p align="center">
<a href="https://www.buymeacoffee.com/DeepLearning101" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-red.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;" ></a>
</p>

# 第十七章 蒙特卡羅方法  - [YouTube](https://www.youtube.com/watch?v=qef-XTUpDvE) - <a href="https://deep-learning-101.github.io/">回上一頁 GitHub Pages</a>

### Monte Carlo Methods (2017/12/15)


**重點摘要:**
隨機算法可以粗略地分為兩類：Las Vegas 算法和蒙特卡羅算法。Las Vegas 算法總是精確地返回一個正確答案（或者返回算法失敗了），但計算資源（一般指內存或運行時間）會有波動。蒙特卡羅算法則相反，它返回的答案具有隨機大小的錯誤，但花費更多的計算資源可以減少這種錯誤。在任意固定的計算資源下，蒙特卡羅算法可以得到一個近似解。對於機器學習中的許多問題來說，精確答案很難得到，確定性算法或 Las Vegas 算法難以解決。因此，確定性的近似算法或蒙特卡羅近似方法成為常用選擇。本章主要關注蒙特卡羅方法。


**Q:** Las Vegas 算法和蒙特卡羅算法的主要區別是什麼？

**A:**
*   **Las Vegas 算法:** 總是返回精確的正確答案，或者報告失敗。其計算資源（如運行時間）是不確定的。
*   **蒙特卡羅算法:** 在固定的計算資源下返回一個近似答案，這個答案帶有隨機大小的錯誤。花費更多的計算資源通常可以減少這個錯誤。

**Q:** 在機器學習中，為什麼蒙特卡羅方法和近似算法如此重要？

**A:** 因為機器學習中的許多問題很難得到精確的答案，或者精確算法（如確定性算法或 Las Vegas 算法）的計算代價過高。在這種情況下，能夠提供近似解的蒙特卡羅方法或確定性近似算法就成為了實用且必要的選擇。

**Q:** 本章主要關注哪一類隨機算法？

**A:** 本章主要關注蒙特卡羅方法。

---

## 17.1 採樣和蒙特卡羅方法

**重點摘要:**
機器學習中的許多重要工具都基於從某種分佈中採樣以及用這些樣本對目標量做一個蒙特卡羅估計。

---

### 17.1.1 為什麼需要採樣？

**重點摘要:**
我們希望從某個分佈中採樣的原因有很多。當我們需要以較小的代價近似許多項的和或某個積分時，採樣是一種很靈活的選擇。例如，用小批量數據對整個訓練集代價進行採樣估計，或者在模型中，需要近似一個難以處理的和或積分（如配分函數對數的梯度）。最根本的情況是，採樣實際上是我們的目標，例如我們想訓練一個可以從訓練分佈採樣的模型。


**Q:** 在機器學習中，我們為什麼需要從機率分佈中進行採樣？請列舉一些原因。

**A:** 我們需要採樣的原因包括：
1.  **近似計算:** 當需要計算一個包含許多項的和或者一個難以解析計算的積分時，可以通過從相關分佈中採樣，然後對樣本進行平均（或加權平均）來近似這個和或積分。例如，用小批量數據估計整個訓練集的損失函數梯度。
2.  **處理難解模型:** 在某些機率模型中，一些關鍵量（如配分函數或其梯度）的精確計算涉及到難以處理的和或積分。採樣提供了一種近似這些量的方法。
3.  **生成模型:** 採樣本身就是生成模型的目標之一，即我們希望訓練一個模型，使其能夠生成符合特定數據分佈的新樣本。

---

### 17.1.2 蒙特卡羅採樣的基礎

**重點摘要:**
當無法精確計算和或積分 `s = Σ_x p(x)f(x) = E_p[f(x)]` (公式 17.1) 或 `s = ∫ p(x)f(x)dx = E_p[f(x)]` (公式 17.2) 時，可以使用蒙特卡羅採樣來近似它。通過從分佈 `p` 中抽取 `n` 個獨立同分佈 (i.i.d.) 的樣本 `x^(1), ..., x^(n)`，可以得到一個經驗平均值 `ŝ_n = (1/n) Σ_{i=1}^n f(x^(i))` (公式 17.3)。這個估計 `ŝ_n` 是無偏的，即 `E[ŝ_n] = s` (公式 17.4)。根據大數定律，只要樣本 `x^(i)` 是獨立同分佈的，`ŝ_n` 會依機率收斂到期望值 `s` (公式 17.5)。如果 `Var[f(x^(i))]` 有限，則 `Var[ŝ_n] = Var[f(x)]/n` (公式 17.7)，這意味著隨著樣本數量 `n` 的增加，估計的方差會減小。中心極限定理進一步說明 `ŝ_n` 的分佈會收斂到一個以 `s` 為均值，`Var[f(x)]/n` 為方差的正態分佈，這使我們可以用正態分佈的累積分佈函數來估計 `ŝ_n` 的置信區間。


**Q:** 什麼是蒙特卡羅估計的基本思想？如何用它來近似一個期望值？

**A:** 蒙特卡羅估計的基本思想是，當我們想要計算一個函數 `f(x)` 在某個機率分佈 `p(x)` 下的期望值 `E_p[f(x)]` 時，如果直接計算困難，可以通過從分佈 `p(x)` 中抽取大量獨立同分佈的樣本 `x^(1), ..., x^(n)`，然後計算這些樣本上 `f(x)` 值的經驗平均值 `ŝ_n = (1/n) Σ_{i=1}^n f(x^(i))`。這個經驗平均值 `ŝ_n` 就是對真實期望值 `E_p[f(x)]` 的蒙特卡羅估計。

**Q:** 蒙特卡羅估計量 `ŝ_n` 有哪些重要的統計性質？

**A:**
1.  **無偏性 (Unbiasedness):** `E[ŝ_n] = E_p[f(x)]`，即 `ŝ_n` 的期望等於真實的期望值。
2.  **一致性 (Consistency):** 根據大數定律，當樣本數量 `n` 趨向無窮大時，`ŝ_n` 會依機率收斂到真實的期望值 `E_p[f(x)]`。
3.  **方差 (Variance):** 如果 `Var[f(x)]` 有限，則 `Var[ŝ_n] = Var[f(x)]/n`。這意味著估計的精度（以方差的倒數衡量）隨著樣本數量的增加而線性增加。
4.  **漸近正態性 (Asymptotic Normality):** 根據中心極限定理，當樣本數量 `n` 足夠大時，`ŝ_n` 的分佈近似於一個正態分佈，其均值為 `E_p[f(x)]`，方差為 `Var[f(x)]/n`。

**Q:** 增加蒙特卡羅採樣的樣本數量 `n` 對估計的準確性和精度有何影響？

**A:** 增加樣本數量 `n`：
*   **提高精度:** 估計量 `ŝ_n` 的方差會以 `1/n` 的速率減小，即估計結果會更接近真實期望值。
*   **不改變無偏性:** `ŝ_n` 始終是無偏的，無論 `n` 多大。
*   **使分佈更接近正態分佈:** `ŝ_n` 的抽樣分佈會更接近正態分佈，使得基於正態分佈的置信區間估計更準確。

---

## 17.2 重要性採樣

**重點摘要:**
當我們難以或不希望從目標分佈 `p(x)` 中直接採樣來估計 `E_p[f(x)]` 時，可以使用重要性採樣。其思想是從一個不同的、易於採樣的提議分佈 `q(x)` 中採樣，然後對樣本進行加權以修正由於從錯誤分佈採樣引入的偏差。具體來說，`E_p[f(x)] = E_q[ (p(x)/q(x)) f(x) ]` (公式 17.8)。因此，我們可以從 `q` 中採樣 `x^(i)`，並計算加權平均 `ŝ_q = (1/n) Σ_{i=1}^n (p(x^(i))/q(x^(i))) f(x^(i))` (公式 17.10) 作為 `E_p[f(x)]` 的估計。這個估計仍然是無偏的 (公式 17.11)。
重要性採樣的方差對提議分佈 `q` 的選擇非常敏感。最優的提議分佈（使方差最小，理想情況下為零）是 `q*(x) = p(x)|f(x)|/Z` (公式 17.13)，其中 `Z` 是歸一化常數。然而，計算 `Z` 通常和原始問題一樣困難。因此，選擇一個好的 `q` 通常需要在易於採樣和接近 `p(x)|f(x)|` 之間進行權衡。
有偏重要性採樣 (Biased Importance Sampling) (公式 17.14-17.16) 使用歸一化的重要性權重，即 `w_i = p(x^(i))/q(x^(i))`，然後估計為 `ŝ_BIS = (Σ w_i f(x^(i))) / (Σ w_i)`。這個估計是有偏的（對於有限 `n`），但通常具有比無偏重要性採樣更低的方差，並且在 `n` 趨於無窮大時是一致的。


**Q:** 什麼是重要性採樣？它試圖解決什麼問題？

**A:** 重要性採樣是一種蒙特卡羅方法，用於估計一個函數 `f(x)` 在目標機率分佈 `p(x)` 下的期望值 `E_p[f(x)]`，特別是當我們難以或不希望直接從 `p(x)` 中採樣時。它通過從一個不同的、更容易採樣的提議分佈 `q(x)` 中抽取樣本，然後對這些樣本應用「重要性權重」來修正由於從錯誤分佈採樣引入的偏差。

**Q:** 在重要性採樣中，重要性權重是如何定義的？為什麼需要它們？

**A:** 對於從提議分佈 `q(x)` 中抽取的樣本 `x`，其重要性權重定義為 `w(x) = p(x)/q(x)`。
    需要它們是因為我們是從 `q(x)` 而不是目標分佈 `p(x)` 中採樣。為了得到對 `E_p[f(x)]` 的無偏估計，我們需要將每個樣本 `f(x^(i))` 乘以其對應的重要性權重 `w(x^(i))`，然後再取平均。這樣做的效果是，那些在 `p(x)` 中機率較高但在 `q(x)` 中機率較低的樣本會被賦予較高的權重，反之亦然，從而修正了由於從不同分佈採樣帶來的影響。

**Q:** 提議分佈 `q(x)` 的選擇對重要性採樣的性能有何影響？理想的提議分佈是什麼樣的？

**A:** 提議分佈 `q(x)` 的選擇對重要性採樣估計的方差有著至關重要的影響。
*   如果 `q(x)` 與 `p(x)|f(x)|` 的形狀差異很大，特別是如果 `q(x)` 在 `p(x)|f(x)|` 很大的區域很小，那麼重要性權重 `p(x)/q(x)` 的方差會非常大，導致蒙特卡羅估計的方差也很大，甚至可能是無限的，使得估計非常不可靠。
*   理想的提議分佈（使方差最小，理想情況下為零）是 `q*(x) = p(x)|f(x)|/Z`，其中 `Z = ∫ p(x)|f(x)|dx`。這個分佈的形狀與被積函數 `p(x)|f(x)|` 成正比。然而，計算 `Z` 通常和原始積分問題一樣困難，所以這只是一個理論上的最優選擇。
在實踐中，我們通常尋找一個易於採樣且其形狀盡可能接近 `p(x)|f(x)|` 的 `q(x)`。

**Q:** 什麼是有偏重要性採樣？它與無偏重要性採樣有何不同？它有哪些優缺點？

**A:** 有偏重要性採樣（也稱為自歸一化重要性採樣）的估計形式為 `ŝ_BIS = (Σ_{i=1}^n w_i f(x^(i))) / (Σ_{i=1}^n w_i)`，其中 `w_i = p(x^(i))/q(x^(i))` 是未歸一化的重要性權重（即我們可能只知道 `p(x)` 和 `q(x)` 的未歸一化形式 `p̃(x)` 和 `q̃(x)`，此時 `w_i = p̃(x^(i))/q̃(x^(i))`）。
*   **與無偏重要性採樣的不同:** 無偏重要性採樣的估計是 `(1/n) Σ w_i f(x^(i))`，它要求我們能夠精確計算權重 `p(x)/q(x)`（或者說，`p` 和 `q` 的歸一化常數已知）。有偏重要性採樣則不需要知道 `p` 和 `q` 的歸一化常數，因為它們在分子分母中被消掉了（如果使用未歸一化形式）。
*   **優點:** 通常具有比無偏重要性採樣更低的方差。當我們只能訪問 `p` 和 `q` 的未歸一化形式時，它是一個實用的選擇。
*   **缺點:** 對於有限的樣本數量 `n`，它是一個有偏估計（即 `E[ŝ_BIS] ≠ E_p[f(x)]`）。然而，它是一致的，即當 `n` 趨於無窮大時，偏差會趨於零，並且 `ŝ_BIS` 會收斂到真實的期望值。

---

## 17.3 馬爾可夫鏈蒙特卡羅方法

**重點摘要:**
在許多高維空間中，直接從複雜的目標機率分佈 `p_model(x)` 中採樣非常困難。馬爾可夫鏈蒙特卡羅 (Markov Chain Monte Carlo, MCMC) 方法通過從一個易於採樣的初始分佈 `q_0(x)` 開始，然後通過一系列隨機轉移（定義了一個馬爾可夫鏈）來逐步逼近目標分佈 `p_model(x)`。如果馬爾可夫鏈設計得當，其平穩分佈 (stationary distribution) 就是目標分佈 `p_model(x)`。
一個馬爾可夫鏈由一個初始狀態分佈 `q^(0)(x)` 和一個轉移算子 `T(x'|x)`（表示從狀態 `x` 轉移到狀態 `x'` 的機率）定義。在第 `t` 步，狀態的分佈為 `q^(t+1)(x') = Σ_x q^(t)(x)T(x'|x)` (公式 17.18)。如果馬爾可夫鏈是遍歷的 (ergodic)，那麼無論初始分佈如何，經過足夠多的轉移後，狀態的分佈 `q^(t)(x)` 都會收斂到唯一的平穩分佈 `p(x)`，滿足 `p(x') = Σ_x p(x)T(x'|x)` (公式 17.24 的矩陣形式 `v = vA`)。
實際中，我們運行馬爾可夫鏈一段時間（稱為「混合」或「burn-in」），然後從鏈的後續狀態中收集樣本，這些樣本可以被視為近似來自平穩分佈 `p_model(x)`。MCMC 的一個關鍵挑戰是混合時間 (mixing time)，即鏈達到平穩分佈所需的時間，這可能非常長。Gibbs 採樣是 MCMC 的一種常用方法。


**Q:** 什麼是馬爾可夫鏈蒙特卡羅 (MCMC) 方法？它為什麼在從複雜機率分佈中採樣時很有用？

**A:** 馬爾可夫鏈蒙特卡羅 (MCMC) 是一類算法，用於從一個目標機率分佈中生成樣本，特別是當直接從該分佈中採樣很困難時。其核心思想是構造一個馬爾可夫鏈，使其平穩分佈恰好是我們想要的目標分佈。然後，通過模擬這條馬爾可夫鏈足夠長的時間，鏈的狀態將會（近似地）從目標分佈中抽取出來。
    它之所以有用，是因為對於許多複雜的、高維的機率分佈（例如深度學習模型中的後驗分佈或能量模型），直接採樣方法（如逆變換採樣或拒絕採樣）往往不可行。MCMC 提供了一種通用的、儘管有時計算成本較高的方法來生成這些分佈的樣本。

**Q:** 一個馬爾可夫鏈由哪兩個主要部分定義？

**A:** 一個馬爾可夫鏈由以下兩個主要部分定義：
1.  **初始狀態分佈 `q^(0)(x)`:** 描述了鏈在時間 `t=0` 時處於各個狀態的機率。
2.  **轉移算子 (Transition Operator) `T(x'|x)`:** 描述了從當前狀態 `x` 轉移到下一個狀態 `x'` 的條件機率。這個算子必須滿足馬爾可夫性質，即下一個狀態只依賴於當前狀態，而與之前的歷史狀態無關。

**Q:** 什麼是馬爾可夫鏈的平穩分佈 (stationary distribution)？它與 MCMC 的目標有何關係？

**A:** 馬爾可夫鏈的平穩分佈 `p(x)` 是指這樣一個機率分佈：如果鏈的當前狀態是從 `p(x)` 中抽取的，那麼經過一次轉移後，下一個狀態的分佈仍然是 `p(x)`。數學上，它滿足 `p(x') = Σ_x p(x)T(x'|x)`。
    MCMC 的目標就是設計一個轉移算子 `T(x'|x)`，使得其唯一的平穩分佈恰好是我們想要從中採樣的目標機率分佈 `p_model(x)`。

**Q:** 在 MCMC 中，「混合 (mixing)」或「burn-in」指的是什麼？為什麼它很重要？

**A:**
*   **混合 (Mixing):** 指的是馬爾可夫鏈從其初始狀態分佈收斂到其平穩分佈的過程和速度。一個混合良好的鏈會較快地「忘記」其初始狀態，並迅速達到平穩分佈。
*   **Burn-in:** 在 MCMC 模擬的初始階段，鏈的狀態分佈通常還沒有達到平穩分佈。因此，我們會丟棄鏈開始時的一段樣本（稱為 burn-in 樣本），只保留之後的樣本，因為這些後續樣本更有可能近似來自平穩分佈。
    混合和 burn-in 之所以重要，是因為 MCMC 算法的正確性依賴於鏈已經達到其平穩分佈。如果混合時間過長，或者 burn-in 期間丟棄的樣本不足，那麼收集到的樣本可能並不能很好地代表目標分佈，從而導致基於這些樣本的估計產生偏差。

---

## 17.4 Gibbs 採樣

**重點摘要:**
Gibbs 採樣是一種簡單且廣泛適用的 MCMC 算法，特別適用於多變量分佈。假設我們想從聯合分佈 `p(x_1, ..., x_n)` 中採樣。Gibbs 採樣通過迭代地從每個變數 `x_i` 的條件分佈 `p(x_i | x_{-i})`（給定所有其他變數 `x_{-i}`）中進行採樣。也就是說，在每次迭代中，依次對每個變數 `x_i` 進行更新，從 `p(x_i | x_1^(t), ..., x_{i-1}^(t), x_{i+1}^(t-1), ..., x_n^(t-1))` 中採樣得到 `x_i^(t)`。如果所有這些單變數條件分佈都易於採樣，那麼 Gibbs 採樣就很容易實現。對於能量模型，這些條件分佈通常易於計算。Gibbs 採樣的一個重要特點是它不需要任何可調的超參數（如 Metropolis-Hastings 中的提議分佈參數）。塊 Gibbs 採樣 (block Gibbs sampling) 是一種類似的技術，它同時對一組（塊）變數進行採樣，條件於所有其他變數。


**Q:** 什麼是 Gibbs 採樣？它是如何工作的？

**A:** Gibbs 採樣是一種 MCMC 算法，用於從多個隨機變數的聯合機率分佈 `p(x_1, x_2, ..., x_n)` 中生成樣本。
*   **工作原理:** 它通過迭代地、輪流地對每個變數 `x_i` 進行採樣，條件於所有其他變數 `x_{-i} = (x_1, ..., x_{i-1}, x_{i+1}, ..., x_n)` 的當前值。也就是說，在一次完整的迭代中，對於 `i` 從 1 到 `n`：
    1.  固定所有其他變數 `x_j` (j ≠ i) 的當前值。
    2.  從條件機率分佈 `p(x_i | x_{-i})` 中抽取一個新的值作為 `x_i` 的更新值。
    重複這個過程，馬爾可夫鏈的狀態最終會收斂到目標聯合分佈 `p(x_1, ..., x_n)`。

**Q:** Gibbs 採樣適用於什麼樣的機率分佈？它有什麼優點？

**A:**
*   **適用性:** Gibbs 採樣特別適用於那些儘管聯合分佈可能很複雜，但每個單個變數在給定所有其他變數時的條件機率分佈（即所謂的「全條件分佈」, full conditional distributions）都易於採樣的場景。這在許多圖模型（如貝葉斯網路、馬爾可夫隨機場）和能量模型中是很常見的。
*   **優點:**
    1.  **實現簡單:** 如果全條件分佈已知且易於採樣，Gibbs 採樣的實現非常直接。
    2.  **無需調整提議分佈:** 與 Metropolis-Hastings 等算法不同，Gibbs 採樣不需要設計或調整提議分佈及其參數，因為它直接從真實的條件分佈中採樣，所以接受率總是 1。
    3.  **概念直觀:** 其迭代更新單個變數的思想比較容易理解。

**Q:** 什麼是塊 Gibbs 採樣 (block Gibbs sampling)？它與標準 Gibbs 採樣有何不同？

**A:** 塊 Gibbs 採樣是標準 Gibbs 採樣的一個推廣。在標準 Gibbs 採樣中，每次只更新一個單獨的變數。而在塊 Gibbs 採樣中，變數被分成若干「塊」(blocks)，每次迭代時，會同時對一個塊中的所有變數進行聯合採樣，條件於所有其他塊中的變數的當前值。
*   **不同之處:** 主要區別在於更新的單位。標準 Gibbs 是單變數更新，塊 Gibbs 是多變數（塊）更新。
*   **優勢:** 如果塊內的變數之間存在強相關性，而塊間的相關性較弱，那麼同時對塊內變數進行採樣可以比逐個更新單個變數更快地探索狀態空間，從而可能加速馬爾可夫鏈的混合。然而，從塊的聯合條件分佈中採樣可能比從單變數條件分佈中採樣更困難。

---

## 17.5 不同峰值之間的混合挑戰

**重點摘要:**
MCMC 方法的一個主要難點在於馬爾可夫鏈在分佈的不同峰值（高機率區域）之間混合 (mixing) 通常很慢。如果設計的轉移算子主要在當前峰值附近進行小步移動，鏈可能需要很長時間才能從一個峰值跳到另一個相距較遠的峰值。這在高維空間中尤其嚴重。能量模型中，如果能量景觀非常崎嶇（有很多局部極小值，對應機率峰值），MCMC 採樣會非常緩慢。
*   **隨機遊走行為:** 許多 MCMC 算法（如 Metropolis-Hastings 的一些變體）的行為類似於隨機遊走。鏈從一個狀態 `x^(t-1)` 轉移到 `x^(t)`，能量 `E(x^(t))` 通常略低於或接近 `E(x^(t-1))`。鏈傾向於向低能量區域移動，但很難從一個低能量區域「爬出來」並越過高能量勢壘到達另一個低能量區域。
*   **回火 (Tempering) / 並行回火 (Parallel Tempering):** 為了解決這個問題，可以引入一個「溫度」參數 `β`，將能量函數修改為 `βE(x)` (公式 17.26)。當 `β < 1`（高溫）時，能量景觀變得更平滑，鏈更容易在不同峰值之間移動。回火 MCMC (tempered MCMC) 或模擬退火 (simulated annealing) 通常在高溫下開始，然後逐漸降低溫度。並行回火則同時運行多條具有不同溫度的鏈，並允許它們之間交換狀態。
*   **潛變數引起的混合問題:** 當我們對潛變數模型 `p(x,h)`（例如 RBM）進行推斷，需要從後驗 `p(h|x)` 中採樣時，如果 `x` 的選擇使得後驗 `p(h|x)` 變得尖銳或多峰，MCMC 採樣也會很困難。例如，對於自編碼器，頂層隱藏空間 `h` 的邊緣分佈可能趨向於均勻和發散，峰值之間的間距很大，導致 Gibbs 採樣在峰值間混合緩慢。


**Q:** 在 MCMC 中，「不同峰值之間的混合挑戰」指的是什麼？為什麼這是一個問題？

**A:** 「不同峰值之間的混合挑戰」指的是馬爾可夫鏈在機率分佈中多個分離的、高機率區域（即「峰值」或「模態」）之間有效探索和轉移的困難。如果轉移算子主要導致鏈在當前峰值內部進行小步移動，而很難「跳躍」到其他峰值，那麼鏈就需要非常長的時間才能充分探索整個狀態空間並準確地從目標分佈中採樣。
    這是一個問題，因為如果混合緩慢，我們可能需要運行 MCMC 非常長的時間才能獲得代表性的樣本，或者我們收集到的樣本可能只集中在少數幾個峰值附近，導致對目標分佈的估計產生偏差，尤其是在估計那些依賴於全局分佈特性的量時。

**Q:** 為什麼基於能量的模型在能量景觀崎嶇時，MCMC 採樣會很慢？

**A:** 在基於能量的模型中，機率與 `exp(-E(x))` 成正比，低能量區域對應高機率峰值。如果能量景觀崎嶇，意味著存在許多由高能量勢壘隔開的局部能量極小點。MCMC 算法（特別是那些傾向於向低能量區域移動的算法，如 Metropolis-Hastings 的某些變體）在從一個能量極小點（對應一個機率峰值）轉移到另一個能量極小點時，需要克服中間的高能量勢壘。這個過程可能非常緩慢，因為跨越能量勢壘的提議通常具有很低的接受率。鏈容易被「困在」一個局部能量極小點中。

**Q:** 什麼是回火 (tempering) 或模擬退火 (simulated annealing)？它們如何幫助改善 MCMC 的混合？

**A:** 回火或模擬退火是一種用於改善 MCMC 混合的技術。它通過引入一個「溫度」參數 `β`（通常 `β > 0`）來修改目標能量函數，將原始能量 `E(x)` 變為 `βE(x)` (公式 17.26)。
*   當 `β < 1`（高溫）時，能量景觀變得更「平坦」，不同狀態之間的能量差異被縮小。這使得馬爾可夫鏈更容易在狀態空間中進行大步移動，並更容易跨越能量勢壘，從而在不同峰值之間探索。
*   當 `β > 1`（低溫）時，能量景觀變得更「尖銳」，鏈更傾向於停留在能量最低的區域。
    模擬退火通常從高溫開始（允許鏈快速探索全局結構），然後逐漸降低溫度（`β` 逐漸增加到 1 或更高），使得鏈最終收斂到原始目標分佈的低能量區域。

**Q:** 什麼是並行回火 (parallel tempering)？它與單鏈回火有何不同？

**A:** 並行回火（也稱為副本交換蒙特卡羅, replica exchange Monte Carlo）是一種增強採樣的 MCMC 技術。它不是像模擬退火那樣隨著時間改變單條鏈的溫度，而是同時運行多條馬爾可夫鏈，每條鏈對應一個不同的固定溫度（從高溫到目標溫度 `β=1`）。這些鏈獨立地進行 MCMC 更新。此外，算法會定期嘗試在不同溫度的鏈之間交換它們的當前狀態。交換的接受機率被設計為保持每條鏈的平穩分佈不變。
*   **不同之處:** 單鏈回火是時間序列上的溫度變化，並行回火是空間上的多溫度並行。
*   **優勢:** 高溫鏈能夠快速探索狀態空間並在不同模態之間跳躍，而低溫鏈（特別是目標溫度鏈）則能更精細地探索局部模態。通過狀態交換，高溫鏈的探索性可以傳遞給低溫鏈，幫助低溫鏈克服能量勢壘，從而改善目標溫度鏈的混合。