---
layout: default
title: Deep Learning 101, 台灣曾經最高最早發起的深度學習社群 @ 83F, 台北101
---

<p align="center">
  <strong>Deep Learning 101, The top private AI Meetup in Taiwan, launched on 2016/11/11 @ 83F, Taipei 101</strong>  
</p>
<p align="center">
  <strong>Deep Learning 101, 台灣曾經最高最早發起的深度學習社群 @ 83F, 台北101</strong><br><br>
  AI是條寂寞且惶恐的道路，花俏的收費課程或活動絕不會是條捷徑<br>
  本頁內容為過往實名分享制的讀書會，感謝來自不同公司參與者的支持；如欲移除資訊還請告知。<br>
  Deep Learning 101 只由 TonTon Huang Ph.D. 及其當時任職公司無償贊助場地及茶水點心，無 Co-organizer<br>
</p>  
<p align="center">
  <a href="https://huggingface.co/spaces/DeepLearning101/Deep-Learning-101-FAQ" target="_blank">
    <img src="https://github.com/Deep-Learning-101/.github/blob/main/images/DeepLearning101.JPG?raw=true" alt="Deep Learning 101" width="400">
  </a>
</p>
<p align="center">
  <a href="https://www.youtube.com/@DeepLearning101" target="_blank">YouTube</a> |
  <a href="https://www.facebook.com/groups/525579498272187/" target="_blank">台灣人工智慧社團 FB</a> |
  <a href="https://www.twman.org/" target="_blank">TonTon Huang Ph.D.</a> |
  <a href="http://DeepLearning101.TWMAN.ORG" target="_blank">台灣人工智慧社團 網站</a> |
  <a href="https://huggingface.co/DeepLearning101" target="_blank">Hugging Face</a>
</p>
<p align="center">
<a href="https://www.buymeacoffee.com/DeepLearning101" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-red.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;" ></a>
</p>

# 第七章 深度學習中的正則化 - [YouTube](https://www.youtube.com/watch?v=gSymqOhKW8o) - <a href="https://deep-learning-101.github.io/">回上一頁 GitHub Pages</a>

### Regularization for Deep Learning @ Deep Learning Book Chapter 7 (2017/02/10)

**重點摘要:**
機器學習中的一個核心問題是設計不僅在訓練數據上表現好，並且能 在新輸入上泛化好的算法。在機器學習中，許多策略顯式地被設計為減少測試誤差（可能會以增大訓練誤差為代價）。這些策略被統稱為**正則化 (regularization)**。我們將在后文看到，深度學習工作者可以使用許多不同形式的正則化策略。事實上，開發更有效的正則化策略已成為本領域的主要研究工作之一。
第五章介紹了泛化、欠擬合、過擬合、偏差、方差和正則化的基本概念。本章將會更詳細地介紹正則化，重點介紹深度模型（或組成深度模型的模塊）的正則化策略。
本章中的某些正則化方法也可以應用於其他機器學習模型，但大多數內容涉及這些基本概念在特定神經網路中的擴展概念。
在第 5.2.2 節中，我們將正則化定義為「對學習算法的修改——旨在減少泛化誤差而不是訓練誤差」。目前有許多正則化策略。有些策略向機器學習模型添加限制參數的額外約束。有些策略向目標函數增加參數值軟約束的額外項。如果我們仔細選擇，這些額外的約束和懲罰可以改善模型在測試集上的表現。有時候，這些約束和懲罰被設計為編碼特定類型的先驗知識；其他時候，這些約束和懲罰被設計為偏好簡單模型，以便提高泛化能力。有時，懲罰和約束對於確定欠定的問題是必要的。
在深度學習的背景下，大多數正則化策略都會對估計進行正則化。估計的正則化以偏差的增加換取方差的減少。一個有效的正則化是有利的「交易」，也就是能顯著減少方差而不過度增加偏差。


**Q:** 什麼是「正則化」在機器學習中的基本含義和目標？

**A:** 正則化是指對學習算法的一系列修改，其主要目標是**減少模型的泛化誤差（即在未見過的新數據上的誤差），而不是僅僅降低訓練誤差**。它通常通過向模型引入額外的約束或懲罰，以防止模型過度擬合訓練數據。

**Q:** 正則化策略通常通過哪兩種主要方式作用於模型？

**A:**
1.  **添加參數約束:** 對模型的參數施加額外的限制（例如，限制參數的取值範圍或范數）。
2.  **修改目標函數:** 在原始的目標函數（如經驗風險）中添加一個額外的懲罰項（正則化項），該懲罰項與模型參數的某些屬性（如大小、稀疏性）相關。

**Q:** 為什麼說一個有效的正則化是一種有利的「交易」？這個交易指的是什麼？

**A:** 一個有效的正則化通常被認為是一種在模型的**偏差 (bias)** 和**方差 (variance)** 之間的有利「交易」。
*   **偏差:** 指模型的預測值與真實值之間的系統性差異，通常源於模型的簡化假設。
*   **方差:** 指模型在不同訓練數據集上學習到的函數的變異程度，通常源於模型對訓練數據中噪聲的過度敏感。
    正則化通常會**增加模型的偏差**（因為它限制了模型的靈活性，使其可能無法完美擬合訓練數據），但其主要目的是**顯著減少模型的方差**（使其對訓練數據的微小變化不那麼敏感，從而提高泛化能力）。一個有利的交易意味著方差的減少程度遠大於偏差的增加程度，從而導致整體泛化誤差的降低。

---

## 7.1 參數范數懲罰

**重點摘要:**
正則化在深度學習的出現之前就已經被使用了數十年。線性模型，如線性回歸和邏輯回歸可以使用簡單、直接的正則化策略。許多正則化方法通過對目標函數 `J` 添加一個參數范數懲罰 `Ω(θ)`，限制模型（如神經網路、線性回歸或邏輯回歸）的學習能力。我們將正則化後的目標函數記為 `J̃`：
`J̃(θ; X, y) = J(θ; X, y) + αΩ(θ)` (公式 7.1)
其中 `α ∈ [0, ∞)` 是權衡范數懲罰項 `Ω` 和標準目標函數 `J(X; θ)` 相對貢獻的超參數。`α` 設為 0 表示沒有正則化。`α` 越大，正則化懲罰越大。
在神經網路的上下文中，有時希望對網路的每一層使用單獨的懲罰，並分配不同的 `α` 系數。參數范數懲罰通常只對權重 `w` 進行懲罰，而不對偏置 `b` 進行懲罰。

---

### 7.1.1 L² 參數正則化

**重點摘要:**
L² 參數正則化，通常也被稱為**權重衰減 (weight decay)** 或嶺回歸 (ridge regression) 或 Tikhonov 正則化，是最常見的正則化形式之一。它通過向目標函數添加一個正則項 `Ω(θ) = (1/2) ||w||_2^2` 來實現。正則化後的目標函數變為：
`J̃(w; X, y) = (α/2) w^T w + J(w; X, y)` (公式 7.2)
其梯度為：
`∇_w J̃(w; X, y) = αw + ∇_w J(w; X, y)` (公式 7.3)
使用單步梯度下降更新權重，即：
`w ← w - ϵ(αw + ∇_w J(w; X, y))`
`w ← (1 - ϵα)w - ϵ∇_w J(w; X, y)` (公式 7.5)
可以看出，加入權重衰減後，每一步梯度更新之前，權重都會先乘以一個小於 1 的因子 `(1 - ϵα)`，從而「衰減」權重。
L² 正則化會使得學習算法感知到具有較高方差的輸入 `x`，因此與輸出目標的協方差較小（相對增加權重的大小）的特征的權重將會收縮。


**Q:** 什麼是 L² 參數正則化（權重衰減）？它的正則化項是什麼形式？

**A:** L² 參數正則化是一種通過向模型的損失函數中添加一個與模型權重平方和成正比的懲罰項來進行正則化的方法。
    其正則化項 `Ω(w)` 通常定義為權重向量 `w` 的 L² 范數的平方的一半：
    `Ω(w) = (1/2) ||w||_2^2 = (1/2) Σ_i w_i^2`
    正則化後的總損失函數 `J̃(w)` 變為原始損失 `J(w)` 加上這個懲罰項乘以一個正則化係數 `α`：
    `J̃(w) = J(w) + (α/2) ||w||_2^2`

**Q:** L² 正則化為什麼被稱為「權重衰減 (weight decay)」？

**A:** 因為在梯度下降的參數更新規則中，L² 正則化項的梯度是 `αw`。這導致權重更新變為：
`w ← w - ϵ(∇_w J_{original}(w) + αw)`
`w ← (1 - ϵα)w - ϵ∇_w J_{original}(w)`
從第二個式子可以看出，在每次使用原始損失的梯度進行更新之前，權重 `w` 都會先乘以一個因子 `(1 - ϵα)`。由於學習率 `ϵ` 和正則化係數 `α` 通常都是小的正數，所以 `(1 - ϵα)` 是一個小於 1 的正數。這意味著權重在每次更新時都會被「衰減」一個小的比例，因此 L² 正則化也被稱為權重衰減。

**Q:** L² 正則化對模型的權重有什麼影響？它如何幫助防止過擬合？

**A:** L² 正則化傾向于使模型的權重值變得更小，更接近於零，但通常不會使它們恰好為零。
    它通過以下方式幫助防止過擬合：
    1.  **限制模型複雜度:** 懲罰大的權重值相當於限制了模型的有效複雜度。一個具有較小權重的模型通常對輸入的微小變化不那麼敏感，其學習到的函數更平滑，從而更不容易擬合訓練數據中的噪聲。
    2.  **改善優化問題的條件:** 在某些情況下，添加 L² 正則化可以使損失函數的 Hessian 矩陣更接近正定，從而改善優化問題的條件數，使得優化過程更穩定。
    3.  **鼓勵權重分散:** L² 懲罰平方和，傾向于讓所有權重都比較小，而不是讓少數權重非常大而其他權重為零（與 L1 正則化不同）。

---

### 7.1.2 L¹ 參數正則化

**重點摘要:**
L¹ 參數正則化是另一種常用的參數范數懲罰。它向目標函數添加一個正則項 `Ω(θ) = ||w||_1 = Σ_i |w_i|` (公式 7.18)。正則化後的目標函數變為：
`J̃(w; X, y) = α||w||_1 + J(w; X, y)` (公式 7.19)
其梯度為：
`∇_w J̃(w; X, y) = α sign(w) + ∇_w J(w; X, y)` (公式 7.20)
其中 `sign(w)` 是對 `w` 的每個元素應用符號函數。
L¹ 正則化與 L² 正則化的一個關鍵區別在於 L¹ 正則化會產生**稀疏解 (sparse solution)**，即許多參數的最優值會變為零。這使得 L¹ 正則化可以用於特征選擇。相比之下，L² 正則化只會使參數接近於零，而不會使其恰好為零（除非參數的原始最優值本來就是零）。
L¹ 正則化可以被解釋為在 MAP 貝葉斯推斷框架下，對參數使用 Laplace 先驗分布 (公式 7.24)。


**Q:** 什麼是 L¹ 參數正則化？它的正則化項是什麼形式？

**A:** L¹ 參數正則化是一種通過向模型的損失函數中添加一個與模型權重絕對值之和成正比的懲罰項來進行正則化的方法。
    其正則化項 `Ω(w)` 通常定義為權重向量 `w` 的 L¹ 范數：
    `Ω(w) = ||w||_1 = Σ_i |w_i|`
    正則化後的總損失函數 `J̃(w)` 變為原始損失 `J(w)` 加上這個懲罰項乘以一個正則化係數 `α`：
    `J̃(w) = J(w) + α||w||_1`

**Q:** L¹ 正則化與 L² 正則化在對模型權重的影響以及產生的解的特性上有何主要區別？

**A:** 主要區別在於它們對權重的懲罰方式以及由此產生的解的稀疏性：
1.  **對權重的影響:**
    *   **L² 正則化:** 懲罰權重的平方和。它傾向于使所有權重都變得比較小，但通常不會使它們恰好為零。解是「平滑」的。
    *   **L¹ 正則化:** 懲罰權重的絕對值之和。它傾向于使模型中的許多權重值恰好變為零，而只保留少數具有較大絕對值的權重。
2.  **解的特性:**
    *   **L² 正則化:** 通常不會產生稀疏解（即權重向量中很少有零元素）。
    *   **L¹ 正則化:** 會產生**稀疏解**，即權重向量中的許多元素會是零。
3.  **特征選擇:** 由於 L¹ 正則化能夠將不重要的特征對應的權重驅動為零，因此它可以被用作一種**特征選擇 (feature selection)** 的方法。L² 正則化則沒有這種直接的特征選擇效果。
4.  **計算:** L¹ 正則化項在零點處不可微，這給優化帶來了一些額外的複雜性（例如，需要使用次梯度或近端梯度等方法）。L² 正則化項則是處處可微的。

**Q:** 為什麼說 L¹ 正則化能夠產生稀疏解？

**A:** 這可以從優化問題的幾何形狀來理解。L¹ 正則化項 `||w||_1 = C` 定義的約束區域是一個在坐標軸上具有「角點」的多面體（例如，在二維情況下是一個菱形）。當損失函數的等值線與這個帶有角點的約束區域相切時，最優解更有可能出現在這些角點上。在角點處，某些坐標（權重）的值為零。
    相比之下，L² 正則化項 `||w||_2^2 = C` 定義的約束區域是一個光滑的超球面。損失函數的等值線與超球面相切時，除非等值線的中心恰好在某個坐標軸上，否則通常不會導致任何坐標恰好為零。

---

## 7.2 作為約束的范數懲罰

**重點摘要:**
通過參數范數懲罰正則化的代價函數 `J̃(θ; X, y) = J(θ; X, y) + αΩ(θ)` (公式 7.25) 可以被看作是對原始目標函數 `J(θ; X, y)` 在約束 `Ω(θ) ≤ k` (其中 `k` 是某個值) 下進行優化的一個拉格朗日乘子形式。這被稱為**約束優化 (constrained optimization)**。
如果 `Ω` 是凸的，那麼 `Ω(θ) ≤ k` 定義了一個凸集。如果 `J` 也是凸的，那麼這是一個凸優化問題。
有時，我們可能希望使用顯式的約束而不是懲罰項。這可以通過修改優化算法（如使用投影梯度下降）來實現。
使用顯式約束的一個優點是，如果我們知道約束區域的大小（例如，通過先驗知識），可以直接指定它，而不需要像調整懲罰係數 `α` 那樣進行搜索。另一個優點是，約束可以阻止參數變得過大（防止梯度爆炸），而懲罰項可能允許參數變得非常大，只要損失函數的下降足夠快。
在實踐中，約束版本的范數懲罰是通過**投影 (projection)** 到滿足約束的區域來實現的。例如，對於 L² 約束 `||w||_2^2 ≤ k`，如果梯度下降更新後的 `w` 超出了這個球形區域，就將其投影回球的表面。


**Q:** 如何將參數范數懲罰（如 L² 或 L¹ 正則化）理解為一種約束優化問題？

**A:** 向目標函數 `J(θ)` 添加一個參數范數懲罰項 `αΩ(θ)`，形成 `J̃(θ) = J(θ) + αΩ(θ)`，這在數學上等價於（或與之密切相關）在某個約束條件 `Ω(θ) ≤ k` 下最小化原始目標函數 `J(θ)` 的問題。
    具體來說，根據拉格朗日乘子法，約束優化問題 `min J(θ) s.t. Ω(θ) ≤ k` 可以轉換為最小化拉格朗日函數 `L(θ, λ) = J(θ) + λ(Ω(θ) - k)`，其中 `λ ≥ 0` 是拉格朗日乘子。這個形式與懲罰項的形式非常相似（`α` 對應於 `λ`）。
    參數 `α` 的大小與約束 `k` 的大小是反相關的：較大的 `α`（強懲罰）對應於較小的 `k`（更嚴格的約束），反之亦然。

**Q:** 相較於使用懲罰項，使用顯式的范數約束（例如，`||w||_2^2 ≤ k`）進行正則化有哪些潛在的優點？

**A:**
1.  **更直接地控制參數範圍:** 如果我們對參數的合理範圍有先驗知識，或者希望將參數限制在一個特定區域內，顯式約束可以更直接地實現這一點。而懲罰項的強度（由 `α` 控制）與參數的實際范數之間的關係可能不那麼直觀。
2.  **防止參數變得過大:** 即使損失函數的梯度非常大（可能導致參數更新步長很大），顯式約束也能確保參數始終保持在允許的範圍內。這有助於防止由於參數值過大而導致的數值不穩定或梯度爆炸問題。而懲罰項雖然會懲罰大的參數，但如果損失函數下降得足夠快，它仍然可能允許參數變得非常大。
3.  **某些情況下更易於分析:** 約束優化問題有其自身的理論和算法。

**Q:** 在實踐中，如何實現基於顯式范數約束的正則化？例如，對於 L² 約束？

**A:** 通常通過**投影梯度下降 (Projected Gradient Descent)** 或類似的方法來實現。
    對於 L² 約束 `||w||_2^2 ≤ R^2`（即權重向量必須位於半徑為 `R` 的球內）：
    1.  執行一次標準的梯度下降更新，得到一個臨時的權重向量 `w̃`。
    2.  檢查 `w̃` 是否滿足約束：
        *   如果 `||w̃||_2^2 ≤ R^2`，則 `w̃` 就是本次迭代的最終更新。
        *   如果 `||w̃||_2^2 > R^2`（即 `w̃` 超出了球的範圍），則將 `w̃` **投影 (project)** 回到球的表面，即 `w = R * (w̃ / ||w̃||_2)`。
    對於 L¹ 約束，投影操作會更複雜一些（涉及到軟閾值操作）。

---

## 7.3 正則化和欠約束問題

**重點摘要:**
在某些機器學習問題中，特別是當特征數量遠大於訓練樣本數量時，問題可能是**欠定的 (underdetermined)**，即存在無限多個解都能完美擬合訓練數據。正則化可以用於選擇這些解中的一個特定解。例如，L² 正則化會選擇具有最小 L² 范數的解。Moore-Penrose 偽逆 `X^+` (公式 7.29) 給出的線性回歸解 `w = X^+y` 正是這種具有最小 L² 范數的解。
更一般地，許多正則化形式（如 L²、L¹）都可以被解釋為在 MAP 貝葉斯推斷框架下，為模型參數引入了特定的先驗分布。例如，L² 正則化對應於高斯先驗，L¹ 正則化對應於 Laplace 先驗。這些先驗使得原本欠定的問題變得良定義 (well-posed)，因為它們在眾多可能的解中引入了一個偏好。


**Q:** 什麼是「欠約束 (underconstrained)」或「欠定 (underdetermined)」的機器學習問題？

**A:** 欠約束或欠定的機器學習問題是指訓練數據提供的信息不足以唯一確定模型的參數。通常發生在：
*   **特征數量遠大於樣本數量 (p >> n):** 例如，在基因表達數據分析中，可能有數萬個基因（特征），但只有幾十或幾百個樣本。
*   **模型過於複雜/靈活:** 即使樣本數量不少，如果模型的容量非常大，也可能存在多組不同的參數都能夠完美地（或同樣好地）擬合訓練數據。
    在這些情況下，存在無限多個解都能使得訓練誤差達到最小值（通常是零）。

**Q:** 正則化是如何幫助解決欠約束問題的？它如何幫助從多個可能的解中選擇一個？

**A:** 正則化通過向學習問題引入額外的約束或偏好，來幫助解決欠約束問題。當存在多個解都能同樣好地擬合訓練數據時，正則化項會引導優化算法選擇其中一個滿足特定屬性（由正則化項定義）的解。
    例如：
    *   **L² 正則化:** 在所有能夠最小化訓練誤差的解中，L² 正則化會選擇那個具有最小 L² 范數（即權重向量長度最短）的解。這通常對應於一個更「平滑」或更「簡單」的解。
    *   **L¹ 正則化:** 在所有能夠最小化訓練誤差的解中，L¹ 正則化會選擇那個具有最小 L¹ 范數的解，這通常是一個稀疏解（即許多權重為零）。
    從貝葉斯的角度看，正則化相當於為模型參數引入了一個先驗分布。這個先驗使得後驗機率在參數空間中具有更明確的峰值，從而使問題從欠定變為良定義。

---

**由於後續章節涉及到更具體的正則化技術，我將繼續為每個主要小節提供摘要和 Q&A。**

---

## 7.4 數據集增強

**重點摘要:**
讓機器學習模型泛化得更好的最好辦法是使用更多的數據進行訓練。然而，在實踐中，我們擁有的數據量是很有限的。解決這個問題的一種方法是創建假數據並添加到訓練集中。對於分類來說，這種方法最容易。一個分類器需要將一個複雜的高維輸入 `x` 映射到一個單個類別標識 `y`。這意味著分類器主要任務是對於各種各樣的變換保持不變。我們可以通過對訓練集中的 `x` 轉換成新的 `(x,y)` 對來輕鬆生成新的數據。
這種方法對於許多分類任務來說都不那麼容易。例如，在密度估計中生成新的假數據就非常困難。
數據集增強對一個具體的分類問題來說是特別有效的方法：對象識別。圖像的高維的並包含多種巨大變化的因素，其中有許多可以輕易地模擬。即使模型已經使用了考慮平移不變性的卷積和池化技術，通過將訓練圖像每個方向平移幾個像素的操作通常可以極大改善泛化。許多其他操作如旋轉圖像或縮放圖像也被證明非常有效。
我們必須要小心，不能使用會改變類別的轉換。例如，光學字符識別任務需要識別字母 "b" 和 "d" 以及 "6" 和 "9" 的區別，所以水平翻轉並不是合適的選擇。


**Q:** 什麼是數據集增強 (dataset augmentation)？它的主要目的是什麼？

**A:** 數據集增強是一種通過對現有的訓練樣本應用各種隨機的、保持標籤不變的變換來人工生成新的訓練樣本的技術。
    其主要目的是：
    1.  **增加訓練數據的多樣性和數量:** 在不實際收集更多原始數據的情況下，擴大訓練集的規模，從而為模型提供更多樣化的訓練示例。
    2.  **提高模型的泛化能力和魯棒性:** 通過向模型展示同一對象或概念在不同視角、光照、姿態、尺度、位置等條件下的變體，可以幫助模型學習到對這些變化更不敏感、更魯棒的特征，從而提高其在未見過的新數據上的泛化性能。
    3.  **減少過擬合:** 數據增強相當於向訓練過程引入了一種噪聲或正則化，有助於防止模型過度擬合訓練數據中的特定細節。

**Q:** 在圖像識別任務中，有哪些常見的數據集增強方法？

**A:** 常見的圖像數據集增強方法包括：
1.  **幾何變換:**
    *   **平移 (Translation):** 在水平或垂直方向上隨機移動圖像。
    *   **旋轉 (Rotation):** 以隨機角度旋轉圖像。
    *   **縮放 (Scaling / Resizing):** 隨機放大或縮小圖像。
    *   **裁剪 (Cropping):** 從原始圖像中隨機裁剪出一部分，或者先對圖像進行填充然後再隨機裁剪。
    *   **翻轉 (Flipping):** 水平翻轉（常用）或垂直翻轉（取決於數據特性）。
    *   **仿射變換 (Affine Transformation) / 透視變換 (Perspective Transformation):** 更複雜的幾何形變。
2.  **顏色空間變換:**
    *   **亮度調整 (Brightness Adjustment):** 隨機改變圖像的亮度。
    *   **對比度調整 (Contrast Adjustment):** 隨機改變圖像的對比度。
    *   **飽和度調整 (Saturation Adjustment):** 隨機改變圖像的飽和度。
    *   **色調抖動 (Hue Jittering):** 隨機改變圖像的色調。
    *   **顏色通道隨機排列或主成分分析噪聲 (PCA Jittering):** 對 RGB 通道進行更複雜的顏色擾動。
3.  **添加噪聲:** 向圖像中添加隨機噪聲，如高斯噪聲、椒鹽噪聲。
4.  **模糊 (Blurring):** 使用高斯模糊等濾波器對圖像進行模糊處理。
5.  **Cutout / Random Erasing:** 在圖像中隨機選擇一個矩形區域並將其像素值置為零或隨機值，迫使模型關注圖像的其他部分。
6.  **Mixup / CutMix:** 將兩張不同的圖像及其標籤進行線性插值或拼接，生成新的混合樣本。

**Q:** 在使用數據集增強時，需要注意什麼重要的原則？

**A:** 最重要的原則是**保持標籤不變性 (label preservation)**。即，對訓練樣本進行的變換不應該改變該樣本的真實類別標籤。
    例如：
    *   對於手寫數字 "6" 的圖像，進行水平翻轉可能會使其看起來像 "9"，這就改變了標籤，因此水平翻轉在這種情況下是不合適的。
    *   對於一般的自然圖像分類（如貓 vs. 狗），水平翻轉通常是保持標籤不變的，因為鏡像的貓仍然是貓。
    *   對於需要精確位置信息的任務（如某些醫學圖像分析），過度的平移或裁剪可能會改變圖像的關鍵診斷信息。
    需要根據具體的任務和數據特性來選擇合適的、有意義的數據增強方法。

---

## 7.5 噪聲魯棒性

**重點摘要:**
正則化的一個一般性觀點是，它向模型中注入噪聲，可以提高模型的魯棒性。
*   **向權重注入噪聲:** (Jim et al., 1996; Graves, 2011) 在訓練期間向模型的權重添加隨機噪聲。這可以被看作是 L² 正則化的一種隨機實現，或者等價於對權重進行貝葉斯推斷時，權重具有高斯先驗。
*   **向輸出注入噪聲 / 標籤平滑 (Label Smoothing):** (Szegedy et al., 2015) 對於分類任務，不是使用 one-hot 編碼的硬標籤，而是將目標標籤從 `[0,1]` 稍微「平滑」一下，例如，將正確類別的目標值設為 `1-ϵ`，將其他錯誤類別的目標值設為 `ϵ/(k-1)`（`k` 是類別數，`ϵ` 是一個小常數）。這可以防止模型對其預測過於自信，並提高泛化能力。


**Q:** 為什麼說向模型中注入噪聲可以作為一種正則化方法，提高模型的魯棒性？

**A:** 向模型中注入噪聲（無論是向輸入、權重還是激活值）可以被視為一種正則化方法，因為它迫使模型學習在存在擾動的情況下仍然能夠做出正確的預測或保持穩定的表示。
    這可以提高模型的魯棒性，原因如下：
    1.  **防止過擬合:** 噪聲使得訓練數據看起來更加多樣化和不確定，模型更難以完全記住訓練樣本的特定細節，從而被迫學習更泛化、更本質的模式。
    2.  **平滑損失景觀:** 注入噪聲可以被認為是在某種程度上平滑了損失函數的景觀，使得優化算法更容易找到較寬闊的、更魯棒的極小值區域，而不是那些狹窄的、對參數微小變化敏感的尖銳極小值。
    3.  **提高對真實世界噪聲的適應性:** 如果模型在訓練時已經學會了處理人工引入的噪聲，那麼它在面對真實世界中帶有噪聲的輸入時，可能會表現得更好。

**Q:** 標籤平滑 (label smoothing) 是如何工作的？它為什麼有助於提高分類模型的性能？

**A:** 標籤平滑是一種用於訓練分類模型的正則化技術。在標準的分類任務中，訓練數據的標籤通常是「硬標籤 (hard labels)」，即 one-hot 編碼的向量（例如，對於正確類別，目標值為 1，其他類別為 0）。
    標籤平滑的做法是，不使用這些硬標籤，而是使用「軟標籤 (soft labels)」。具體來說，對於一個正確類別為 `c` 的樣本：
    *   將其目標向量中對應正確類別 `c` 的元素從 1 修改為一個略小於 1 的值，例如 `1 - ϵ`（其中 `ϵ` 是一個小的正數，如 0.1）。
    *   將其目標向量中對應所有其他錯誤類別的元素從 0 修改為一個小的正值，例如 `ϵ / (K - 1)`（其中 `K` 是總的類別數量），以確保所有元素的總和仍然為 1。
    標籤平滑有助於提高分類模型的性能，因為：
    1.  **防止模型過於自信:** 使用硬標籤訓練時，模型會被激勵使其對正確類別的預測機率無限接近於 1，對錯誤類別的預測機率無限接近於 0。這可能導致模型對其預測過於自信，並且對訓練數據中的微小擾動或噪聲非常敏感。標籤平滑通過「軟化」目標，鼓勵模型輸出一種更平滑的預測分布，減少了過度自信。
    2.  **改善模型的校準 (Calibration):** 標籤平滑訓練的模型輸出的預測機率通常更能反映其真實的置信水平。
    3.  **提高泛化能力:** 通過不強迫模型對訓練樣本做出極端的預測，可以提高模型在未見過數據上的泛化性能。

---

**由於後續章節涉及到更具體的正則化技術，我將繼續為每個主要小節提供摘要和 Q&A。**

---

## 7.6 半監督學習

**重點摘要:**
在半監督學習的框架下，模型同時從有標註數據 `P(x,y)` 和無標註數據 `P(x)` 中學習。其核心思想是，關於 `P(x)` 的信息（例如，數據點如何在輸入空間中聚集）可以用來幫助指導模型在 `P(y|x)` 上的學習，即使沒有 `y` 的標註。如果 `x` 的結構與 `y` 的結構相關，那麼學習 `P(x)` 可以幫助學習 `P(y|x)`。
一種方法是共享參數。一個同時學習 `P(x)`（或其相關任務，如重構 `x`）和 `P(y|x)` 的模型，可以讓這兩個任務共享一些底層的參數（例如，學習一個共享的表示 `h=f(x)`）。無標註數據可以幫助學習一個好的表示 `h`，然後這個表示可以用於監督任務。


**Q:** 什麼是半監督學習？它與監督學習和無監督學習的主要區別是什麼？

**A:** 半監督學習是一種機器學習範式，它在訓練時同時使用**少量有標註的數據**和**大量無標註的數據**。
    與監督學習和無監督學習的主要區別在於訓練數據的構成：
    *   **監督學習:** 所有的訓練數據都帶有明確的標籤（即輸入和對應的期望輸出）。
    *   **無監督學習:** 所有的訓練數據都沒有標籤，模型需要從數據本身中發現結構、模式或表示。
    *   **半監督學習:** 訓練數據包含一部分帶有標籤的樣本和一部分（通常是更大量的）沒有標籤的樣本。

**Q:** 半監督學習的核心思想是什麼？無標註數據如何幫助有標註數據的學習任務？

**A:** 半監督學習的核心思想是，儘管無標註數據沒有提供直接的監督信號（即沒有 `y`），但它們仍然攜帶了關於輸入數據 `x` 的分布 `P(x)` 的有用信息。如果輸入數據的結構（例如，數據點如何在特徵空間中聚集，哪些區域是高密度的，哪些是低密度的）與我們感興趣的監督任務 `P(y|x)` 相關，那麼利用無標註數據來學習 `P(x)` 的信息，就可以幫助改進對 `P(y|x)` 的學習。
    無標註數據可以通過以下方式幫助有標註數據的學習任務：
    1.  **學習更好的表示:** 無標註數據可以用來預訓練一個表示學習模型（如自編碼器、RBM），學習到輸入數據的低維、有意義的特征表示。然後，這個學到的表示可以用於後續的、基於少量標註數據的監督學習。
    2.  **改進決策邊界:** 如果假設決策邊界不應該穿過輸入空間中的高密度區域（聚類假設, cluster assumption），那麼無標註數據可以幫助識別這些高密度區域，從而指導決策邊界的放置。
    3.  **平滑性假設 (Smoothness Assumption) / 低密度分離假設 (Low-Density Separation Assumption):** 如果兩個點在輸入空間的高密度區域中很接近，那麼它們的標籤也應該相似。無標註數據可以幫助確定這種「接近性」。
    4.  **流形假設 (Manifold Assumption):** 如果數據位於一個嵌入在高維空間中的低維流形上，無標註數據可以幫助學習這個流形的結構。

---

## 7.7 多任務學習

**重點摘要:**
多任務學習 (Multitask Learning) (Caruana, 1993) 是一種通過合併幾個任務中的樣本（可以視為對參數施加的軟約束）來提高泛化的一種方式。額外的訓練樣本將參數置於同樣適用於其他任務的模式，額外的任務的參數的泛化誤差將得到改善。
當模型的一部分在任務之間共享時，模型的這一部分更多地被約束為良好的值（假設共享是合理的），往往能更好地泛化。
圖 7.2 展示了多任務學習中參數共享的一種常見形式：底層的特征提取層是共享的，而頂層的任務特定層是分開的。共享參數的統計強度可以大大提高（共享參數的樣本數量相對於單任務模型中的樣本數量）。


**Q:** 什麼是多任務學習 (Multitask Learning)？它的核心思想是什麼？

**A:** 多任務學習是一種機器學習方法，它通過**同時學習多個相關的任務**，並讓這些任務**共享模型的一部分參數或表示**，來提高每個單獨任務的學習性能和泛化能力。
    核心思想是，如果多個任務之間存在相關性（例如，它們依賴於一些共同的底層特征或知識），那麼同時學習這些任務可以讓模型從所有任務的數據中學習到更通用、更魯棒的表示，並且一個任務的學習可以為其他任務的學習提供有益的約束或歸納偏置。

**Q:** 多任務學習是如何通過參數共享來提高模型性能的？

**A:**
1.  **增加有效訓練數據量:** 對於共享的參數部分，它實際上是從所有任務的數據中進行學習的。這相當於增加了用於訓練這部分共享參數的有效數據量，有助於學習到更泛化、更魯棒的特征。
2.  **正則化效果:** 迫使共享表示對多個任務都有用，這本身就是一種隱式的正則化。模型需要找到一個能夠同時滿足多個任務需求的表示，這有助於避免過度擬合到任何單個任務的特定噪聲或細節。
3.  **特征的互補性:** 來自一個任務的學習信號可能包含對另一個任務有用的信息，即使這些信息在另一個任務的數據中不那麼明顯。多任務學習可以幫助模型發現和利用這種跨任務的互補信息。
4.  **注意力聚焦:** 如果一個特征對多個任務都很重要，那麼模型會更加關注學習這個特征。

**Q:** 在多任務學習中，常見的參數共享方式是什麼樣的？

**A:** 常見的參數共享方式是**硬參數共享 (hard parameter sharing)**，尤其是在基於神經網路的模型中：
*   網路的較低層（例如，輸入層和一些初始的隱藏層）的參數在所有任務之間是共享的。這些共享層負責學習通用的、底層的特征表示。
*   網路的較高層則是任務特定的，每個任務都有其自己的一組不共享的參數。這些任務特定的層在共享表示的基礎上學習完成各自的特定任務。
    圖 7.2 展示了這種典型的結構。也可以有更複雜的共享模式，例如，部分共享或通過門控機制動態決定共享程度。

---

## 7.8 提前終止

**重點摘要:**
提前終止 (Early Stopping) 是一種非常常用且有效的正則化形式，它幾乎不需要修改訓練過程，並且不需要改變代價函數。當訓練有足夠表示能力的大模型時，訓練誤差會隨著時間的推移逐漸降低，但驗證集誤差會開始再次上升（過擬合）。提前終止通過在驗證集誤差達到最小值時停止訓練來應對這個問題。
算法 7.1 描述了提前終止的過程：監控驗證集誤差，如果經過一定「耐心 (patience)」步數後驗證集誤差沒有進一步改善，則停止訓練，並返回在驗證集上性能最好的模型參數。
提前終止可以被看作是一種高效的超參數選擇方法（選擇訓練的迭代次數）。它的一個優點是不需要額外的代價項來平衡訓練誤差和正則化強度。然而，它需要一個獨立的驗證集，並且如果驗證集太小，對泛化誤差的估計可能不準確。
圖 7.3 展示了訓練誤差和驗證誤差隨訓練輪數 (epochs) 的變化。


**Q:** 什麼是提前終止 (early stopping)？它是如何工作的？

**A:** 提前終止是一種在訓練迭代學習模型（如神經網路）時使用的正則化技術和停止準則。
*   **工作原理:**
    1.  在訓練過程中，除了監控模型在訓練集上的性能（例如，訓練損失）外，還同時在一個獨立的**驗證集 (validation set)** 上監控模型的性能（例如，驗證損失或驗證準確率）。
    2.  如果發現模型在驗證集上的性能不再提升，甚至開始惡化（表明模型開始過擬合訓練數據），就提前停止訓練過程。
    3.  通常會保存並返回在驗證集上性能達到最佳時的那個模型參數副本。

**Q:** 提前終止為什麼能夠起到正則化的作用，防止模型過擬合？

**A:**
1.  **限制模型有效容量:** 訓練迭代的次數可以被看作是模型的一個超參數，它間接控制了模型的有效容量。訓練時間越長，模型越有機會擬合訓練數據中的噪聲和特定細節。提前終止通過在模型開始過擬合之前停止訓練，有效地限制了模型學習過於複雜的函數的能力。
2.  **選擇泛化能力好的模型:** 提前終止的目標是找到一個在未見過的數據（由驗證集代表）上表現最好的模型，而不是僅僅在訓練數據上表現最好的模型。這直接優化了模型的泛化能力。

**Q:** 使用提前終止有哪些主要的優點和潛在的缺點？

**A:**
*   **優點:**
    1.  **實現簡單:** 幾乎不需要修改訓練算法本身，只需要額外監控驗證集性能。
    2.  **計算高效:** 不需要像某些正則化方法那樣增加額外的計算負擔（例如，計算懲罰項的梯度）。它甚至可以減少總的訓練時間（因為提前停止了）。
    3.  **自動確定訓練輪數:** 提供了一種自動確定合適訓練迭代次數的方法，避免了手動設置固定輪數可能導致的訓練不足或過度訓練。
    4.  **通常非常有效:** 在許多情況下，提前終止是一種非常有效的防止過擬合的方法。
*   **潛在缺點:**
    1.  **需要驗證集:** 需要從訓練數據中劃分出一部分作為驗證集，這減少了可用於訓練的數據量。如果原始數據集本身就很小，這可能是一個問題。
    2.  **對驗證集敏感:** 驗證集的選擇和大小會影響提前終止的效果。如果驗證集太小或不具有代表性，那麼基於驗證集性能做出的停止決策可能不是最優的。
    3.  **可能過早停止:** 如果驗證集性能的波動較大，或者「耐心」參數設置不當，模型可能在達到其潛在最佳性能之前就過早停止了訓練。

---

**由於後續的章節涉及到更具體的正則化技術，我將繼續為每個主要小節提供摘要和 Q&A。**

---

## 7.9 參數綁定和參數共享

**重點摘要:**
有時我們可能沒有足夠的訓練數據來為模型的每個參數學習一個獨立的值。**參數共享 (parameter sharing)** 是一種策略，它強制模型中的某些參數相等。這意味著我們只需要存儲和學習這些共享參數的一個副本。例如，在卷積神經網路 (CNN) 中，卷積核的參數在輸入圖像的不同空間位置是共享的。
**參數綁定 (parameter tying)** 是一種更一般的形式，其中參數不一定完全相等，而是被約束為滿足某些關係（例如，一個參數是另一個參數的線性函數）。
參數共享的一個顯著優勢是它顯著減少了模型的參數數量，從而降低了模型過擬合的風險，並提高了統計效率（可以用更少的數據學習到更可靠的參數）。然而，它也引入了一個強的先驗，即被共享的參數應該是相似的或相同的。如果這個先驗不符合數據的真實特性，可能會限制模型的表達能力。


**Q:** 什麼是參數共享 (parameter sharing)？它在機器學習模型中是如何應用的？

**A:** 參數共享是指在一個模型中，讓不同的部分（例如，網路的不同位置或不同的組件）使用相同的一組參數。這意味著這些共享的參數只需要被學習一次，然後在多個地方重複使用。
    在機器學習模型中，參數共享的典型應用包括：
    1.  **卷積神經網路 (CNN):** 卷積核的權重在輸入圖像的不同空間位置是共享的。這意味著同一個濾波器被用來掃描整個圖像以檢測相同的局部模式。
    2.  **循環神經網路 (RNN):** 在處理序列的不同時間步時，RNN 使用相同的狀態轉移函數和相同的權重參數。
    3.  **某些類型的多任務學習:** 不同任務的模型之間共享一部分參數（例如，共享底層的特征提取層）。

**Q:** 參數共享相比於每個部分都使用獨立參數的模型有哪些主要的優點？

**A:**
1.  **顯著減少模型參數數量:** 這是最直接的優點。由於參數在多處被重用，需要學習和存儲的唯一參數的總量大大減少。
2.  **提高統計效率:** 因為每個共享參數是從輸入數據的更多部分（或更多樣本，在某些情況下）中學習得到的，所以對這些參數的估計通常更可靠、更穩定，需要更少的數據就能學好。
3.  **降低過擬合風險:** 參數數量減少通常會降低模型的有效容量，使其更不容易過度擬合訓練數據中的噪聲。
4.  **引入有意義的先驗:** 參數共享通常基於某些關於數據或任務的先驗假設。例如，在 CNN 中，參數共享基於圖像中的局部模式具有平移不變性的假設。如果這些先驗是合理的，它們可以引導模型學習更有意義的表示。
5.  **允許處理可變大小的輸入 (在某些情況下):** 例如，CNN 的卷積操作由於參數共享，可以自然地處理不同大小的輸入圖像（儘管後續的全連接層可能需要固定大小的輸入）。

**Q:** 參數綁定 (parameter tying) 與參數共享有何異同？

**A:**
*   **相同點:** 兩者都是通過對模型的參數施加約束來減少模型的自由度或引入先驗知識。
*   **不同點:**
    *   **參數共享:** 強制某些參數**完全相等**。例如，CNN 中的卷積核在所有位置都是同一個核。
    *   **參數綁定:** 是一種更廣義的概念，它不一定要求參數完全相等，而是要求它們之間滿足某種預先定義的**關係**。例如，可以約束一個權重是另一個權重的倍數，或者一組權重必須對稱等。參數共享可以被看作是參數綁定的一種特殊情況（關係是「相等」）。

---

## 7.10 稀疏表示

**重點摘要:**
另一種正則化策略是**稀疏表示 (sparse representation)**。這可以通過兩種方式實現：
1.  **對表示本身施加稀疏性懲罰:** 例如，在自編碼器中，可以對隱藏層的激活值 `h` 施加 L1 懲罰 `Ω(h) = Σ_i |h_i|` (公式 7.48)，以鼓勵許多激活值為零。
2.  **學習稀疏的連接或權重:** 例如，L1 權重衰減（如 7.1.2 節所述）可以誘導模型中的許多權重變為零，從而使得從輸入到輸出的路徑變得稀疏。
稀疏表示的動機包括：
*   **信息瓶頸:** 迫使模型只用少數幾個活躍的特征來表示信息，從而提取更本質的內容。
*   **可解釋性:** 稀疏的激活或權重可能更容易解釋，每個活躍的單元或權重可能對應一個更明確的概念或模式。
*   **計算效率:** 如果表示是稀疏的，後續的計算可能可以利用這種稀疏性來加速。
正交匹配追踪 (Orthogonal Matching Pursuit, OMP) 是一種可以學習稀疏表示的算法。


**Q:** 什麼是稀疏表示？它在正則化中有哪兩種主要的實現方式？

**A:** 稀疏表示是指一種數據表示，其中大部分元素的值都是零或接近於零，只有少數元素具有顯著的非零值。
    在正則化中，實現稀疏表示的主要方式有：
    1.  **懲罰表示的激活值 (Penalty on Activations):** 直接對神經網路中間層（隱藏層）的激活值 `h` 施加稀疏性懲罰。例如，在損失函數中加入激活值的 L1 范數 `α||h||_1`。這會鼓勵模型在表示任何給定輸入時，只激活少數幾個隱藏單元。
    2.  **懲罰模型的權重 (Penalty on Weights):** 對模型的權重參數 `w` 施加稀疏性懲罰，最常用的是 L1 權重衰減（在損失函數中加入 `α||w||_1`）。這會導致許多權重變為零，從而使得從輸入到輸出的有效連接變得稀疏，即每個輸出單元只依賴於少數幾個輸入單元（通過非零權重連接）。

**Q:** 學習稀疏表示有哪些潛在的好處？

**A:**
1.  **特征選擇/信息壓縮:** 稀疏性迫使模型只選擇和使用那些對表示輸入或完成任務最重要的特征，從而實現一種形式的特征選擇和信息壓縮。
2.  **提高可解釋性:** 如果表示是稀疏的，那麼每個激活的隱藏單元或每個非零的權重可能對應一個更明確、更容易理解的輸入數據的屬性或模式。
3.  **提高計算效率:** 如果表示或權重是稀疏的，那麼後續的計算（如矩陣乘法）可能可以利用這種稀疏性來減少實際的運算量（儘管這需要專門的稀疏計算庫支持）。
4.  **改善泛化能力/減少過擬合:** 作為一種正則化手段，稀疏性限制了模型的有效容量，有助於防止模型過度擬合訓練數據。
5.  **對噪聲的魯棒性:** 稀疏模型可能對輸入中的某些類型的噪聲不那麼敏感，因為它們主要依賴於少數幾個關鍵特征。

---

## 7.11 Bagging 和其他集成方法

**重點摘要:**
Bagging (Bootstrap Aggregating) (Breiman, 1994) 是一種通過組合多個模型來降低泛化誤差的集成方法。
*   **工作原理:**
    1.  從原始訓練數據集中通過有放回抽樣（bootstrap sampling）生成 `k` 個不同的訓練子集。
    2.  在這 `k` 個訓練子集上分別獨立地訓練 `k` 個不同的模型。
    3.  對於新的輸入，將這 `k` 個模型的預測結果進行聚合（例如，對於分類問題是投票，對於回歸問題是取平均）得到最終的集成預測。
Bagging 主要通過**減少模型的方差**來提高性能。如果單個模型對訓練數據的微小變化很敏感（即方差較高），那麼對多個在略微不同的數據集上訓練的模型的預測進行平均，可以平滑掉這些波動，得到一個更穩定、更魯棒的集成模型。
其他集成方法包括 Boosting（如 AdaBoost, Gradient Boosting）。


**Q:** 什麼是 Bagging (Bootstrap Aggregating)？它是如何工作的？

**A:** Bagging 是一種集成學習 (ensemble learning) 技術，它通過組合多個獨立訓練的模型的預測來提高整體模型的性能。
*   **工作原理:**
    1.  **Bootstrap 採樣:** 從原始的 `m` 個樣本的訓練數據集中，進行 `k` 次有放回的隨機抽樣，每次抽取 `m` 個樣本，得到 `k` 個大小與原始數據集相同的、但可能包含重複樣本且各不相同的訓練子集。
    2.  **獨立訓練模型:** 在這 `k` 個不同的訓練子集上，獨立地訓練 `k` 個相同的基礎學習器（例如，`k` 個決策樹，或 `k` 個神經網路）。
    3.  **聚合預測:** 對於新的輸入數據，將這 `k` 個獨立訓練的模型的預測結果進行聚合，得到最終的集成預測。
        *   對於**分類問題**，聚合方式通常是**多數投票 (majority voting)**。
        *   對於**回歸問題**，聚合方式通常是**取平均值 (averaging)**。

**Q:** Bagging 主要通過改善模型的哪個方面（偏差還是方差）來提高性能？為什麼？

**A:** Bagging 主要通過**減少模型的方差 (variance)** 來提高性能。
    原因如下：
    *   **方差的來源:** 單個模型（特別是複雜的模型，如深度決策樹或大型神經網路）的預測結果可能對訓練數據的微小變化非常敏感。如果在略微不同的訓練數據子集上訓練相同的模型，可能會得到性能差異較大的模型。這種不穩定性就是方差的體現。
    *   **平均效應:** Bagging 通過在多個略微不同的訓練數據集（通過 bootstrap 採樣得到）上獨立訓練多個模型，然後對它們的預測進行平均（或投票）。對多個（近似）獨立同分布的隨機變量取平均，其結果的方差會小於單個隨機變量的方差。
    *   **平滑決策邊界:** 對於分類問題，投票過程可以平滑掉單個模型可能產生的過於複雜或不穩定的決策邊界。
    因此，Bagging 對於那些本身方差較高（容易過擬合）但偏差相對較低的基礎學習器（如未剪枝的決策樹）效果尤為顯著。它通常不會顯著降低模型的偏差。

---

## 7.12 Dropout

**重點摘要:**
Dropout (Srivastava et al., 2014) 是一種非常有效且被廣泛使用的針對神經網路的正則化技術。
*   **工作原理:** 在訓練期間，對於網路的每個隱藏單元（有時也包括輸入單元），以一定的機率 `p`（例如 0.5）將其隨機地「丟棄」(drop out)，即暫時將其輸出置為零，不參與當前的前向傳播和反向傳播。每次訓練一個小批量數據時，都會隨機生成一個新的「丟棄掩碼 (dropout mask)」。在測試（推斷）時，通常不進行 Dropout，而是將所有單元的權重乘以一個與丟棄機率相關的縮放因子（例如，乘以保留機率 `1-p`，或者在訓練時對保留的單元的激活值進行相應的放大，稱為 inverted dropout）。
*   **效果:**
    1.  **防止特征之間的過度協同適應 (co-adaptation):** 由於每個單元都可能被隨機丟棄，模型不能過度依賴於任何少數幾個特定的特征，而是被迫學習更魯棒、更分散的特征表示，其中多個不同的特征組合都能夠做出正確的預測。
    2.  **近似於訓練大量共享權重的「瘦」網路的集成:** 每次應用 Dropout 都相當於從原始網路中採樣出一個不同的子網路（「瘦」網路）。整個訓練過程可以被看作是在訓練這些大量不同的子網路的集成，它們共享原始網路的權重。
    3.  **計算高效的 Bagging 近似:** Dropout 提供了一種計算上非常高效的方式來近似 Bagging 大量共享參數的神經網路的效果。
Dropout 是一種非常強大的正則化器，能夠顯著減少大型神經網路的過擬合。


**Q:** 什麼是 Dropout？它在神經網路訓練期間是如何工作的？

**A:** Dropout 是一種在訓練神經網路時用於防止過擬合的正則化技術。
*   **工作原理 (訓練期間):**
    1.  對於網路中的每個隱藏單元（有時也包括輸入單元，但更常見的是作用於隱藏層），在每次前向傳播時，以一個預先設定的機率 `p`（例如，`p=0.5`，稱為丟棄機率）隨機地將該單元「丟棄」。
    2.  被「丟棄」的單元在當前這次前向傳播和對應的反向傳播中被暫時移除，即其輸出被置為零，並且不參與梯度的計算和權重的更新。
    3.  對於每個訓練小批量 (minibatch)，都會生成一個新的隨機的「丟棄掩碼 (dropout mask)」來決定哪些單元被丟棄。
    4.  （可選，稱為 inverted dropout）為了保持激活值的期望在訓練和測試時一致，通常會在訓練時將那些**未被丟棄**的單元的激活值除以保留機率 `(1-p)`。

**Q:** 在測試（推斷）期間，Dropout 是如何處理的？

**A:** 在測試（推斷）期間，**通常不進行 Dropout**，即所有的神經單元都被保留並參與計算。
    為了補償訓練期間由於部分單元被丟棄而導致的激活值尺度的變化，有兩種常見的處理方式：
    1.  **權重縮放 (Weight Scaling):** 如果在訓練時沒有進行 inverted dropout，那麼在測試時，需要將所有隱藏單元的輸出權重乘以保留機率 `(1-p)`。
    2.  **反向 Dropout (Inverted Dropout):** 如果在訓練時已經對未被丟棄的單元的激活值除以了保留機率 `(1-p)`，那麼在測試時就不需要對權重進行任何額外的縮放，直接使用所有單元進行前向傳播即可。這是目前更常見的做法。

**Q:** Dropout 為什麼能夠起到正則化的作用，防止模型過擬合？

**A:** Dropout 能夠起到正則化作用的主要原因包括：
1.  **防止特征之間的過度協同適應 (Breaking Co-adaptation):** 由於每個隱藏單元都有可能被隨機丟棄，模型不能過度依賴於任何少數幾個特定的隱藏單元或它們之間的特定交互。它被迫學習更魯棒、更分散的特征表示，使得網路中的多個不同的子路徑都能夠對預測做出貢獻。
2.  **近似於訓練大量共享權重的子網路的集成 (Ensemble Averaging Approximation):** 每次應用 Dropout 都相當於從原始的、大的神經網路中採樣出一個不同的、更小的子網路（「瘦」網路）。整個 Dropout 訓練過程可以被看作是在並行地訓練這些大量不同的子網路，它們共享原始網路的權重。在測試時，使用所有單元（並進行適當縮放）的效果近似於對這些大量子網路的預測進行平均，這種類似於模型集成（特別是 Bagging）的效果有助於減少方差和提高泛化能力。
3.  **引入噪聲:** Dropout 的隨機性可以被看作是向網路的隱藏層激活中引入了一種乘性二元噪聲，這種噪聲有助於模型學習更魯棒的特征。

---

## 7.13 對抗訓練

**重點摘要:**
對抗訓練 (Adversarial Training) (Szegedy et al., 2014b; Goodfellow et al., 2014b) 是一種旨在提高模型對**對抗樣本 (adversarial examples)** 魯棒性的正則化方法。對抗樣本是指通過對原始輸入進行微小的、人眼難以察覺的擾動而精心構造的輸入，這些擾動能夠導致訓練好的模型以高置信度做出錯誤的預測。
*   **工作原理:** 在訓練過程中，除了使用正常的訓練樣本外，還顯式地生成對抗樣本，並將這些對抗樣本（及其正確的標籤）也加入到訓練集中，或者在損失函數中加入一個與模型在對抗樣本上表現相關的懲罰項。
    生成對抗樣本的常用方法之一是**快速梯度符號法 (Fast Gradient Sign Method, FGSM)**：`x_adv = x + ϵ * sign(∇_x J(θ, x, y))`，其中 `x` 是原始輸入，`y` 是其真實標籤，`J` 是損失函數，`ϵ` 是一個小的擾動幅度。
*   **效果:** 對抗訓練可以顯著提高模型對特定類型對抗攻擊的魯棒性，但也可能降低模型在乾淨數據上的性能，並且計算成本較高（因為需要額外生成對抗樣本並在其上進行訓練）。
對抗訓練也可以被看作是一種數據增強，但它生成的「假」數據是針對模型弱點精心設計的。


**Q:** 什麼是對抗樣本 (adversarial example)？

**A:** 對抗樣本是指那些通過對一個合法的、乾淨的輸入樣本（例如，一張圖像）添加一個經過精心設計的、通常對人類觀察者來說非常微小甚至難以察覺的擾動，從而導致一個訓練好的機器學習模型（特別是深度神經網路）以高置信度做出錯誤分類（或其他錯誤預測）的輸入樣本。

**Q:** 什麼是對抗訓練 (adversarial training)？它的主要目的是什麼？

**A:** 對抗訓練是一種旨在提高機器學習模型（特別是深度神經網路）對抗對抗樣本的**魯棒性 (robustness)** 的訓練方法。
    其主要目的是讓模型在面對這些經過精心設計的、旨在欺騙它的惡意輸入時，仍然能夠保持較高的準確性和可靠性。

**Q:** 對抗訓練是如何工作的？它與標準的監督學習有何不同？

**A:** 對抗訓練的工作原理是在標準的監督學習訓練流程中，額外地引入對抗樣本進行訓練。
    與標準的監督學習的主要不同在於**訓練數據的構成**和**損失函數的計算**：
    1.  **數據增強:** 在每個訓練迭代（或某些迭代）中，除了使用原始的乾淨訓練樣本外，還會針對當前模型生成一些對抗樣本。這些對抗樣本通常是通過對乾淨樣本添加小的、特定的擾動來產生的，這些擾動旨在最大化模型在該樣本上的損失（即最能「欺騙」模型的擾動）。
    2.  **模型訓練:** 模型被訓練來同時在乾淨樣本和這些生成的對抗樣本上都做出正確的預測。這通常意味著損失函數是計算在乾淨樣本和對抗樣本上的損失的某種組合。
    通過這種方式，模型被迫學習識別和抵抗這些對抗性擾動，從而提高其在面對類似攻擊時的魯棒性。

**Q:** 快速梯度符號法 (FGSM) 是如何生成對抗樣本的？

**A:** 快速梯度符號法 (Fast Gradient Sign Method, FGSM) 是一種簡單且計算高效的生成對抗樣本的方法。對於一個給定的輸入樣本 `x` 和其真實標籤 `y`，以及一個模型參數為 `θ`、損失函數為 `J(θ, x, y)` 的模型：
1.  計算損失函數 `J` 關於輸入 `x` 的梯度：`∇_x J(θ, x, y)`。這個梯度向量指出了如果稍微改變 `x`，能夠使損失 `J` 增加最快的方向。
2.  取這個梯度向量的符號 (sign)：`sign(∇_x J(θ, x, y))`。符號函數對向量的每個元素進行操作，如果元素為正則取 +1，為負則取 -1，為零則取 0（或 +/-1）。
3.  將這個符號向量乘以一個小的擾動幅度 `ϵ`，然後加到原始輸入 `x` 上，得到對抗樣本 `x_adv`：
    `x_adv = x + ϵ * sign(∇_x J(θ, x, y))`
    直觀上，FGSM 是在能夠使損失增加最快的方向（由梯度的符號決定）上，對輸入 `x` 的每個特征添加一個固定幅度 `ϵ` 的擾動。

---

## 7.14 切面距離、正切傳播和流形正切分類器

**重點摘要:**
另一種利用輸入空間幾何結構的正則化方法是基於對數據流形的切線信息的利用。
*   **切面距離 (Tangent Distance)** (Simard et al., 1993, 1998): 假設數據點位於低維流形上。兩個點之間的距離不僅僅是它們的歐氏距離，而是考慮到它們各自所在流形的局部切空間。如果一個點可以通過沿其流形切空間的微小移動（對應於已知的變換，如圖像的微小平移、旋轉）到達另一個點附近，則認為它們是相似的。
*   **正切傳播 (Tangent Propagation)** (Simard et al., 1992): 一種正則化策略，它鼓勵模型的輸出 `f(x)` 對於輸入 `x` 沿著數據流形切空間方向的已知變換是不變的（或者變化可控）。這通過向損失函數添加一個懲罰項來實現，該懲罰項懲罰 `f(x)` 的梯度與這些切向量的內積的平方 (公式 7.67)：
    `Ω(f) = Σ_i ( (∇f(x^(i)))^T v^(i) )^2` (其中 `v^(i)` 是在 `x^(i)` 處的切向量)
*   **流形正切分類器 (Manifold Tangent Classifier)** (Rifai et al., 2011c, 2011d): 將正切傳播的思想與自編碼器學習到的流形切空間相結合。自編碼器用於估計數據流形的切向量，然後用這些切向量來正則化一個監督分類器。


**Q:** 「切面距離 (tangent distance)」的基本思想是什麼？它如何衡量兩個數據點之間的相似性？

**A:** 「切面距離」的基本思想是，在比較兩個數據點（例如，兩張圖像）的相似性時，不僅僅考慮它們在原始高維空間中的歐氏距離，還要考慮到它們各自可能位於一個低維的數據流形上，並且可能因為一些小的、已知的變換（如平移、旋轉、縮放）而看起來不同，但本質上是相似的。
    切面距離試圖找到將一個數據點通過沿其流形切空間（即允許的微小變換方向）的移動，使其盡可能接近另一個數據點的路徑，並將這個「最短的、沿流形變換的路徑」的長度作為它們之間的距離。
    如果一個點可以通過少量的、沿流形允許的變換變成另一個點，那麼它們的切面距離就很小，即使它們的歐氏距離可能較大。

**Q:** 「正切傳播 (tangent propagation)」是如何利用數據流形的切線信息來進行正則化的？

**A:** 正切傳播是一種正則化技術，它旨在使模型的輸出對輸入數據沿著其所在數據流形的切線方向的微小變換不敏感（或者說，輸出變化可控）。
    具體做法是：
    1.  對於每個訓練樣本 `x^(i)`，識別出一些描述數據在其附近如何變化的「切向量」`v^(i)`。這些切向量代表了數據流形在 `x^(i)` 點的局部切空間的方向，通常對應於一些已知的、不改變樣本類別的小變換（例如，圖像的微小平移、旋轉）。
    2.  在模型的損失函數中添加一個正則化項，該正則化項懲罰模型的輸出函數 `f(x)` 的梯度 `∇f(x^(i))` 與這些切向量 `v^(i)` 的內積的平方。即，懲罰 `( (∇f(x^(i)))^T v^(i) )^2`。
    如果梯度與切向量的內積為零，意味著模型輸出在沿著該切向量方向移動時變化不大（即對該變換不敏感）。通過最小化這個懲罰項，正切傳播鼓勵模型學習到對這些已知的、沿流形的局部變換具有不變性的函數。

**Q:** 流形正切分類器 (manifold tangent classifier) 是如何將自編碼器與正切傳播相結合的？

**A:** 流形正切分類器將自編碼器（特別是收縮自編碼器或去噪自編碼器）學習數據流形的能力與正切傳播的正則化思想相結合。
1.  **學習流形切空間:** 首先，使用一個自編碼器（例如，收縮自編碼器，其 Jacobian 矩陣的奇異向量可以近似流形的局部基）在未標註或有標註的數據上進行訓練，以學習數據流形的局部幾何結構，特別是估計出每個數據點附近的切空間的基向量。
2.  **正則化分類器:** 然後，在訓練一個監督分類器時，使用從自編碼器中提取出的這些切向量來構造正切傳播的正則化項，以鼓勵分類器的決策邊界對沿著數據流形的這些方向的微小變換不敏感。
    這種方法的好處是，自編碼器可以從數據中自動地學習到相關的變換方向（切向量），而不需要像傳統的正切傳播那樣手動指定所有可能的變換。
