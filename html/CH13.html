<!DOCTYPE html>
<html lang="zh-Hant">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>第 13 章：線性因子模型 & 深度學習模型探索</title>
    <script src="https://cdn.tailwindcss.com?plugins=typography"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css">
    <script type="importmap">
      {
        "imports": {
          "framer-motion": "https://esm.sh/framer-motion@11.2.10"
        }
      }
    </script>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, "Noto Sans", sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
            background-color: #000000; /* File A: Apple's deep black */
            color: #f5f5f7; /* File A: Apple's off-white */
            overflow-x: hidden;
        }

        .bento-grid {
            display: grid;
            gap: 1.5rem; 
            padding: 1.5rem; 
            max-width: 1280px; 
            margin: 0 auto;
        }

        .bento-item {
            background-color: #1d1d1f; /* File A: Apple's dark gray for elements */
            border-radius: 20px; /* File A: Softer radius */
            padding: 2rem; /* File A: Padding */
            overflow: hidden;
            position: relative;
            box-shadow: 0 10px 20px rgba(0,0,0,0.1), 0 3px 6px rgba(0,0,0,0.08); /* File B shadow */
            transition: transform 0.3s ease-out, box-shadow 0.3s ease-out; /* File B transition */
            display: flex;
            flex-direction: column;
            justify-content: space-between; /* File B: Pushes content and footer apart */
            opacity: 0; /* Initial state for animation */
        }

        .bento-item:hover { 
            transform: translateY(-5px); /* File B hover */
            box-shadow: 0 15px 30px rgba(0,0,0,0.15), 0 5px 10px rgba(0,0,0,0.1); /* File B hover shadow */
        }

        /* Highlight Gradients from File A */
        .highlight-gradient-blue {
            background: linear-gradient(45deg, rgba(0, 122, 255, 0.7), rgba(0, 122, 255, 0.3));
            color: #f5f5f7;
        }
        .highlight-gradient-green {
            background: linear-gradient(45deg, rgba(52, 199, 89, 0.7), rgba(52, 199, 89, 0.3));
            color: #f5f5f7;
        }
        .highlight-gradient-orange {
            background: linear-gradient(45deg, rgba(255, 149, 0, 0.7), rgba(255, 149, 0, 0.3));
            color: #f5f5f7;
        }
        /* Highlight Gradient from File B */
        .highlight-gradient-general-blue { /* Renamed to avoid conflict if File A's is also generic blue */
            background-image: linear-gradient(to bottom right, rgba(0, 122, 255, 0.3), rgba(0, 122, 255, 0.05));
            color: #f5f5f7;
        }


        h1, h2, h3, h4 { 
            font-weight: 600;
            color: #f5f5f7; 
        }
        
        /* Main Page Header Typography */
        .page-main-title { 
            font-size: 2.8rem; /* Adjusted from File A's .chinese-title (2.5rem) and File B's header (5xl) */
            line-height: 1.2;
            font-weight: 700; 
            margin-bottom: 0.5rem; 
            color: #f5f5f7;
            opacity: 0; 
        }
         .page-main-title a {
            color: inherit; /* Make link color same as text */
            text-decoration: none;
             background-image: linear-gradient(to right, #60a5fa, #34d399);
             background-clip: text;
            -webkit-background-clip: text;
            color: transparent;
        }
        .page-main-title a:hover {
            background-image: linear-gradient(to right, #3b82f6, #10b981);
        }
        .page-english-sub { 
            font-size: 1.2rem; /* Adjusted */
            color: #86868b; /* File A .english-sub */
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 0.75rem;
            opacity: 0; 
        }
         .page-presenter-info { 
            color: #86868b; /* File A .text-apple-gray */
            font-size: 1rem;
            opacity: 0; 
        }

        /* Section Hero Typography (for File B's intro) */
        .section-hero-title {
            font-size: 2.2rem; /* Adjusted */
            font-weight: 700;
            color: #f5f5f7;
            margin-bottom: 0.5rem;
            opacity: 0;
        }
        .section-hero-subtitle {
            font-size: 1.1rem;
            color: #86868b; /* text-apple-medium-gray */
            max-width: 48rem; /* max-w-3xl */
            margin-left: auto;
            margin-right: auto;
            opacity: 0;
        }


        /* Typography for Bento Item Content */
        .bento-item .item-title-main { 
            font-size: 1.8rem; /* File A .chinese-subtitle */
            font-weight: 600;
            line-height: 1.3;
            color: #f5f5f7;
            margin-bottom: 0.25rem;
        }
        .bento-item .item-title-sub-eng { 
            font-size: 0.9rem; /* File A .english-sub */
            color: #86868b;
            text-transform: uppercase;
            letter-spacing: 0.05em;
            margin-bottom: 0.75rem;
        }
        .bento-item .item-text-primary { 
            font-size: 1rem; 
            color: #d2d2d7; /* File A .text-apple-light-gray */
            line-height: 1.6;
        }
        .bento-item .item-text-secondary { 
            font-size: 0.875rem; 
            color: #86868b; /* File A .text-apple-gray */
        }
        .bento-item .item-footer-text { /* For small text at bottom of File B cells */
             margin-top: auto; /* Pushes to bottom because of flex-direction column and justify-content space-between */
             padding-top: 1rem;
             text-align: right;
             font-size: 0.75rem; /* text-xs */
             color: #6c6c70; /* text-apple-medium-gray/70 like */
        }
        

        /* Icons */
        .icon-large { /* General large icon for items from File A */
            font-size: 3rem; 
            margin-bottom: 1rem;
            opacity: 0.8; 
            color: rgba(0, 122, 255, 0.8); /* File A's blue for icons */
        }
        .icon-bg { /* From File B */
            width: 60px;
            height: 60px;
            border-radius: 12px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 1rem;
        }
        
        .bento-item img { /* Base img styling */
            border-radius: 0.75rem; 
            object-fit: contain;
            max-height: 350px; 
            margin: 1rem auto;
            display: block;
        }

        /* Formula Styling (Monospaced) */
        .formula { 
            background-color: #2c2c2e; 
            padding: 1rem;
            border-radius: 10px; 
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace; 
            font-size: 1.05rem; 
            color: #f5f5f7;
            overflow-x: auto;
            margin: 1rem 0;
            border: 1px solid #4a4a4e;
        }
        .formula code, .bento-item code { /* General code tag styling */
            background-color: #4a4a4c;
            padding: 0.2em 0.4em;
            margin: 0;
            font-size: 85%;
            border-radius: 3px;
            font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, Courier, monospace;
        }
        
        /* List styling with Font Awesome check from File A */
        .bento-item ul.fa-ul { 
            list-style: none;
            padding-left: 0;
        }
        .bento-item ul.fa-ul li {
            padding-left: 1.75em; /* Space for the icon + a bit more */
            position: relative;
            margin-bottom: 0.5em;
            color: #d2d2d7; 
        }
        .bento-item ul.fa-ul li::before {
            content: "\f00c"; 
            font-family: "Font Awesome 6 Free";
            font-weight: 900; 
            position: absolute;
            left: 0;
            top: 0.1em; 
            color: rgba(0, 122, 255, 0.8); 
        }
        /* Standard list for other cases */
         .bento-item ul:not(.fa-ul) {
            list-style: disc;
            padding-left: 1.5rem; 
            margin-top: 0.5rem;
            margin-bottom: 0.5rem;
            color: #d2d2d7; 
        }
         .bento-item ol {
            list-style-type: decimal;
            padding-left: 1.5rem;
            margin-top: 0.5rem;
            margin-bottom: 0.5rem;
            color: #d2d2d7; 
        }


        /* Diagram Placeholder from File A */
        .diagram-placeholder {
            border: 1px dashed #444;
            padding: 1rem;
            text-align: center;
            color: #6c6c70; 
            min-height: 100px; 
            display: flex;
            align-items: center;
            justify-content: center;
            flex-direction: column;
            border-radius: 10px; 
            margin-top: 0.5rem;
            background-color: #232325; 
        }
        
        /* Grid layout */
        @media (min-width: 768px) { /* md screens */
            .bento-grid {
                grid-template-columns: repeat(3, 1fr); /* Default to 3 columns on medium */
            }
            .bento-item.md-col-span-1 { grid-column: span 1 / span 1; }
            .bento-item.md-col-span-2 { grid-column: span 2 / span 2; }
            .bento-item.md-col-span-3 { grid-column: span 3 / span 3; }
        }
        @media (min-width: 1024px) { /* lg screens */
            .bento-grid {
                grid-template-columns: repeat(4, 1fr); /* Up to 4 columns on large */
            }
            .bento-item.lg-col-span-1 { grid-column: span 1 / span 1; }
            .bento-item.lg-col-span-2 { grid-column: span 2 / span 2; }
            .bento-item.lg-col-span-3 { grid-column: span 3 / span 3; }
            .bento-item.lg-col-span-4 { grid-column: span 4 / span 4; }
            /* Row spans for File B items */
            .bento-item.lg-row-span-2 { grid-row: span 2 / span 2; }
        }
    </style>
</head>

<body class="antialiased"> 
    <header class="text-center py-12 md:py-16 px-6">
        <h1 class="page-main-title text-5xl md:text-6xl">
            <a href="https://deep-learning-101.github.io/" target="_blank" rel="noopener noreferrer">
                第 13 章：線性因子模型
            </a>
        </h1>
        <p class="page-english-sub text-xl md:text-2xl">Chapter 13: Linear Factor Models</p>
        <p class="page-presenter-info text-md md:text-lg">
            主講人：呂寧遠 (Ning-Yuan Lyu) | 日期：2017.08.11
        </p>
    </header>

    <main class="bento-grid">
        <section class="bento-item md-col-span-2 lg-col-span-2" data-custom="0">
            <i class="fas fa-stream icon-large"></i>
            <div>
                <h2 class="item-title-main">13.1 機率性 PCA 與因子分析</h2>
                <p class="item-title-sub-eng">Probabilistic PCA and Factor Analysis</p>
                <p class="item-text-primary mb-4">本節探討將主成分分析 (PCA) 與因子分析 (Factor Analysis) 框架擴展至機率模型的概念，並介紹相關的估計方法。</p>
                <ul class="fa-ul">
                    <li><strong>機率模型</strong> (Probabilistic model)</li>
                    <li><strong>PPCA 的最大概似法</strong> (Maximum likelihood approach for PPCA)</li>
                    <li><strong>EM 演算法</strong> (EM algorithm)</li>
                </ul>
            </div>
            <p class="item-text-secondary mt-3 text-sm">
                演講者說明：將介紹 PCA 和因子分析的機率模型，並使用最大概似法 (ML) 和期望最大化 (EM) 演算法來估計參數，特別適用於潛在變數模型。
            </p>
        </section>

        <section class="bento-item md-col-span-1 lg-col-span-2 highlight-gradient-blue" data-custom="1">
            <i class="fas fa-project-diagram icon-large"></i>
            <div>
                <h3 class="item-title-main">機率性 PCA (PPCA) 模型</h3>
                <p class="item-title-sub-eng">Probabilistic PCA Model</p>
                <div class="formula">x = Wh + b + ε</div>
                <p class="item-text-primary text-sm mb-2"><strong>假設 (Assumptions):</strong></p>
                <ul class="fa-ul text-sm">
                    <li>潛在變數 h: h ~ N(0, I)</li>
                    <li>雜訊 ε: ε ~ N(0, σ²I)</li>
                    <li>觀測變數 x (h 邊際化後): x ~ N(b, WWᵀ + σ²I)</li>
                </ul>
                <p class="item-text-primary text-sm mt-2"><strong>維度:</strong> h: d x 1, x & ε: n x 1, W: n x d</p>
            </div>
            <div class="diagram-placeholder mt-auto"> {/* Pushed to bottom */}
                <i class="fas fa-brain text-2xl mb-2"></i>
                圖形模型：hᵢ → xᵢ (受 W, b, σ² 影響)
                <p class="text-xs mt-1">(Graphical Model: hᵢ influences xᵢ via W, b, σ²)</p>
            </div>
        </section>

        <section class="bento-item md-col-span-3 lg-col-span-4" data-custom="2">
            <i class="fas fa-chart-line icon-large"></i>
            <div>
                <h3 class="item-title-main">PPCA 模型視覺化</h3>
                <p class="item-title-sub-eng">PPCA Model Visualization (13.1.1-picture)</p>
                <div class="grid grid-cols-1 md:grid-cols-3 gap-4">
                    <div class="diagram-placeholder">
                        <p><strong>步驟 1：</strong>潛在變數 p(h)</p>
                        <p class="text-xs">(Step 1: Latent variable p(h) - 1D Gaussian)</p>
                        <i class="fas fa-wave-square mt-2 text-xl"></i>
                    </div>
                    <div class="diagram-placeholder">
                        <p><strong>步驟 2：</strong>線性轉換 Wh + b</p>
                        <p class="text-xs">(Step 2: Linear transformation Wh + b - maps 1D h to 2D line)</p>
                        <i class="fas fa-long-arrow-alt-right mt-2 text-xl"></i>
                    </div>
                    <div class="diagram-placeholder">
                        <p><strong>步驟 3：</strong>加入雜訊 p(x)</p>
                        <p class="text-xs">(Step 3: Add noise, resulting p(x) - elliptical distribution)</p>
                        <i class="fas fa-bullseye mt-2 text-xl"></i>
                    </div>
                </div>
            </div>
            <p class="item-text-secondary mt-3 text-sm">
                演講者說明：1D 潛在變數 h 經過線性轉換和加入等向性高斯雜訊後，在高維觀測空間 x 中形成一個橢圓狀分佈。
            </p>
        </section>

        <section class="bento-item md-col-span-1 lg-col-span-2 highlight-gradient-green" data-custom="3">
            <i class="fas fa-sitemap icon-large"></i>
            <div>
            <h3 class="item-title-main">因子分析模型</h3>
            <p class="item-title-sub-eng">Factor Analysis Model (13.1.2)</p>
            <div class="formula">x = Wh + b + ε</div>
            <p class="item-text-primary text-sm mb-2"><strong>主要差異 (Key Difference from PPCA):</strong></p>
            <ul class="fa-ul text-sm">
                <li>雜訊 ε: ε ~ N(0, Ψ)</li>
                <li>其中 Ψ = diag(σ₁², σ₂², ..., σₙ²)</li>
                <li>觀測變數 x: x ~ N(b, WWᵀ + Ψ)</li>
            </ul>
            </div>
            <p class="item-text-secondary mt-3 text-sm">
                演講者說明：因子分析與 PPCA 類似，但其雜訊的共變異數矩陣 Ψ 是對角矩陣，允許各觀測維度有不同的雜訊變異數。
            </p>
        </section>

        <section class="bento-item md-col-span-2 lg-col-span-2" data-custom="4">
            <i class="fas fa-calculator icon-large"></i>
            <div>
            <h3 class="item-title-main">平均值與共變異數</h3>
            <p class="item-title-sub-eng">Mean and Covariance (13.1.2)</p>
            <p class="item-text-primary mb-2">對於因子分析模型：</p>
            <div class="formula">E[x] = b</div>
            </div>
            <div class="formula mt-auto">Cov(x) = E[xxᵀ] - E[x]E[x]ᵀ = WWᵀ + Ψ</div>
        </section>

        <section class="bento-item md-col-span-3 lg-col-span-4" data-custom="5">
            <i class="fas fa-infinity icon-large"></i>
            <div>
            <h3 class="item-title-main">PPCA 的最大概似法</h3>
            <p class="item-title-sub-eng">Maximum Likelihood for PPCA (13.1.3)</p>
            <p class="item-text-primary mb-2">PPCA 的對數概似函數 (Log-likelihood):</p>
            <div class="formula text-xs">
                LL = Σᵢ<sup>N</sup> ln[p(xᵢ|b,W,σ²)] = - (Nd/2)ln(2π) - (N/2)ln|C| - (1/2)Σᵢ<sup>N</sup>(xᵢ-b)ᵀC⁻¹(xᵢ-b)
            </div>
            <p class="item-text-primary text-sm mb-1">其中 C = WWᵀ + σ²I.</p>
            <p class="item-text-primary text-sm mb-2">對於 PPCA，參數 b, W, σ² 存在解析解:</p>
            <ul class="fa-ul text-sm item-text-primary">
                <li>b = (1/N) Σ xᵢ (樣本平均值)</li>
                <li>W = Uₘ(Lₘ - σ²I)¹ᐟ² R </li>
                <li>σ² = (1/(d-m)) Σ (j=m+1 to d) λⱼ </li>
            </ul>
            </div>
            <p class="item-text-secondary mt-3 text-sm">
                演講者說明：當雜訊變異數 σ² → 0 時，PPCA 模型會收斂至標準 PCA。 (Uₘ: 前 m 特徵向量, Lₘ: 特徵值, R: 旋轉矩陣)
            </p>
        </section>

        <section class="bento-item md-col-span-2 lg-col-span-2" data-custom="6">
            <i class="fas fa-sync-alt icon-large"></i>
            <div>
            <h3 class="item-title-main">EM 演算法</h3>
            <p class="item-title-sub-eng">EM Algorithm (13.1.4)</p>
            <p class="item-text-primary mb-2"><strong>為何需要 EM:</strong></p>
            <ul class="fa-ul text-sm item-text-primary">
                <li>減少計算複雜度</li>
                <li>因子分析無解析解</li>
            </ul>
            <p class="item-text-primary text-sm mt-2 mb-1"><strong>EM 方法回顧:</strong></p>
            <div class="formula text-xs">ln(p(x)) = ELBO + KL Divergence</div>
            </div>
            <div class="diagram-placeholder mt-auto">
                <i class="fas fa-chart-bar text-2xl mb-2"></i>
                E-step: 固定參數，更新 q(z) 使 KL=0。<br/>M-step: 固定 q(z)，最大化 ELBO 更新參數。
            </div>
        </section>

        <section class="bento-item md-col-span-1 lg-col-span-2 highlight-gradient-orange" data-custom="7">
            <i class="fas fa-cogs icon-large"></i>
            <div>
            <h3 class="item-title-main">PPCA/因子分析的 EM 步驟</h3>
            <p class="item-title-sub-eng">EM for PPCA and Factor Analysis (13.1.4)</p>
            <p class="item-text-primary mb-2"><strong>E-步驟:</strong> 固定參數，評估 q(hᵢ) = p(hᵢ|xᵢ, θ_old)</p>
            <ul class="fa-ul text-sm item-text-primary"><li>計算 E[hᵢ] 和 E[hᵢhᵢᵀ]</li></ul>
            <p class="item-text-primary text-sm mt-2 mb-1"><strong>M-步驟:</strong> 固定 q(hᵢ)，最大化參數</p>
            <ul class="fa-ul text-sm item-text-primary"><li>更新 W_new, σ²_new (或 Ψ_new)</li></ul>
            </div>
            <p class="item-text-secondary mt-3 text-sm">
                演講者說明：E-步驟計算潛在變數的後驗期望。M-步驟使用這些期望來更新模型參數。
            </p>
        </section>

        <section class="bento-item md-col-span-3 lg-col-span-4" data-custom="8">
            <i class="fas fa-random icon-large"></i>
            <div>
            <h2 class="item-title-main">13.2 獨立成分分析 (ICA)</h2>
            <p class="item-title-sub-eng">Independent Component Analysis</p>
            <p class="item-text-primary mb-4">ICA 旨在將多變量信號分解為統計上獨立的非高斯子成分。</p>
            <ul class="fa-ul item-text-primary">
                <li><strong>簡要介紹</strong> (Brief introduction)</li>
                <li><strong>ICA 的條件</strong> (Conditions for ICA)</li>
                <li><strong>非高斯性度量</strong> (Measure of non-Gaussianity)</li>
                <li><strong>互信息觀點</strong> (Mutual information view point)</li>
            </ul>
            </div>
        </section>

        <section class="bento-item md-col-span-2 lg-col-span-2 highlight-gradient-blue" data-custom="9">
            <i class="fas fa-puzzle-piece icon-large"></i>
            <div>
            <h3 class="item-title-main">ICA 問題定義</h3>
            <p class="item-title-sub-eng">ICA Problem Definition</p>
            <p class="item-text-primary mb-2">觀測 x 是未知、獨立非高斯變數 h 的線性組合。目標是獲取 W (或 A) 及 h。</p>
            <div class="formula">x = Wh  或  x = Ah</div>
            <p class="item-text-primary text-sm mb-1"><strong>假設:</strong> &lt;xᵢ&gt; = 0, &lt;hⱼ&gt; = 0 (零均值)</p>
            <p class="item-text-primary text-sm mb-1"><strong>機率模型:</strong></p>
            <ul class="fa-ul text-sm item-text-primary">
                <li>p(h) = Πᵢ p(hᵢ) (源信號獨立)</li>
                <li>p(hᵢ) is non-Gaussian</li>
                <li>p(x) = (1/|det(A)|) p(h)</li>
            </ul>
            </div>
        </section>

        <section class="bento-item md-col-span-1 lg-col-span-2" data-custom="10">
            <i class="fas fa-microchip icon-large"></i>
            <div>
            <h3 class="item-title-main">ICA 應用</h3>
            <p class="item-title-sub-eng">ICA Applications (13.2.1)</p>
            <p class="item-text-primary mb-2">ICA 通常用於恢復低階混合信號。</p>
            <ul class="fa-ul text-sm item-text-primary">
                <li><strong>MEG 數據中偽影分離</strong></li>
                <li><strong>自然圖像降噪</strong></li>
                <li><strong>金融數據中尋找隱藏因子</strong></li>
            </ul>
            </div>
            <div class="grid grid-cols-2 gap-2 mt-auto">
                <div class="diagram-placeholder text-xs">MEG: 混合(左) vs. 分離(右)</div>
                <div class="diagram-placeholder text-xs">圖像: 原始 vs. 含噪 vs. ICA降噪</div>
            </div>
        </section>

        <section class="bento-item md-col-span-1 lg-col-span-1" data-custom="11">
            <i class="fas fa-unlink icon-large"></i>
            <div>
            <h3 class="item-title-main">何謂「獨立」?</h3>
            <p class="item-title-sub-eng">What is "Independent"? (13.2.2)</p>
            <div class="formula text-sm">p(hᵢ, hⱼ) = p(hᵢ)p(hⱼ)</div>
            <p class="item-text-primary text-sm mb-1">意味著:</p>
            <div class="formula text-sm">E[f(hᵢ)g(hⱼ)] = E[f(hᵢ)]E[g(hⱼ)]</div>
            </div>
            <p class="item-text-primary text-sm mt-auto">「不相關」: E[hᵢhⱼ] - E[hᵢ]E[hⱼ] = 0 <span class="item-text-secondary text-xs">(不相關 ≠ 獨立)</span></p>
        </section>

        <section class="bento-item md-col-span-2 lg-col-span-3 highlight-gradient-green" data-custom="12">
            <i class="fas fa-check-double icon-large"></i>
            <div>
            <h3 class="item-title-main">ICA 的條件 / 可分離源</h3>
            <p class="item-title-sub-eng">Conditions for ICA / Separable Sources (13.2.4)</p>
            <ol class="list-decimal list-inside item-text-primary text-sm space-y-1">
                <li><strong>模糊性:</strong> x = ((1/k)W)(kh). 需指定 E[hᵢ²] = 1 (源信號單位變異數)。</li>
                <li><strong>非高斯性:</strong> 需要非高斯隨機變數才能分離。最多只能有一個 hᵢ 是高斯分佈。</li>
                <li><strong>線性組合:</strong> 若 y = Σ aᵢxᵢ = zᵀh，且 y 對應高斯性的局部最小值，則 z 中只有一個元素非零。</li>
            </ol>
            </div>
        </section>

        <section class="bento-item md-col-span-3 lg-col-span-2" data-custom="13">
            <i class="fas fa-ruler-combined icon-large"></i>
            <div>
            <h3 class="item-title-main">非高斯性度量</h3>
            <p class="item-title-sub-eng">Measure of non-Gaussianity (13.2.5)</p>
            <p class="item-text-primary mb-1"><strong>1. 峰度 (Kurtosis):</strong></p>
            <ul class="fa-ul item-text-primary text-sm">
                <li>若 y 高斯分佈, kurt(y) = 0。</li>
                <li>kurt(y) = E[y⁴] - 3(E[y²])²</li>
                <li>缺點：對離群值不穩健。</li>
            </ul>
            <p class="item-text-primary mt-2 mb-1"><strong>2. 負熵 (Negentropy):</strong></p>
            <ul class="fa-ul item-text-primary text-sm">
                <li>若 y 高斯分佈, J[y] = 0。</li>
                <li>J[y] = H[y_gauss] - H[y] ≥ 0</li>
            </ul>
            <p class="item-text-primary mt-2 mb-1"><strong>近似負熵:</strong></p>
            <div class="formula text-xs"> J[y] ≈ Σᵢ kᵢ [E[Gᵢ(y<sub>gauss</sub>)]-E[Gᵢ(y)]]² </div>
            <p class="item-text-primary text-sm">常用 G(y): (1/a₁) ln(cosh(a₁y)) 或 -exp(-y²/2)</p>
            </div>
        </section>

        <section class="bento-item md-col-span-3 lg-col-span-2 highlight-gradient-orange" data-custom="14">
            <i class="fas fa-info-circle icon-large"></i>
            <div>
            <h3 class="item-title-main">互信息</h3>
            <p class="item-title-sub-eng">Mutual Information (13.2.6)</p>
            <p class="item-text-primary mb-2">最小化互信息方法:</p>
            <div class="formula text-sm">I(y₁, ..., yₘ) = Σᵢ H[yᵢ] - H[y₁, ..., yₘ]</div>
            <p class="item-text-primary text-sm mt-3"><strong>結論:</strong></p>
            <p class="item-text-primary text-sm">最小化互信息 I(y₁, ..., yₘ) 等價於最大化總負熵 Σ J[yᵢ]。</p>
            </div>
            <p class="item-text-secondary mt-2 text-xs text-right">Note: I(x,y) = H(x) + H(y) - H(x,y)</p>
        </section>

        <section class="text-center my-10 md:my-12 md-col-span-3 lg-col-span-4" data-custom="15">
            <h1 class="section-hero-title text-4xl md:text-5xl">探索線性因子模型</h1>
            <p class="section-hero-subtitle text-lg md:text-xl mt-2">深入理解 PCA, ICA, SFA 及稀疏編碼等無監督學習方法</p>
        </section>

        <section class="bento-item lg-col-span-2 lg-row-span-2 flex flex-col items-center justify-center text-center" data-custom="16">
            <div class="icon-bg bg-blue-500/20">
                <i class="fas fa-project-diagram text-3xl text-blue-400"></i> </div>
            <h2 class="item-title-main text-3xl md:text-4xl">線性因子模型</h2>
            <p class="item-title-sub-eng text-blue-400">Linear Factor Models</p>
            <p class="item-text-secondary text-lg leading-relaxed">
                本章節探討一系列用於從高維數據中提取潛在結構與表徵的無監督學習模型。這些模型旨在發現數據中更簡潔、更有意義的低維表示。
            </p>
        </section>

        <section class="bento-item" data-custom="17">
            <div>
                <div class="icon-bg bg-green-500/20">
                    <i class="fas fa-chart-pie text-3xl text-green-400"></i>
                </div>
                <h3 class="item-title-main">主成分分析 (PCA)</h3>
                <p class="item-title-sub-eng text-green-400">Principal Component Analysis & Probabilistic PCA</p>
                <p class="item-text-secondary text-sm mb-2">
                    <strong>目標：</strong>降維，找到數據變異最大的方向。
                </p>
                <ul class="fa-ul text-sm item-text-secondary space-y-1">
                    <li>將數據投影到低維子空間。</li>
                    <li><strong>機率PCA (PPCA)：</strong>為PCA引入機率模型，允許噪聲並能生成數據。當噪聲 <code class="text-xs">σ² → 0</code> 時，PPCA趨近於標準PCA。</li>
                </ul>
            </div>
            <div class="item-footer-text">Dimensionality Reduction</div>
        </section>

        <section class="bento-item" data-custom="18">
            <div>
                <div class="icon-bg bg-purple-500/20">
                    <i class="fas fa-unlink text-3xl text-purple-400"></i>
                </div>
                <h3 class="item-title-main">獨立成分分析 (ICA)</h3>
                <p class="item-title-sub-eng text-purple-400">Independent Component Analysis</p>
                <p class="item-text-secondary text-sm mb-2">
                    <strong>目標：</strong>將混合信號分離成統計上獨立的原始信號。
                </p>
                <ul class="fa-ul text-sm item-text-secondary space-y-1">
                    <li>最小化互信息等價於最大化總負熵。</li>
                    <li>旨在使輸出分量盡可能非高斯化。</li>
                    <li>應用於盲信號分離。</li>
                </ul>
            </div>
            <div class="item-footer-text">Signal Separation</div>
        </section>

        <section class="bento-item lg-col-span-2 lg-row-span-2 highlight-gradient-general-blue" data-custom="19">
            <div>
                <div class="icon-bg bg-orange-500/20">
                    <i class="fas fa-th-large text-3xl text-orange-400"></i>
                </div>
                <h3 class="item-title-main text-3xl md:text-4xl">稀疏編碼</h3>
                <p class="item-title-sub-eng text-orange-400">Sparse Coding</p>
                <p class="item-text-secondary text-base mb-3">
                    <strong>核心思想：</strong>用少量「基函數」的線性組合來表示輸入數據，同時保持用於組合的「隱變量」稀疏。
                </p>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-4 text-sm">
                    <div>
                        <h4 class="font-semibold item-text-primary mb-1">成本函數最小化</h4>
                        <p class="item-text-secondary text-xs">目標：<code>min Σ ||x⁽ⁿ⁾ - Σ hᵢ⁽ⁿ⁾φᵢ||² + λ Σ S(hᵢ⁽ⁿ⁾)</code></p>
                        <ul class="fa-ul item-text-secondary/80 mt-1 pl-2 text-xs">
                            <li>重建成本。</li>
                            <li>稀疏性成本 (e.g. <code>S(hᵢ) = |hᵢ|</code>)。</li>
                            <li>常使用超完備基 (k > d)。</li>
                        </ul>
                    </div>
                    <div>
                        <h4 class="font-semibold item-text-primary mb-1">機率模型觀點</h4>
                        <p class="item-text-secondary text-xs"><code>x = Σ hᵢφᵢ + ε</code></p>
                        <ul class="fa-ul item-text-secondary/80 mt-1 pl-2 text-xs">
                            <li><code>ε</code>：高斯噪聲 <code>N(0, σ²I)</code>。</li>
                            <li><code>p(h)</code>：隱變量的稀疏先驗 (如拉普拉斯)。</li>
                        </ul>
                    </div>
                </div>
                <p class="item-text-secondary text-base mt-3">
                    <strong>應用範例：</strong>稀疏編碼自編碼器可學習類似邊緣檢測器特徵。
                </p>
            </div>
            <div class="item-footer-text">Feature Learning & Representation</div>
        </section>

        <section class="bento-item" data-custom="20">
            <div>
                <div class="icon-bg bg-teal-500/20">
                    <i class="fas fa-hourglass-half text-3xl text-teal-400"></i>
                </div>
                <h3 class="item-title-main">慢特徵分析 (SFA)</h3>
                <p class="item-title-sub-eng text-teal-400">Slow Feature Analysis</p>
                <p class="item-text-secondary text-sm mb-2">
                    <strong>慢度原則：</strong>場景的重要特徵變化緩慢。
                </p>
                <ul class="fa-ul text-sm item-text-secondary space-y-1">
                    <li>目標是學習隨時間變化最慢的特徵。</li>
                    <li>成本函數懲罰特徵在相鄰時間步長間的快速變化: <code>Eₜ[(fᵢ(x(t+1)) - fᵢ(x(t)))²]</code>。</li>
                </ul>
            </div>
            <div class="item-footer-text">Temporal Coherence</div>
        </section>

        <section class="bento-item" data-custom="21">
            <div>
                <div class="icon-bg bg-indigo-500/20">
                    <i class="fas fa-map-marked-alt text-3xl text-indigo-400"></i>
                </div>
                <h3 class="item-title-main">拓撲ICA與其他</h3>
                <p class="item-title-sub-eng text-indigo-400">Topographic ICA & Other Concepts</p>
                <ul class="fa-ul text-sm item-text-secondary space-y-1">
                    <li><strong>拓撲ICA：</strong>學習特徵按相似性排列。</li>
                    <li><strong>NICE：</strong>堆疊一系列可逆轉換。</li>
                    <li><strong>獨立子空間分析：</strong>組內相關，組間獨立。</li>
                </ul>
                <p class="item-text-secondary text-sm mt-2">
                    共同目標是從複雜數據中提取有結構、有意義的低維表示。
                </p>
            </div>
            <div class="item-footer-text">Advanced Representations</div>
        </section>


    </main>

    <footer class="text-center py-8 mt-8 border-t border-gray-700">
        <p class="item-text-secondary text-sm">Presentations by Ning-Yuan Lyu (2017) & others. Compiled notes © 2024-2025.</p>
    </footer>

    <script type="module">
        import { animate } from "framer-motion";

        document.addEventListener('DOMContentLoaded', () => {
            // console.log("DOM fully loaded. Starting animation setup.");

            const elementsToAnimate = [
                document.querySelector('header h1.page-main-title'),
                document.querySelector('header p.page-english-sub'),
                document.querySelector('header p.page-presenter-info'),
                document.querySelector('section.text-center h1.section-hero-title'), 
                document.querySelector('section.text-center p.section-hero-subtitle'),
                ...document.querySelectorAll('.bento-item')
            ].filter(el => {
                if (el == null) {
                    // console.warn("A selector returned null. Check HTML class/tag names.");
                }
                return el != null;
            });
            
            // console.log(`Found ${elementsToAnimate.length} elements to animate.`);

            elementsToAnimate.forEach((el, index) => {
                const elementId = el.id || el.className.split(" ")[0] || el.tagName; 
                
                let delayOrder = index; // Default for header elements
                if (el.dataset.custom) { // Prioritize data-custom if present
                    delayOrder = parseInt(el.dataset.custom);
                }
                
                const initialY = (el.tagName.startsWith('H') || el.classList.contains('page-main-title') || el.classList.contains('section-hero-title')) ? -20 : 20;
                
                el.style.opacity = 0; // Ensure initial opacity is 0

                const observer = new IntersectionObserver(entries => {
                    entries.forEach(entry => {
                        const entryId = entry.target.id || entry.target.className.split(" ")[0] || entry.target.tagName;
                        if (entry.isIntersecting) {
                            // console.log(`Animating: ${entryId}`);
                            animate(entry.target, 
                                { opacity: [0, 1], y: [initialY, 0] }, 
                                { duration: 0.5, delay: delayOrder * 0.065 } 
                            ).catch(error => {
                                console.error(`Animation error for ${entryId}:`, error);
                            });
                            observer.unobserve(entry.target); 
                        }
                    });
                }, { threshold: 0.05 }); 
                
                observer.observe(el);
            });
        });
    </script>
</body>
</html>
