<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>	NLP Landing & Machine Reading Comprehension</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
    <style>
        body {
            background-color: #0d1117; /* GitHub dark background */
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji";
            margin: 0;
            padding: 1rem;
        }

        .bento-grid {
            display: grid;
            gap: 1rem; /* Default gap */
            padding: 1rem;
            max-width: 1400px; /* Adjust as needed */
            margin: auto;
        }

        .bento-item {
            background-color: #161b22; /* GitHub darker gray for boxes */
            border: 1px solid #30363d; /* GitHub border color */
            border-radius: 0.75rem; /* Tailwind: rounded-xl */
            padding: 1.75rem; /* Tailwind: p-7 */
            display: flex;
            flex-direction: column;
            box-shadow: 0 8px 24px rgba(0,0,0,0.3); /* Slightly stronger shadow */
            position: relative;
            overflow: hidden;
        }
        .bento-item h2 {
            font-size: 1.875rem; /* Adjusted to be slightly smaller than 4xl for balance */
            font-weight: 600; /* Tailwind: font-semibold */
            margin-bottom: 1rem; /* Tailwind: mb-4 */
            color: #e6edf3; /* GitHub lighter gray for titles */
        }
        .bento-item h2 strong { /* For emphasis like in the first file */
            font-weight: 700;
        }
        .bento-item h3 {
            font-size: 1.25rem; /* Tailwind: text-xl */
            font-weight: 500; /* Tailwind: font-medium */
            margin-top: 1rem;
            margin-bottom: 0.5rem; /* Tailwind: mb-2 */
            color: #8b949e; /* GitHub medium gray for sub-titles */
        }
        .bento-item p, .bento-item li {
            font-size: 1rem; /* Adjusted to match first file's base, second was 1.125rem */
            color: #adb5bd; /* Lighter medium gray for body text */
            line-height: 1.7;
        }
        .bento-item ul, .bento-item ol {
            padding-left: 1.5rem; /* Indent lists */
            margin-top: 0.5rem;
            margin-bottom: 0.5rem;
        }
        .bento-item ul.list-inside, .bento-item ol.list-inside {
             padding-left: 0; /* Reset for list-inside if needed */
        }
         .bento-item .list-disc { list-style-type: disc; }
         .bento-item .list-decimal { list-style-type: decimal; }
         .bento-item .list-circle { list-style-type: circle; }
         .bento-item .space-y-1 > * + * { margin-top: 0.25rem; }
         .bento-item .space-y-2 > * + * { margin-top: 0.5rem; }
         .bento-item .ml-4 { margin-left: 1rem; }


        .bento-item .icon {
            font-size: 2.5rem; /* Adjusted, 3rem felt a bit large for all contexts */
            color: #58a6ff; /* GitHub blue */
            margin-bottom: 1rem; /* Adjusted */
            align-self: flex-start;
        }
        .highlight-text {
            background: linear-gradient(to right, rgba(88, 166, 255, 0.4), rgba(88, 166, 255, 0.1));
            padding: 0.1em 0.35em;
            border-radius: 0.3rem;
            color: #c9d1d9;
        }
        .pill {
            background-color: #21262d; /* GitHub darker pill background */
            color: #8b949e;
            padding: 0.3rem 0.8rem;
            border-radius: 9999px;
            font-size: 0.875rem; /* Match first file's base */
            display: inline-block;
            margin-right: 0.5rem; /* Match first file */
            margin-bottom: 0.5rem; /* Match first file */
            border: 1px solid #30363d;
        }
        .code-block {
            background-color: #010409; /* Very dark for code blocks */
            padding: 1rem;
            border-radius: 0.5rem;
            overflow-x: auto;
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace;
            font-size: 0.9em;
            color: #abb2bf; /* Light gray for code text */
            border: 1px solid #30363d;
            margin-top: 0.75rem;
        }
        .code-block .code-comment { color: #6a737d; } /* Gray for comments */
        .code-block .code-keyword { color: #f97583; } /* Pink for keywords */
        .code-block .code-string { color: #9ecbff; } /* Blue for strings */
        .code-block .code-function { color: #b392f0; } /* Purple for functions */

        /* Grid spans from second file (more comprehensive) */
        @media (min-width: 768px) { /* md */
            .bento-grid { grid-template-columns: repeat(6, 1fr); }
            .col-span-md-2 { grid-column: span 2 / span 2; }
            .col-span-md-3 { grid-column: span 3 / span 3; }
            .col-span-md-4 { grid-column: span 4 / span 4; }
            .col-span-md-6 { grid-column: span 6 / span 6; }
            .row-span-md-2 { grid-row: span 2 / span 2; }
        }
        @media (min-width: 1024px) { /* lg */
            /* Adjusted to use 4 columns for lg as per original files, could be 4 or more */
            .bento-grid { grid-template-columns: repeat(4, 1fr); }
            .col-span-lg-1 { grid-column: span 1 / span 1; }
            .col-span-lg-2 { grid-column: span 2 / span 2; }
            .col-span-lg-3 { grid-column: span 3 / span 3; }
            .col-span-lg-4 { grid-column: span 4 / span 4; }
            /* Retain md spans for elements that don't have lg specific spans */
        }

        .large-visual {
            font-size: 5rem; /* Tailwind: text-8xl */
            font-weight: 700;
            text-align: center;
            margin: auto 0 0.5rem 0; /* Push to bottom */
            color: rgba(201, 209, 217, 0.08);
            user-select: none;
        }
        .formula-visual {
            font-family: "SFMono-Regular", Consolas, "Liberation Mono", Menlo, Courier, monospace;
            font-size: 1.5rem;
            color: #58a6ff;
            text-align: center;
            padding: 1rem;
            background-color: rgba(88, 166, 255, 0.05);
            border-radius: 0.5rem;
            margin-top: auto;
        }

        /* Utility classes from first file (basic implementation) */
        .mb-2 { margin-bottom: 0.5rem; }
        .mb-3 { margin-bottom: 0.75rem; }
        .mt-1 { margin-top: 0.25rem; }
        .mt-2 { margin-top: 0.5rem; }
        .mt-3 { margin-top: 0.75rem; }
        .mt-4 { margin-top: 1rem; }
        .text-sm { font-size: 0.875rem; }
        .text-neutral-500 { color: #6b7280; } /* Example, adjust if needed */
        .text-blue-400 { color: #60a5fa; }
        .hover\:underline:hover { text-decoration: underline; }
        .pl-4 { padding-left: 1rem; }

        /* Header styling for the demo header */
        header {
            text-align: center;
            margin-bottom: 2rem;
            color: #e6edf3; /* Light color for header text */
        }
        header h1 {
            font-size: 2.5rem; /* Tailwind: text-4xl */
            font-weight: 700; /* Tailwind: font-bold */
            margin-bottom: 0.5rem;
        }
        header p {
            font-size: 1.125rem; /* Tailwind: text-lg */
            color: #adb5bd; /* Medium gray */
        }

    </style>
</head>
<body>

    <header>
        <h1>NLP Landing & Machine Reading Comprehension</h1>
        <h2><a href="https://deep-learning-101.github.io/">https://deep-learning-101.github.io/</a></h2>
    </header>

    <div class="bento-grid">
        <div class="bento-item col-span-md-3 col-span-lg-2 row-span-md-2" id="item-overview">
            <i class="fas fa-chalkboard-teacher icon"></i>
            <h2><strong>Deep Learning 101</strong> (AI) Meetup</h2>
            <p class="mb-2">æ­¤ç ”è¨æœƒæ—¨åœ¨æ·±å…¥æ¢è¨æ·±åº¦å­¸ç¿’çš„åŸºç¤èˆ‡å‰æ²¿æ‡‰ç”¨ï¼Œå°¤å…¶èšç„¦æ–¼è‡ªç„¶èªè¨€è™•ç† (NLP) é ˜åŸŸã€‚</p>
            <p>å„˜ç®¡æ´»å‹•åˆæœŸé­é‡ <span class="pill">ç›´æ’­å¹³å°æŠ€è¡“å•é¡Œ</span>ï¼Œå°è‡´Facebookç›´æ’­ä¸€åº¦ä¸­æ–·ï¼Œä½†åœ˜éšŠè¿…é€Ÿåˆ‡æ›è‡³ <span class="pill">Google Meet</span> èˆ‡ <span class="pill">YouTube</span> ç¹¼çºŒé€²è¡Œï¼Œç¢ºä¿äº†å…§å®¹çš„é †åˆ©å‚³æ’­ã€‚</p>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 0:00 - 1:28</p>
        </div>

        <div class="bento-item col-span-md-3 col-span-lg-2" id="item-nchc">
            <i class="fas fa-server icon"></i>
            <h2>åœ‹ç¶²ä¸­å¿ƒ <span class="highlight-text">GPUé‹ç®—è³‡æº</span> ä»‹ç´¹</h2>
            <p>æœƒè­°ä¸­ç‰¹åˆ¥ä»‹ç´¹äº†åœ‹ç¶²ä¸­å¿ƒ (NCHC) ç‚ºæ”¯æŒã€Œç§‘æŠ€æŠ—ç–«ã€å°ˆæ¡ˆæä¾›çš„GPUé‹ç®—è³‡æºï¼š</p>
            <ul class="list-disc list-inside mt-2 space-y-1">
                <li>å¯ç”³è«‹ <span class="pill">Tesla V100 GPU</span>ï¼Œç‚ºç ”ç©¶æä¾›å¼·å¤§ç®—åŠ›ã€‚</li>
                <li>æ¯å¼µé¡¯å¡æ“æœ‰ <span class="pill">32GB é¡¯å­˜</span>ï¼Œé©åˆè™•ç†å¤§è¦æ¨¡æ•¸æ“šã€‚</li>
                <li>ä¸»æ©Ÿé…ç½®ç¸½è¨˜æ†¶é«”é«˜é” <span class="pill">ç´„360GB</span>ã€‚</li>
            </ul>
            <p class="mt-2">æ­¤è³‡æºæ—¨åœ¨æ¨å‹•æ–°å† è‚ºç‚ç›¸é—œç ”ç©¶ï¼Œä¸¦ä»¥è²ç´‹è¾¨è­˜æŠ€è¡“æ‡‰ç”¨æ–¼é˜²ç–«è¿½è¹¤ç‚ºä¾‹ï¼Œå±•ç¤ºäº†å…¶å¯¦ç”¨åƒ¹å€¼ã€‚</p>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 1:28 - 2:47, 2:52 - 3:30</p>
        </div>

        <div class="bento-item col-span-md-3 col-span-lg-2 row-span-md-2" id="item-nlp-demos">
            <i class="fas fa-brain icon"></i>
            <h2>NLP <span class="highlight-text">æŠ€è¡“æ‡‰ç”¨</span>å±•ç¤º</h2>
            <p>ç ”è¨æœƒå±•ç¤ºäº†å¤šé …NLPæŠ€è¡“çš„å¯¦éš›æ‡‰ç”¨ï¼Œç›¸é—œ Demo å¯æ–¼çµè±¹ç§»å‹•æä¾›çš„ç¶²å€ (<a href="http://nlp.cm.com.tw:8383" target="_blank" class="text-blue-400 hover:underline">nlp.cm.com.tw:8383</a>ï¼Œç«¯å£å¯èƒ½éš¨æ™‚é–“è®Šæ›´) é€²è¡Œé«”é©—ï¼š</p>
            <ul class="list-disc list-inside mt-2 space-y-2">
                <li><strong>ä¸­æ–‡æ–‡æœ¬åˆ†é¡ (Text Classification):</strong> è­˜åˆ¥ç”¨æˆ¶è¼¸å…¥æ„åœ–ï¼Œä¾‹å¦‚ã€Œå¸¶æˆ‘å»éº¥ç•¶å‹ã€è¢«æ­¸é¡ç‚º <span class="pill">Mall Service</span>ã€‚</li>
                <li><strong>ä¸­æ–‡å¯¦é«”è­˜åˆ¥ (NER - Named Entity Recognition):</strong> å¾æ–‡æœ¬ä¸­æŠ½å–ç‰¹å®šå¯¦é«”ï¼Œå¦‚åœ¨ã€Œç‹å°æ˜å–œæ­¡æ—¥æœ¬Sonyæ‰€è£½é€ çš„é›»è¦–æ©Ÿã€ä¸­è­˜åˆ¥å‡ºäººå (ç‹å°æ˜)ã€åœ°å (æ—¥æœ¬) å’Œçµ„ç¹”å (Sony)ã€‚</li>
                <li><strong>ä¸­æ–‡æ–‡æœ¬ç›¸ä¼¼åº¦ (Text Similarity):</strong> è¨ˆç®—å…©æ®µæ–‡æœ¬ä¹‹é–“çš„èªç¾©ç›¸ä¼¼ç¨‹åº¦ã€‚</li>
                <li><strong>ä¸­æ–‡æ–‡æœ¬ç³¾éŒ¯ (Text Correction):</strong> è‡ªå‹•æ ¡æ­£è¼¸å…¥æ–‡æœ¬ä¸­çš„éŒ¯åˆ¥å­—ï¼Œä¾‹å¦‚å°‡ã€Œæˆ‘æƒ³å»è³£ç•¶è¾£ã€ä¿®æ­£ç‚ºã€Œæˆ‘æƒ³å»éº¥ç•¶å‹ã€ã€‚</li>
            </ul>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 9:30 - 16:40</p>
        </div>

        <div class="bento-item col-span-md-3 col-span-lg-2" id="item-mrc-chatbot">
            <i class="fas fa-robot icon"></i>
            <h2>æ·±åº¦å­¸ç¿’ <span class="highlight-text">MRCèŠå¤©æ©Ÿå™¨äºº</span> æŠ€è¡“è§£æ</h2>
            <p>æœƒè­°å¾ŒåŠæ®µæ·±å…¥æ¢è¨äº†åŸºæ–¼æ©Ÿå™¨é–±è®€ç†è§£ (Machine Reading Comprehension, MRC) çš„èŠå¤©æ©Ÿå™¨äººæ¶æ§‹èˆ‡æŠ€è¡“ç´°ç¯€ï¼š</p>
            <ul class="list-disc list-inside mt-2 space-y-1">
                <li><strong>è³‡æ–™é è™•ç† (Pre-Process)</strong>:
                    <ul class="list-circle list-inside ml-4">
                        <li>å°æ‡‰ä¸Šä¸‹æ–‡é¸æ“‡ (Corresponding Context Pick): å¦‚ä½•å¾å¤§é‡æ–‡æœ¬ä¸­æŒ‘é¸èˆ‡å•é¡Œæœ€ç›¸é—œçš„ä¸Šä¸‹æ–‡ã€‚</li>
                        <li>é•·æ–‡æœ¬è™•ç† (Context Overlength): è§£æ±ºæ¨¡å‹è¼¸å…¥é•·åº¦é™åˆ¶çš„å•é¡Œï¼Œå¦‚é€šéæ–‡æœ¬æ‘˜è¦ (Summarization) é€²è¡Œè™•ç†ã€‚</li>
                    </ul>
                </li>
                <li><strong>æ ¸å¿ƒæŠ€è¡“èˆ‡æ¨¡å‹</strong>: å¼·èª¿äº† <span class="pill">BERT</span> åŠå…¶è®Šé«” (å¦‚ <span class="pill">ALBERT</span>) åœ¨MRCä»»å‹™ä¸­çš„é‡è¦æ€§ã€‚æåŠ <span class="pill">TF-IDF Bag-of-words model (å¦‚ DrQA)</span> å’Œ <span class="pill">TextRank</span> ç­‰ç›¸é—œæŠ€è¡“ã€‚</li>
                <li><strong>æ‘˜è¦æ–¹æ³•æ¯”è¼ƒ</strong>: æ¢è¨äº†æŠ½å–å¼ (Extractive) èˆ‡ç”Ÿæˆå¼/æŠ½è±¡å¼ (Abstractive) æ‘˜è¦æŠ€è¡“çš„å€åˆ¥èˆ‡æ‡‰ç”¨ã€‚
                    <ul class="list-circle list-inside ml-4">
                        <li>æŠ½å–å¼: å¦‚ã€Œåªè¦æ˜¯åƒåŠ  Deep Learning 101 è®€æ›¸æœƒçš„äººï¼Œä¹‹å¾Œé‹å½©å¦å¤–éƒ½èƒ½ä¸­é ­çæˆç‚ºå„„è¬å¯Œç¿ã€‚ã€(ç›´æ¥æ‘˜éŒ„)</li>
                        <li>ç”Ÿæˆå¼: å¦‚ã€ŒDeep Learning 101 è®€æ›¸æœƒçš„æˆå“¡æ—¥å¾Œéƒ½æˆäº†å„„è¬å¯Œç¿ã€‚ã€(é‡æ–°çµ„ç¹”èªå¥)</li>
                    </ul>
                </li>
            </ul>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 21:15 - End</p>
        </div>

        <div class="bento-item col-span-md-2 col-span-lg-1" id="item-barista"> <i class="fas fa-mug-hot icon"></i>
            <h2>æœƒå ´èŠ±çµ®</h2>
            <p>ç ”è¨æœƒç¾å ´è¨­æœ‰ <span class="highlight-text">ã€Œè±¹ç”œç±³ã€ (Barista)</span> å…¨è‡ªå‹•æ™ºèƒ½èŒ¶é£²æ©Ÿï¼Œç‚ºèˆ‡æœƒè€…å…è²»æä¾›ç™¾é¦™ç¶ èŒ¶ï¼Œå¢æ·»äº†è¼•é¬†çš„äº¤æµæ°›åœã€‚</p>
            <div class="large-visual mt-auto">ğŸµ</div>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 4:51 - 5:19</p>
        </div>

        <div class="bento-item col-span-md-2 col-span-lg-1" id="item-tech-issues"> <i class="fas fa-tools icon"></i>
            <h2>æŠ€è¡“æ’æ›²</h2>
            <p>æ´»å‹•é–‹å ´æ™‚ï¼ŒåŸå®šçš„ <span class="pill">Facebook ç›´æ’­</span> åŠŸèƒ½å‡ºç¾å•é¡Œï¼Œä¸€åº¦ç„¡æ³•æ­£å¸¸æ¨æµã€‚åœ˜éšŠç·Šæ€¥æ‡‰å°ï¼Œå°‡ç›´æ’­è½‰ç§»è‡³ <span class="pill">Google Meet</span> å’Œ <span class="pill">YouTube</span> å¹³å°ï¼Œç¢ºä¿äº†ç ”è¨æœƒçš„é †åˆ©é€²è¡Œã€‚</p>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 0:00 - 1:15</p>
        </div>


        <div class="bento-item col-span-md-3 col-span-lg-2" id="item-context-overlength">
            <i class="fas fa-file-alt icon"></i>
            <h2><strong>é•·æ–‡æœ¬è™•ç†</strong> Context Overlength</h2>
            <p>æ¢è¨ NLP æ¨¡å‹åœ¨è™•ç†éé•·ä¸Šä¸‹æ–‡æ™‚çš„æŒ‘æˆ°ï¼Œä¸»è¦è§£æ±ºæ–¹æ¡ˆç‚º <span class="highlight-text">æ–‡æœ¬æ‘˜è¦ (Summarization)</span>ã€‚</p>
            <h3 class="mt-3">æ‘˜è¦æ–¹æ³• Types of Summarization:</h3>
            <ul class="list-disc list-inside space-y-1">
                <li><strong>æŠ½å–å¼ (Extractive):</strong> ç›´æ¥å¾åŸæ–‡ä¸­æå–é—œéµå¥å­ã€‚
                    <p class="text-sm text-neutral-500 pl-4">ä¾‹ï¼šã€Œåªè¦æ˜¯åƒåŠ  Deep Learning 101 è®€æ›¸æœƒçš„äººï¼Œä¹‹å¾Œé‹å½©éƒ½èƒ½ä¸­é ­çæˆç‚ºå„„è¬å¯Œç¿ã€‚ã€</p>
                </li>
                <li><strong>ç”Ÿæˆå¼ (Abstractive):</strong> ç†è§£åŸæ–‡å¾Œï¼Œç”Ÿæˆæ–°çš„æ‘˜è¦å¥å­ã€‚
                    <p class="text-sm text-neutral-500 pl-4">ä¾‹ï¼šã€ŒDeep Learning 101 è®€æ›¸æœƒçš„æˆå“¡æ—¥å¾Œéƒ½æˆäº†å„„è¬å¯Œç¿ã€‚ã€</p>
                </li>
            </ul>
            <p class="mt-2 text-sm text-neutral-500">æåŠ <span class="pill">XLNet</span> å¯èƒ½è§£æ±ºæ­¤å•é¡Œã€‚Timestamp: 0:00 - 0:09</p>
        </div>

        <div class="bento-item col-span-md-3 col-span-lg-2" id="item-what-is-mrc">
            <i class="fas fa-question-circle icon"></i>
            <h2><strong>MRC</strong> æ˜¯ä»€éº¼ï¼Ÿ What is MRC?</h2>
            <p>æ©Ÿå™¨é–±è®€ç†è§£ (Machine Reading Comprehension) çš„æ ¸å¿ƒä»»å‹™æ˜¯ï¼šæ ¹æ“šæå‡ºçš„ <span class="pill">å•é¡Œ (Question)</span>ï¼Œå¾çµ¦å®šçš„ <span class="pill">æ–‡ç«  (Context)</span> ä¸­ï¼Œ**æŠ½å– (Extract)** å‡ºä¸€å€‹é€£çºŒçš„æ–‡æœ¬ç‰‡æ®µ <span class="highlight-text">(Span)</span> ä½œç‚ºç­”æ¡ˆã€‚</p>
            <p class="mt-2">ç­”æ¡ˆå¿…é ˆå®Œå…¨åŒ…å«åœ¨åŸæ–‡ä¸­ï¼Œä¸èƒ½ç”±ä¸é€£çºŒçš„éƒ¨åˆ†çµ„æˆã€‚</p>
            <div class="large-visual">MRC</div>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 0:55 - 1:24</p>
        </div>

        <div class="bento-item col-span-md-6 col-span-lg-4 row-span-md-2" id="item-mrc-outline">
            <i class="fas fa-sitemap icon"></i>
            <h2><strong>MRC æŠ€è¡“å¤§ç¶±</strong> Technical Outline</h2>
            <p class="mb-3">æœ¬æ¬¡ç ”è¨æœƒæ·±å…¥æ¢è¨äº†æ©Ÿå™¨é–±è®€ç†è§£ (MRC) çš„å¤šå€‹é—œéµæ–¹é¢ï¼š</p>
            <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 1rem;">
                <div>
                    <h3 style="font-size: 1.1rem; font-weight: 500; color: #58a6ff;">æ ¸å¿ƒæ¦‚å¿µèˆ‡æ¨¡å‹ Core Concepts & Models:</h3>
                    <ul class="list-disc list-inside space-y-1 mt-1">
                        <li>è³‡æ–™é è™•ç† <span class="pill">Pre-Process</span></li>
                        <li>MRC å®šç¾© <span class="pill">What is MRC?</span></li>
                        <li>QANet <span class="pill">Pre-BERT Model</span></li>
                        <li>BERT <span class="pill">Bidirectional Transformer</span></li>
                        <li>è‡ªç ”æ¨¡å‹ <span class="pill">Our Design</span> (åŸºæ–¼ QANet)</li>
                    </ul>
                </div>
                <div>
                    <h3 style="font-size: 1.1rem; font-weight: 500; color: #b392f0;">é—œéµæŠ€è¡“ Key Technologies:</h3>
                    <ul class="list-disc list-inside space-y-1 mt-1">
                        <li>ä¸Šä¸‹æ–‡-æŸ¥è©¢æ³¨æ„åŠ› <span class="pill">Context-Query Attention</span></li>
                        <li>è‡ªæ³¨æ„åŠ›æ©Ÿåˆ¶ <span class="pill">Self-Attention</span></li>
                        <li>Synthesizer <span class="pill">Attention Variants</span></li>
                        <li>ä½ç½®ç·¨ç¢¼ <span class="pill">Positional Encoding</span></li>
                        <li>Hugging Face å·¥å…·åŒ… <span class="pill">Transformers Toolkit</span></li>
                        <li>NER è³‡æ–™é è™•ç† <span class="pill">NER Preprocessing</span></li>
                    </ul>
                </div>
            </div>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 0:09 - 0:54 åŠå¾ŒçºŒå„ç¯€é»</p>
        </div>

        <div class="bento-item col-span-md-3 col-span-lg-2" id="item-qanet">
            <i class="fas fa-microchip icon"></i>
            <h2><strong>QANet</strong> æ¨¡å‹è§£æ</h2>
            <p>QANet (Yu, et al., 2018) æ˜¯åœ¨ BERT å‡ºç¾å‰çš„ä¸€å€‹é‡è¦ MRC æ¨¡å‹ã€‚</p>
            <ul class="list-disc list-inside mt-2 space-y-1">
                <li>æ¶æ§‹é¡ä¼¼ <span class="pill">BiDAF</span>ï¼Œä½†ä»¥ <span class="highlight-text">Convolution + Self-Attention</span> å–ä»£ LSTMã€‚</li>
                <li>é¦–æ¬¡å°‡ <span class="pill">Self-Attention</span> æ‡‰ç”¨æ–¼ MRCã€‚</li>
                <li>ç·¨ç¢¼å™¨ä¸­åŒ…å« <span class="pill">Positional Encoding</span>ã€‚</li>
            </ul>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 1:25 - 2:25</p>
        </div>

        <div class="bento-item col-span-md-3 col-span-lg-2 row-span-md-2" id="item-context-query">
            <i class="fas fa-retweet icon"></i>
            <h2><strong>ä¸Šä¸‹æ–‡-æŸ¥è©¢æ³¨æ„åŠ›</strong> Context-Query Attention</h2>
            <p>æºè‡ª BiDAF æ¨¡å‹ (Seo, et al., 2017)ï¼Œç”¨æ–¼è¨ˆç®—ä¸Šä¸‹æ–‡èˆ‡æŸ¥è©¢é–“çš„é—œè¯æ€§ã€‚</p>
            <h3 class="mt-2">ä¸»è¦æ­¥é©Ÿ Steps:</h3>
            <ol class="list-decimal list-inside space-y-2 mt-2">
                <li>è¨ˆç®— <span class="pill">ç›¸ä¼¼åº¦çŸ©é™£ (Similarity Matrix)</span> S<sub>ij</sub> = W<sub>0</sub>\[c<sub>i</sub>; q<sub>j</sub>; c<sub>i</sub> âŠ™ q<sub>j</sub>]ã€‚</li>
                <li>é€²è¡Œ Softmax æ­£è¦åŒ–å¾—åˆ° <span class="pill">æ³¨æ„åŠ›æ¬Šé‡ (Attention Weights)</span> SÌƒ (C2Q) å’Œ SÌƒÌƒ (Q2C)ã€‚</li>
                <li>ç”Ÿæˆå¸¶æœ‰æ³¨æ„åŠ›çš„å‘é‡è¡¨ç¤ºï¼š
                    <ul class="list-disc list-inside ml-4 text-sm">
                        <li>Context-to-Query (C2Q): Ãƒ = SÌƒ â‹… Q<sup>T</sup></li>
                        <li>Query-to-Context (Q2C): CÌƒ = SÌƒ â‹… SÌƒÌƒ<sup>T</sup> â‹… C<sup>T</sup></li>
                    </ul>
                </li>
                <li>æœ€çµ‚è¼¸å‡ºç‚ºæ‹¼æ¥å‘é‡ G<sub>i</sub> = \[c<sub>i</sub>; Ã£<sub>i</sub>; c<sub>i</sub> âŠ™ Ã£<sub>i</sub>; c<sub>i</sub> âŠ™ cÌƒ<sub>i</sub>]ã€‚</li>
            </ol>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 2:25 - 4:55</p>
        </div>

        <div class="bento-item col-span-md-3 col-span-lg-2" id="item-self-attention">
            <i class="fas fa-atom icon"></i>
            <h2><strong>è‡ªæ³¨æ„åŠ›æ©Ÿåˆ¶</strong> Self-Attention</h2>
            <p>ç¶“å…¸çš„ Self-Attention æ©Ÿåˆ¶ä¾†è‡ª "Attention is All You Need" (Vaswani, et al., 2017)ã€‚</p>
            <div class="formula-visual">
                Attention(Q, K, V) = softmax(QK<sup>T</sup>/âˆšd<sub>k</sub>)V
            </div>
            <p class="mt-2">é€šé Queries, Keys, Values è¨ˆç®—åŠ æ¬Šè¡¨ç¤ºï¼Œä¸¦å¸¸ç”¨ <span class="pill">Multi-head Attention</span> å¢å¼·æ¨¡å‹èƒ½åŠ›ã€‚</p>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 4:55 - 7:10</p>
        </div>

        <div class="bento-item col-span-md-3 col-span-lg-2" id="item-synthesizer">
            <i class="fas fa-random icon"></i>
            <h2><strong>Synthesizer</strong> æ³¨æ„åŠ›è®Šé«”</h2>
            <p>Synthesizer (Y. Tay, et al., 2020) è«–æ–‡æ¢è¨äº† Self-Attention çš„ä¸åŒè®Šé«”ï¼š</p>
            <ul class="list-disc list-inside mt-2 space-y-1">
                <li><span class="pill">Transformer (Standard)</span>: ä½¿ç”¨ QK<sup>T</sup> äº¤äº’ã€‚</li>
                <li><span class="pill">Synthesizer (Dense)</span>: ä»¥å¯†é›†å±¤å­¸ç¿’æ³¨æ„åŠ›æ¬Šé‡ã€‚</li>
                <li><span class="pill">Synthesizer (Random)</span>: ä½¿ç”¨éš¨æ©Ÿã€å›ºå®šçš„æ³¨æ„åŠ›æ¬Šé‡ã€‚</li>
            </ul>
            <p class="mt-2">ç ”ç©¶è¡¨æ˜ï¼Œå³ä½¿æ˜¯ <span class="highlight-text">éš¨æ©Ÿæ³¨æ„åŠ›</span> æœ‰æ™‚ä¹Ÿèƒ½å–å¾—ä¸éŒ¯çš„æ€§èƒ½ã€‚</p>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 7:10 - 8:06</p>
        </div>

        <div class="bento-item col-span-md-2 col-span-lg-2" id="item-positional-encoding">
            <i class="fas fa-map-marked-alt icon"></i>
            <h2><strong>ä½ç½®ä¿¡æ¯</strong> Positional Information</h2>
            <p>Self-Attention æœ¬èº«ä¸æ„ŸçŸ¥åºåˆ—é †åºï¼Œéœ€ <span class="highlight-text">ä½ç½®ç·¨ç¢¼ (Positional Encoding)</span> ä¾†å¼•å…¥é †åºä¿¡æ¯ã€‚</p>
            <ul class="list-disc list-inside mt-2 space-y-1">
                <li><span class="pill">RNN</span>: å›ºæœ‰é †åºæ€§ã€‚</li>
                <li><span class="pill">Transformer/QANet</span>: ä½¿ç”¨ä¸‰è§’å‡½æ•¸å…¬å¼ç”Ÿæˆå›ºå®šä½ç½®ç·¨ç¢¼ã€‚</li>
                <li><span class="pill">BERT</span>: ä½¿ç”¨å¯å­¸ç¿’çš„ <span class="highlight-text">Positional Embeddings</span>ã€‚</li>
            </ul>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 8:06 - 10:02</p>
        </div>

        <div class="bento-item col-span-md-2 col-span-lg-2" id="item-our-design">
            <i class="fas fa-drafting-compass icon"></i>
            <h2><strong>è‡ªç ”æ¨¡å‹</strong> Our Design (QANet-based)</h2>
            <p>åŸºæ–¼ QANet é€²è¡Œçš„æ”¹é€²ï¼Œç”¨æ–¼ä¸­æ–‡MRCä»»å‹™ (DRCDæ•¸æ“šé›†)ï¼š</p>
            <ul class="list-disc list-inside mt-2 space-y-1">
                <li>å…©æ¬¡ <span class="pill">Context-Query Attention</span> æ“ä½œã€‚</li>
                <li>ä½¿ç”¨ <span class="pill">Highway Network</span> èåˆä¿¡æ¯ã€‚</li>
                <li>æ¡ç”¨ <span class="pill">Single-head Self-Attention</span>ã€‚</li>
            </ul>
            <p class="mt-2">è¨“ç·´ç´„4å°æ™‚ï¼Œæ€§èƒ½å„ªæ–¼åŸºç·šQANetï¼ŒåŠ å…¥é¡å¤–ç¿»è­¯æ•¸æ“šå¾Œé€²ä¸€æ­¥æå‡ã€‚</p>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 10:02 - 11:20</p>
        </div>

        <div class="bento-item col-span-md-2 col-span-lg-2" id="item-bert-mrc">
            <i class="fas fa-bold icon"></i>
            <h2><strong>BERT</strong> æ‡‰ç”¨æ–¼ MRC</h2>
            <p>BERT (Devlin, et al., 2018) å°‡ Transformer çš„ Encoder é€²è¡Œé›™å‘è¨“ç·´ã€‚</p>
            <p class="mt-2">åœ¨ MRC ä¸­ï¼Œå°‡ <span class="pill">Question Tokens</span> å’Œ <span class="pill">Context Tokens</span> åˆä½µè¼¸å…¥ BERTï¼Œæ¨¡å‹è¼¸å‡ºç·¨ç¢¼å¾Œçš„ Tokensï¼Œå†é€šéç·šæ€§å±¤é æ¸¬ç­”æ¡ˆçš„ <span class="highlight-text">Start/End Score</span>ã€‚</p>
            <div class="large-visual mt-auto">BERT</div>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 11:20 - 13:19</p>
        </div>

        <div class="bento-item col-span-md-6 col-span-lg-2 row-span-md-2" id="item-huggingface">
            <i class="fas fa-puzzle-piece icon"></i>
            <h2><strong>Hugging Face</strong> Transformers Toolkit</h2>
            <p>ä¸€å€‹å¼·å¤§ä¸”å»£æ³›ä½¿ç”¨çš„NLPå·¥å…·åŒ…ï¼Œæ¥µå¤§ç°¡åŒ–äº† Transformer æ¨¡å‹çš„æ‡‰ç”¨ã€‚</p>
            <h3 class="mt-2">ä¸»è¦ç‰¹æ€§ Features:</h3>
            <ul class="list-disc list-inside space-y-1">
                <li>æ”¯æŒ <span class="pill">PyTorch</span> å’Œ <span class="pill">TensorFlow 2.0</span>ã€‚</li>
                <li>æä¾›å¤§é‡å®˜æ–¹åŠç¤¾ç¾¤ä¸Šå‚³çš„ <span class="highlight-text">é è¨“ç·´æ¨¡å‹ (Pretrained Models)</span>ã€‚</li>
                <li>ç°¡ä¾¿çš„ <span class="pill">Tokenizer</span> å’Œ <span class="pill">Model</span> åŠ è¼‰æ¥å£ã€‚</li>
                <li>é‡å°ä¸åŒä¸‹æ¸¸ä»»å‹™ (Downstream Tasks) çš„å°ˆç”¨æ¨¡å‹é¡ï¼Œå¦‚ï¼š
                    <ul class="list-circle list-inside ml-4 text-sm">
                        <li>`BertForMaskedLM`</li>
                        <li>`BertForSequenceClassification`</li>
                        <li>`BertForTokenClassification` (for NER)</li>
                        <li>`BertForQuestionAnswering` (for MRC)</li>
                    </ul>
                </li>
            </ul>
            <div class="code-block mt-auto">
                <span class="code-keyword">from</span> transformers <span class="code-keyword">import</span> BertTokenizer, BertModel<br>
                tokenizer = BertTokenizer.from_pretrained(<span class="code-string">'bert-base-chinese'</span>)<br>
                model = BertModel.from_pretrained(<span class="code-string">'bert-base-chinese'</span>)<br>
                <span class="code-comment"># text = "ä»Šå¤©å¤©æ°£å¾ˆå¥½" -> embeddings</span>
            </div>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 13:19 - 20:30</p>
        </div>

        <div class="bento-item col-span-md-6 col-span-lg-2" id="item-hf-ner">
            <i class="fas fa-cogs icon"></i>
            <h2><strong>Hugging Face NER</strong> è³‡æ–™é è™•ç†</h2>
            <p>ä½¿ç”¨ Hugging Face é€²è¡Œ NER ä»»å‹™æ™‚çš„è³‡æ–™é è™•ç†æ­¥é©Ÿï¼š</p>
            <ol class="list-decimal list-inside mt-2 space-y-1">
                <li>åŸå§‹æ•¸æ“š (Raw Data) é€šå¸¸ç‚ºæ¯è¡Œä¸€å€‹è©åŠå…¶æ¨™ç±¤ (e.g., <span class="pill">Stuttgart B-LOC</span>)ã€‚</li>
                <li>åŸ·è¡Œé è™•ç†è…³æœ¬ (`preprocess.py`)ã€‚</li>
                <li>é—œéµè™•ç†ï¼š
                    <ul class="list-disc list-inside ml-4 text-sm">
                        <li>éæ¿¾ <span class="pill">æ§åˆ¶å­—ç¬¦ (Control Characters)</span>ï¼Œå›  `BertTokenizer` å¯èƒ½ç”¢ç”Ÿç©º tokenã€‚</li>
                        <li>å°‡é•·å¥å­ <span class="pill">åˆ‡åˆ† (Split)</span> æˆè¼ƒçŸ­å¥å­ä»¥ç¬¦åˆæ¨¡å‹è¼¸å…¥é•·åº¦é™åˆ¶ã€‚</li>
                    </ul>
                </li>
                <li>è™•ç†å¾Œæ ¼å¼ï¼šæ¯å€‹ token ä¸€è¡Œï¼Œé™„å¸¶å…¶ NER æ¨™ç±¤ï¼Œé©ç”¨æ–¼ BERT æ¨¡å‹è¨“ç·´ã€‚</li>
            </ol>
            <p class="mt-4 text-sm text-neutral-500">Timestamp: 20:30 - 26:48</p>
        </div>

    </div>

<script>
    // Framer Motion and Intersection Observer setup
    document.addEventListener('DOMContentLoaded', () => {
        const bentoItems = document.querySelectorAll('.bento-item');
        bentoItems.forEach((item, index) => {
            item.style.opacity = 0;
            item.style.transform = 'translateY(30px)';

            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        item.style.transition = `opacity 0.7s cubic-bezier(0.17, 0.55, 0.55, 1) ${index * 0.08}s, transform 0.7s cubic-bezier(0.17, 0.55, 0.55, 1) ${index * 0.08}s`;
                        item.style.opacity = 1;
                        item.style.transform = 'translateY(0px)';
                        // observer.unobserve(entry.target); // Uncomment to animate only once
                    } else {
                        // Optional: Reset for re-animation on scroll up
                        // item.style.opacity = 0;
                        // item.style.transform = 'translateY(30px)';
                    }
                });
            }, { threshold: 0.1 }); // Trigger when 10% of the item is visible

            observer.observe(item);
        });

        // Header animation (simpler, non-Framer Motion directly for static HTML)
        const headerH1 = document.querySelector('header h1');
        const headerP = document.querySelector('header p');
        if (headerH1) {
            headerH1.style.opacity = 0;
            headerH1.style.transform = 'translateY(-40px)';
            setTimeout(() => {
                headerH1.style.transition = 'opacity 0.9s ease-out, transform 0.9s ease-out';
                headerH1.style.opacity = 1;
                headerH1.style.transform = 'translateY(0)';
            }, 100);
        }
        if (headerP) {
            headerP.style.opacity = 0;
            headerP.style.transform = 'translateY(25px)';
            setTimeout(() => {
                headerP.style.transition = 'opacity 0.9s ease-out 0.25s, transform 0.9s ease-out 0.25s';
                headerP.style.opacity = 1;
                headerP.style.transform = 'translateY(0)';
            }, 100);
        }
    });
</script>

</body>
</html>
