---
layout: default
title: Deep Learning 101, Taiwan’s pioneering and highest deep learning meetup, launched on 2016/11/11 @ 83F, Taipei 101
---

<p align="center">
  <strong>Deep Learning 101, Taiwan’s pioneering and highest deep learning meetup, launched on 2016/11/11 @ 83F, Taipei 101</strong>  
</p>
<p align="center">
  AI是一條孤獨且充滿惶恐及未知的旅程，花俏絢麗的收費課程或活動絕非通往成功的捷徑。<br>
  衷心感謝當時來自不同單位的AI同好參與者實名分享的寶貴經驗；如欲移除資訊還請告知。<br>
  由 <a href="https://www.twman.org/" target="_blank">TonTon Huang Ph.D.</a> 發起，及其當時任職公司(台灣雪豹科技)無償贊助場地及茶水點心。<br>
</p>  
<p align="center">
  <a href="https://huggingface.co/spaces/DeepLearning101/Deep-Learning-101-FAQ" target="_blank">
    <img src="https://github.com/Deep-Learning-101/.github/blob/main/images/DeepLearning101.JPG?raw=true" alt="Deep Learning 101" width="180"></a>
    <a href="https://www.buymeacoffee.com/DeepLearning101" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-red.png" alt="Buy Me A Coffee" style="height: 100px !important;width: 180px !important;" ></a>
</p>
<p align="center">
  <a href="https://www.youtube.com/@DeepLearning101" target="_blank">YouTube</a> |
  <a href="https://www.facebook.com/groups/525579498272187/" target="_blank">Facebook</a> |
  <a href="https://deep-learning-101.github.io/"> 回 GitHub Pages</a> |
  <a href="http://DeepLearning101.TWMAN.ORG" target="_blank">網站</a> |
  <a href="https://huggingface.co/DeepLearning101" target="_blank">Hugging Face Space</a>
</p>

# 第十七章 蒙特卡羅方法

<a href="https://www.youtube.com/watch?v=qef-XTUpDvE" target="_blank" rel="noopener noreferrer"><i class="fab fa-youtube mr-1"></i>2017/12/15, Monte Carlo Methods @ Deep Learning Book Chapter 17</a><br>

# 機器學習中的採樣與蒙地卡羅方法

## 1. 採樣的必要性與蒙地卡羅方法基礎

*   在機器學習中，**經常需要從機率分佈中採樣** [1]。
*   主要原因是為了**近似難以精確計算的數學表達式**，例如複雜的和或積分 [2, 3]，這在處理大型數據或難解模型時非常有用 [2]。
*   當我們需要以較小的代價近似許多項的和或某個積分時，採樣是一種很靈活的選擇 [3, 4]。例如，用小批量數據對整個訓練集代價進行採樣估計，或者在模型中，需要近似一個難以處理的和或積分（如配分函數對數的梯度） [3]。
*   **最根本的情況是，採樣本身就是我們的目標**，例如我們想訓練一個可以從訓練分佈採樣的模型 [2, 3, 5]。
*   蒙地卡羅採樣是使用重複隨機採樣來獲得數值結果的計算方法，常用於**估計期望值、積分或求和** [6]。
*   核心思想是將要求解的和或積分視為某個分佈下的期望值 $E_p[f(x)]$ [4, 5, 7]，然後通過從分佈 $p$ 中抽取獨立同分佈 (i.i.d.) 樣本 $x^{(i)}$ [6, 7] 並計算經驗平均值 $\hat{s}_n = \frac{1}{n} \sum_{i=1}^n f(x^{(i)})$ 來近似這個期望值 [4, 5, 7]。
*   **蒙地卡羅估計量 $\hat{s}_n$ 是無偏估計** [2, 6, 7]，意味著其期望值等於它所估計的真實期望值 $s$ [2]。
*   根據**大數定律** [6, 7]，當樣本數量 $n$ 趨於無窮大時，獨立同分佈樣本的經驗平均值 $\hat{s}_n$ 將會依機率收斂到它們的期望值 $s$ [2, 6, 7]。這解釋了為什麼增加樣本數可以改善估計的準確性 [1, 2]。
*   **中心極限定理**指出，大量獨立同分佈隨機變數的平均值的分佈會趨於正態分佈 [6, 7]，這在大樣本下允許我們估計蒙地卡羅估計量的置信區間 [6-8]。
*   蒙地卡羅方法的局限性之一是，當目標和或積分難以直接從分佈中採樣時，基本蒙地卡羅方法不再直接適用 [7].

## 2. 重要性採樣 (Importance Sampling)

*   重要性採樣的主要目的是**在無法直接或有效從目標分佈 $p(x)$ 中採樣時**，通過從一個易於採樣的提議分佈 $q(x)$ 中抽取樣本來估計在 $p(x)$ 下的期望值 $E_p[f(x)]$ [1, 2, 6, 7].
*   核心思想是從提議分佈 $q$ 中抽取樣本，並使用重要性權重 $w(x) = p(x)/q(x)$ 對樣本進行加權，以校正由於採樣分佈不同引入的偏差 [6, 7].
*   存在**無偏重要性採樣**和**有偏（自歸一化）重要性採樣**方法 [6, 7, 9].
    *   **無偏重要性採樣**的估計形式是加權樣本和除以樣本數 $n$，$\hat{s}_{UIS} = \frac{1}{n} \sum_{i=1}^n w(x^{(i)}) f(x^{(i)})$ [2, 9]. 它要求能夠精確計算權重 $p(x)/q(x)$，即 $p$ 和 $q$ 的歸一化常數已知 [9].
    *   **有偏重要性採樣**的估計形式是加權樣本和除以權重之和，$\hat{s}_{BIS} = \frac{\sum_{i=1}^n w(x^{(i)}) f(x^{(i)})}{\sum_{i=1}^n w(x^{(i)})}$ [2, 9]. 它的主要優點是**不需要知道目標分佈 $p$ 和提議分佈 $q$ 的歸一化常數** [2, 9, 10]，因為它們在分子分母中會消掉 [9]. 然而，它對於有限樣本數是一個有偏估計 [2, 9]，只在樣本數趨於無窮時漸近無偏 [2, 9].
    *   有偏重要性採樣通常**具有比無偏重要性採樣更低的方差** [9].
*   **提議分佈 $q(x)$ 的選擇對估計的準確性有極為關鍵的影響** [1, 2, 6-8].
    *   一個好的 $q(x)$ 應當與 $p(x)|f(x)|$ 的形狀相似 [2, 8].
    *   一個糟糕的 $q(x)$ 可能導致重要性權重 $p(x)/q(x)$ 的方差非常大 [2, 8, 10]，使得估計不可靠，甚至方差可能無限 [2, 8].
    *   理論上最優的提議分佈 $q^*(x)$ 與 $p(x)|f(x)|$ 成正比 [7, 8]，但在實踐中通常難以實現 [7, 8].
*   儘管存在一些潛在問題，重要性採樣在機器學習應用中扮演著重要角色，包括深度學習算法 [10].

## 3. 馬爾可夫鏈蒙地卡羅 (MCMC) 方法

*   MCMC 方法主要解決在**目標分佈難以直接進行獨立同分佈採樣的問題** [6, 7, 11, 12]，特別是對於**高維分佈**或其歸一化常數（如配分函數）難以計算的情況 [7, 11, 12]. 這類問題常見於複雜的、高維機率分佈，例如深度學習模型中的後驗分佈或能量模型 [10, 12].
*   MCMC 的核心思想是**構造一個馬爾可夫鏈** [6, 7, 11, 12]，使其在經過足夠長時間的演變後，能夠收斂到以**目標分佈 $p$ 作為其平穩分佈 (stationary distribution)** [6, 7, 11, 12].
*   一個馬爾可夫鏈由**初始狀態分佈 $q^{(0)}(x)$** 和**轉移算子 $T(x'|x)$** 定義 [12]. 轉移算子描述從當前狀態 $x$ 轉移到下一個狀態 $x'$ 的條件機率 [12]，並滿足馬爾可夫性質（未來狀態只依賴於當前狀態） [12].
*   如果馬爾可夫鏈是遍歷的 (ergodic)，那麼無論初始分佈如何，經過足夠多的轉移後，狀態的分佈 $q^{(t)}(x)$ 都會收斂到唯一的平穩分佈 $p(x)$ [12-14].
*   一旦馬爾可夫鏈達到平穩狀態（經過「燒入期」burn-in period 後） [6, 11, 12]，從鏈中抽取出的樣本序列在理論上就近似於從目標分佈 $p$ 中抽取的樣本 [11-13]，可以用於近似目標分佈下的期望值或其他統計量 [11].
*   MCMC 的一個關鍵挑戰是**混合時間 (mixing time)** [12, 13]，即鏈達到平穩分佈所需的時間，這可能非常長 [12]. 並且**無法預先知道確切需要運行多少步才能達到平衡分佈** [13, 14]。實際中常通過人工檢查或比較前後樣本的相關度來判斷是否收斂 [14].

## 4. MCMC 的常見挑戰與改善方法

*   MCMC 存在一些挑戰 [7, 11]:
    *   **收斂性 (Convergence):** 需要運行足夠長的「燒入期」以確保馬爾可夫鏈達到其平穩分佈 [6, 11]. 確定何時達到收斂是一個難題 [11, 13].
    *   **混合性 (Mixing):** 馬爾可夫鏈需要有效地探索整個狀態空間 [6, 11]，特別是對於多模態分佈 [6, 7, 11]. 如果鏈難以在不同高機率區域（峰值）之間快速跳躍，混合就會很慢 [6, 11, 15]，導致採樣效率低下和對目標分佈的估計存在偏差 [11, 15].
    *   **能量景觀崎嶇問題 (Rugged energy landscapes):** 在基於能量的模型中 [6, 11, 15, 16]，如果能量景觀崎嶇（有多個由高能量勢壘分隔的局部能量極小點） [6, 7, 11, 15]，MCMC 算法可能被困在一個局部極小點（對應機率峰值） [11, 15]，難以跨越高能量勢壘 [11, 15]，這會導致混合緩慢 [11].

*   改善 MCMC 混合性或處理能量景觀崎嶇問題的方法包括 [7, 8, 17]:
    *   **退火 (Annealing) / 回火 (Tempering):** 模擬物理系統的退溫過程 [6, 16, 17]，在高「溫度」下增加狀態轉換的機率 [16, 17]，使鏈更容易探索狀態空間並跨越能量勢壘 [16, 17]，然後逐漸降低溫度以收斂到目標分佈 [16, 17].
        *   **單鏈回火 (Simulated Annealing)** 是在時間上逐漸改變單條鏈的溫度 [6, 7, 16, 17].
        *   **並行回火 (Parallel Tempering):** 運行多條在不同溫度下的馬爾可夫鏈 [6, 7, 16-18]，並允許這些鏈之間**交換狀態** [16-18]. 高溫鏈更容易探索狀態空間和跳躍到不同峰值區域 [17, 18]，通過與低溫鏈交換狀態，將這種探索結果傳遞給低溫鏈 [17, 18]，幫助低溫鏈克服能量勢壘，改善整體混合性 [17, 18]. 並行處理多條鏈也可以幫助獲取更多無關樣本 [13].

## 5. Gibbs 採樣

*   Gibbs 採樣是一種**特殊的 MCMC 算法** [6, 7, 17].
*   它適用於**當目標分佈的全條件分佈 (full conditional distributions) 易於採樣的情況** [6, 7, 17]. 全條件分佈是一個變數在給定其他所有變數當前值下的條件機率分佈 [6].
*   工作原理：對於多個變數構成的分佈，Gibbs 採樣通過**輪流對每個變數進行採樣** [6, 17]，每次都從該變數在給定所有其他變數當前值的情況下的全條件分佈中進行採樣 [6, 17]. 這個過程生成一個狀態序列，其平穩分佈是目標聯合分佈 [6].
*   Gibbs 採樣的優點包括**實現相對簡單**（如果全條件分佈已知且易於採樣） [2, 6, 17]，**無需調整提議分佈** [2, 17]，且接受率（在 Metropolis-Hastings 框架下）總是 1 [2, 17].
*   它特別適用於各變數全條件分佈易於採樣的場景，常見於圖模型和能量模型中 [17]. 在處理潛變數模型（如 RBM）時，如果後驗分佈尖銳或多峰，Gibbs 採樣可能混合緩慢 [16].

## 6. 深度學習圖像處理項目案例

*   一個基於深度學習技術的**平面角色處理和識別項目正在進行中** [7].
*   項目成員來自台灣科技大學和清華大學 [7].
*   項目面臨的主要挑戰是**動漫角色圖像數據集稀缺** [7, 19].
*   為此，建立了**一個網站來號召志願者協助標註數據**，特別是**框選角色臉部** [7, 20, 21]. 志願者需框選**整個頭部包含臉部** [21]，只框人臉，不框動物或其他不似人臉的 [21].
*   已進行的研究與嘗試包括:
    *   測試現有預訓練模型在動漫圖像上的應用，發現直接應用效果不佳，需要針對性調整 [7]. 這歸因於**真實世界圖像和動漫圖像的本質差異**（如色彩鮮豔度、物體形態等），基於自然圖像訓練的模型不適用於動漫 [19].
    *   進行圖像分割實驗，成功切出角色臉部，但也發現**雜訊問題，懷疑是數據標註不精確**所致 [7].
    *   研究圖像超解析度技術，嘗試使用生成模型 (如 GAN) 提升動漫圖像解析度 [7, 22]. 實作中採用**分塊並行放大**的方式進行超解析度處理 [23]，對小圖塊訓練，使用平方誤差作為目標 [23]. 初步結果顏色有偏差 [24]，可能與色彩空間選擇有關 [24].
    *   探索在不同顏色空間（如 RGB, Lab, Lch, HSV）中分析圖像數據，發現 **Lab 空間的色彩分佈相對標準，可能更適合用於預測和處理顏色** [7, 24].
    *   研究並嘗試改進數據預處理方法和模型架構，例如利用不同大小的卷積核 (1x1, 3x3, 5x5) 進行特徵提取和圖像重組 [7, 22].
    *   測試了新型激活函數 (如 GELU) 與傳統 ReLU 的差異，發現在特定情況下 ReLU 會導致神經元「死亡」 [7, 22]. 項目使用了 GELU [22].
    *   探索使用**單次學習 (single-shot learning) 模型**來處理稀缺數據集的角色識別問題 [7, 20].
    *   進行語義分析研究，旨在通過角色的服裝等非臉部特徵來輔助角色識別 [7].
*   數據收集網站功能包括輸入名稱、查看排行榜（顯示標註數量）、框選操作、縮放、提交等 [20]. 網站正在累積數據集 [21]. 數據品質控制是一個重要課題 [25]，目前依賴人工快速審核 [25].

