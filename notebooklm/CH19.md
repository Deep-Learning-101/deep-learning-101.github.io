---
layout: default
title: Deep Learning 101, Taiwan’s pioneering and highest deep learning meetup, launched on 2016/11/11 @ 83F, Taipei 101
---

<p align="center">
  <strong>Deep Learning 101, Taiwan’s pioneering and highest deep learning meetup, launched on 2016/11/11 @ 83F, Taipei 101</strong>  
</p>
<p align="center">
  AI是一條孤獨且充滿惶恐及未知的旅程，花俏絢麗的收費課程或活動絕非通往成功的捷徑。<br>
  衷心感謝當時來自不同單位的AI同好參與者實名分享的寶貴經驗；如欲移除資訊還請告知。<br>
  由 <a href="https://www.twman.org/" target="_blank">TonTon Huang Ph.D.</a> 發起，及其當時任職公司(台灣雪豹科技)無償贊助場地及茶水點心。<br>
</p>  
<p align="center">
  <a href="https://huggingface.co/spaces/DeepLearning101/Deep-Learning-101-FAQ" target="_blank">
    <img src="https://github.com/Deep-Learning-101/.github/blob/main/images/DeepLearning101.JPG?raw=true" alt="Deep Learning 101" width="180"></a>
    <a href="https://www.buymeacoffee.com/DeepLearning101" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-red.png" alt="Buy Me A Coffee" style="height: 100px !important;width: 180px !important;" ></a>
</p>
<p align="center">
  <a href="https://www.youtube.com/@DeepLearning101" target="_blank">YouTube</a> |
  <a href="https://www.facebook.com/groups/525579498272187/" target="_blank">Facebook</a> |
  <a href="https://deep-learning-101.github.io/"> 回 GitHub Pages</a> |
  <a href="http://DeepLearning101.TWMAN.ORG" target="_blank">網站</a> |
  <a href="https://huggingface.co/DeepLearning101" target="_blank">Hugging Face Space</a>
</p>

# 第十九章 近似推斷

<a href="https://www.youtube.com/watch?v=YeCDY_wsojA" target="_blank" rel="noopener noreferrer"><i class="fab fa-youtube mr-1"></i>2018/03/16, Approximate Inference @ Deep Learning Book Chapter 19</a><br>

## 1. 最大後驗 (MAP) 推斷

*   **定義:** MAP 推斷是計算潛變數 `h` 在給定可見變數 `v` 時的**最可能值** (眾數) `h*` [5, 7, 9, 12]。
*   **與完整後驗分佈的差異:** 它只提供一個點估計，而不是像計算完整的後驗分佈 `p(h|v)` 那樣提供潛變數所有可能值的**完整機率分佈** [7, 9, 12]。
*   **視為近似推斷:** 如果將 MAP 推斷的結果 `h*` 用來定義一個近似後驗分佈 `q`，則這個 `q` 是一個**集中在 `h*` 點的狄拉克 (Dirac) δ 函數**，表示為 `q(h|v) = δ(h-h*)` [5, 7, 9, 12]。
*   **與 ELBO 的關係:** 從最大化證據下界 (ELBO) `L(v, θ, q)` 的角度看，將 `q` 限定為狄拉克分佈 `q(h|v) = δ(h-μ)` 時，最大化 ELBO 等價於解決 `μ* = argmax_μ log p(h=μ, v;θ)` [5]。這與 MAP 推斷問題 `h* = argmax_h p(h|v)` 本質相同 [5]。
*   **局限性 (從變分下界角度):** 狄拉克分佈的熵趨近於負無窮，這會導致 ELBO 的下界**無限鬆散** [7, 12]，因此 MAP 推斷通常不被認為是一個好的變分近似方法 [7, 12]。
*   **在稀疏編碼中的應用:** MAP 推斷在深度學習中被廣泛應用於**稀疏編碼模型** [5]。這是因為在稀疏編碼中，當 `v` 被觀察時，潛變數之間由於**「相消解釋」效應**會形成大的團，使得精確計算後驗 `p(h|v)` 非常困難，特別是當潛變數先驗不是高斯分佈時 (例如常用的 **Laplace 稀疏先驗**) [5, 7, 9, 12, 13]。計算成本較低的 MAP 推斷成為實用替代方案 [7, 9, 12, 13]。
*   **稀疏編碼的學習目標:** 使用 MAP 推斷學習稀疏編碼模型參數時，目標函數通常是**最小化**一個包含潛變數稀疏性懲罰項 (如 L1 範數 `Σ λ|H_{i,j}|`) 和重構誤差項 (如平方誤差 `Σ (V - HW^T)_{i,j}^2`) 的組合函數 [5, 14]。這可以通過**交替優化**潛變數 `H` 和模型參數 `W` 來解決 [5]。

## 2. 變分推斷 (Variational Inference)

*   **核心思想:** 在一個**預先定義的、受約束的分佈族** Q 中，尋找一個近似後驗分佈 `q ∈ Q`，使得**證據下界 (ELBO) L(v, θ, q) 被最大化** [9, 14-17]。選擇分佈族時需考慮計算 `E_q[log p(h,v)]` 的難易度 [14, 17]。
*   **與 KL 散度的關係:** 最大化 ELBO 等價於最小化近似後驗 `q` 與真實後驗 `p(h|v)` 之間的 **KL 散度 `D_KL(q||p)`** [16, 18]。最小化 `D_KL(q||p)` 傾向於找到一個 `q`，使得在真實後驗 `p` 機率低的地方，`q` 的機率也低 [14, 16, 18]。

## 3. 均值場 (Mean-field) 方法

*   **概念:** 一種常用的變分學習方法，假設近似後驗 `q` 可以**分解為各個潛變數邊緣分佈的乘積**，即 `q(h|v) = Π_i q(h_i|v)` [9, 13, 14, 17, 19]。這也被稱為均值場近似 [14]。
*   **帶來的簡化:** 均值場近似使得原本複雜的聯合後驗期望計算**可以分解為對各個獨立的 `q(h_i|v)` 的期望計算** [9, 17, 19]。這使得 ELBO 更容易處理和優化 [19]。
*   **參數優化:** 在均值場近似下，近似後驗 `q` 的參數 (例如離散潛變數的機率參數) 通常可以通過求解**不動點方程**來優化 [9, 13, 17, 19]。對 ELBO 關於每個參數求偏導並令其等於零，然後反覆迭代更新直到收斂 [17, 19]。這可以視為一種**坐標上升法** [17]。
*   **結構化變分推斷:** 可以通過選擇 `q` 的圖模型結構來更靈活地決定近似程度 [14]。
*   **連續型潛變數:** 對於連續型潛變數，均值場近似下的**最優單個因子 `q(h_i|v)` 的通用更新規則**是未歸一化的 `~q(h_i|v) = exp(E_{h_{-i}~Π_{j≠i}q(h_j|v)}[log p(v,h)])` [13, 20]。計算此期望可以**揭示最優解的泛函形式** (例如，證明其為高斯分佈)，而不僅僅提供迭代方法 [13, 20]。

## 4. 學成近似推斷 (Amortized Inference)

*   **概念與目的:** 學成近似推斷是訓練一個**額外的參數化函數** (通常是神經網路)，稱為**推斷網路**或識別模型，它的作用是**直接從輸入 `v` 預測潛變數的近似後驗分佈 `q(h|v)` 的參數** [6, 8, 9, 15]。這樣做的主要目的是**避免在每次需要推斷時都執行耗時的迭代優化過程** (如迭代均值場) 來尋找最優的 `q` [8, 9]。
*   **主要優勢:** 一旦推斷網路訓練完成，對於新的輸入 `v`，只需**一次前向傳播**就能快速得到潛變數的近似後驗分佈 [6, 8, 9, 15]。
*   **應用示例:**
    *   **變分自編碼器 (VAE):** VAE 是學成近似推斷的核心應用模型 [6, 8, 9, 15]。其中的編碼器 (推斷網路) 直接參數化近似後驗分佈 `q(z|x)`，並用來計算 ELBO [6, 8, 9]。訓練 VAE 是**聯合優化**編碼器和解碼器參數以最大化 ELBO [6, 8, 9]。
    *   **深度玻爾茲曼機 (DBM):** 可以使用學成的推斷網路進行單遍推斷以加速，其訓練過程是運行推斷網路後，再運行一步均值場改進估計，並訓練推斷網路輸出這個改進後的估計 [6]。
    *   **預測性稀疏分解 (PSD) / ISTA:** 可視為自編碼器和稀疏編碼的混合，編碼器被視為執行學成近似 MAP 推斷的網路 [6]。

## 5. 期望最大化 (EM) 演算法 (相關背景)

*   **目標:** 最大化模型參數 `θ` 下數據的**對數概似** `log p(v;θ)` [3, 16]。
*   **步驟:**
    *   **E 步 (Expectation Step):** 基於當前模型參數 `θ` 和可見變數 `v`，推斷潛變數 `h` 的**後驗分佈 `q(h|v)`** [9]。
    *   **M 步 (Maximization Step):** **固定** E 步得到的 `q(h|v)`，然後調整模型參數 `θ` 以**最大化證據下界 L(v, θ, q)** (這等價於最大化 `E_q[log p(v,h;θ)]`) [9]。
*   **與變分推斷的聯繫:** EM 演算法**最大化 ELBO** [9, 16, 18]。當潛變數的完整後驗 `p(h|v)` 易於計算時，EM 的 E 步可以精確計算 `p(h|v)`，並設置 `q(h|v) = p(h|v)`，此時 ELBO 等於對數概似，EM 直接最大化對數概似 [16]。當完整後驗難以計算時 (如深度學習中的許多模型)，需要使用**近似推斷**方法 (如變分推斷) 來近似後驗 `p(h|v)`，此時最大化 ELBO 成為目標 [9, 16, 17]。
*   **與坐標上升的關聯:** EM 算法可以被看作是**坐標上升法**的一種應用，通過交替優化 `q` (E 步) 和 `θ` (M 步) 來**單調最大化 ELBO** [9]。
*   **收斂判斷:** EM 算法單調增加 ELBO 或對數概似 [9]。可以通過檢查 ELBO 的變化量或參數的變化量是否小於某個閾值來判斷收斂 [9]。
*   **深度學習中 M 步的差異:** 在深度學習中，EM 的 M 步通常很難獲得參數的**解析解**，需要使用**梯度下降等迭代優化方法**；而傳統機器學習中某些模型的 M 步可能存在解析解 [9]。
*   **醒眠算法 (Wake-Sleep algorithm):** 一種學成近似推斷方法，包含兩個階段。Wake 階段使用推斷網路推斷 `h` 並更新生成模型參數以增加聯合機率 `p(v,h)` [9]。Sleep 階段從生成模型採樣 `(v,h)` 對，並訓練推斷網路去預測這些採樣到的 `h` [9]。其主要缺點是訓練早期生成模型可能與真實數據分佈差異大，導致推斷網路在不真實樣本上訓練，效果不佳 [9, 15]。
