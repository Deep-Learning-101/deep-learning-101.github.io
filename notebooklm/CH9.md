---
layout: default
title: Deep Learning 101, 台灣曾經最高最早發起的深度學習社群 @ 83F, 台北101
---

<p align="center">
  <strong>The top private AI Meetup in Taiwan, launched on 2016/11/11 @ 83F, Taipei 101</strong>
</p>
<p align="center">
  <strong>Deep Learning 101, 台灣曾經最高最早發起的深度學習社群 @ 83F, 台北101</strong><br><br>
  AI是條寂寞且惶恐的道路，花俏的收費課程或活動絕不會是條捷徑<br>
  本頁內容為過往實名分享制的讀書會，感謝來自不同公司參與者的支持；如欲移除資訊還請告知。<br>
  Deep Learning 101 只由 TonTon Huang Ph.D. 及其當時任職公司無償贊助場地及茶水點心，無 Co-organizer<br>
</p>  
<p align="center">
  <a href="https://huggingface.co/spaces/DeepLearning101/Deep-Learning-101-FAQ" target="_blank">
    <img src="https://github.com/Deep-Learning-101/.github/blob/main/images/DeepLearning101.JPG?raw=true" alt="Deep Learning 101" width="400">
  </a>
</p>
<p align="center">
  <a href="https://www.youtube.com/@DeepLearning101">YouTube</a> |
  <a href="https://www.facebook.com/groups/525579498272187/">台灣人工智慧社團 FB</a> |
  <a href="https://www.twman.org/">TonTon Huang Ph.D.</a> |  
  <a href="https://deep-learning-101.github.io/">GitHub Pages</a> |
  <a href="http://DeepLearning101.TWMAN.ORG">台灣人工智慧社團 網站</a> |
  <a href="https://huggingface.co/DeepLearning101">Hugging Face</a>
</p>
<p align="center">
<a href="https://www.buymeacoffee.com/DeepLearning101" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-red.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;" ></a>
</p>

# 深度模型中的優化 - [YouTube](https://www.youtube.com/watch?v=51cO6Kv37p4)

### Convolutional Networks @ Deep Learning Book Chapter 9 (2017/04/14)

**文件日期：** 根據來源內容生成，主要基於 CH8 章節資料。
**文件來源：**
*   Excerpts from "CH8-常見問答"
*   Excerpts from "CH8-時間軸"
*   Excerpts from "CH8-研讀指南"
*   Excerpts from "CH8-簡介"
*   Excerpts from the transcript of the video "No. 05 @ Chapter 8 @ Optimization for Training Deep Models @ Deep Learning 101" uploaded on the YouTube channel "Deep Learning 101"
*   Excerpts from "PDF8.md"

**核心主題：** 深度神經網路模型的優化訓練

**概述：**
深度學習算法在許多情況下涉及優化，其中最困難且代價高昂的是**神經網路的訓練**。其重要性在於模型效能高度依賴於訓練結果的品質。由於神經網路模型參數眾多（數百萬到數十億）且訓練數據集龐大，訓練過程需要龐大的計算資源和時間。為了解決這個重要且代價高昂的優化問題，研究者們開發了一組專門的優化技術。

本章主要關注尋找一組神經網路參數 θ，使得代價函數 J(θ) 顯著降低。這個代價函數通常包含衡量模型在整個訓練集上性能的指標（如經驗風險）以及額外的正則化項。內容涵蓋機器學習優化與純優化的區別、神經網路優化的挑戰、實用算法（包括基本和高級）、參數初始化策略，以及將簡單算法組合成高級過程的優化策略。

## 機器學習優化與純優化的不同 (8.1)

機器學習中的優化與純粹的數學優化在目的和方法上有所區別。

1.  **間接優化：** 純優化旨在直接最小化目標函數 J 本身。機器學習的終極目標是最小化在**未知測試集上的效能度量 P**（稱為**真實風險**）。由於真實風險通常不可直接優化，我們轉而間接地優化一個在訓練集上定義的**代價函數 J(θ)**（通常稱為**經驗風險**），希望透過降低訓練誤差來降低真實風險。

2.  **風險 (Risk) 與經驗風險 (Empirical Risk)：**
    *   **風險**是指模型在**真實的、未知的數據生成分布 p_data** 上的期望損失或泛化誤差。這是我們真正希望最小化的目標。我們通常不能直接最小化風險，因為**不知道真實的數據生成分布 p_data**。
    *   **經驗風險**是指模型在**訓練數據集**上的平均損失。它是用訓練集上的經驗分布 p̂_data 替代真實分布 p_data 對真實風險進行的經驗估計。
    *   **經驗風險最小化 (Empirical Risk Minimization, ERM)** 是一種學習策略，目標是找到使經驗風險最小的參數 θ。
    *   儘管 ERM 最小化訓練誤差，其最終目標更重要的是希望模型在未見過的數據上表現良好，即具有較低的**真實風險（泛化誤差）**。因此，**防止過擬合**（即經驗風險很低但真實風險很高）是 ERM 框架下非常重要的考量。

3.  **目標函數結構：** 機器學習的目標函數通常可以分解為訓練樣本上的總和或平均。這催生了**小批量 (Minibatch)** 等只使用部分資料來估計梯度的方法，這與傳統優化中常用整個資料集計算精確梯度不同.

4.  **代理損失函數 (Surrogate Loss Function)：** 當我們真正關心的損失函數（例如分類問題中的 0-1 損失，即錯誤率）因為其數學性質（如不連續、導數為零）而**難以直接優化**時，我們會轉而優化一個更容易處理的「代理損失函數」。代理損失函數通常被設計為連續可微，且其梯度能為優化提供更好的指引（例如，負對數似然/交叉熵損失常用作 0-1 損失的代理）。

5.  **提前終止 (Early Stopping)：** 這是一種偏離純優化（最小化訓練誤差）的**正則化和停止策略**。它在訓練過程中監控模型在一個獨立的**驗證集**上的效能。當模型在訓練集上的損失仍在下降，但驗證集上的損失開始上升（表明模型開始過擬合）時，便停止訓練。提前終止不是為了最小化訓練誤差，而是為了找到一個在訓練誤差和泛化能力（由驗證集衡量）之間取得較好平衡的參數。這意味著返回的不是訓練損失最小的參數，而是泛化性能較好的參數。

## 批量算法與小批量算法 (8.1.3)

機器學習算法的目標函數通常可以分解為訓練樣本上的求和。優化算法通常僅使用整個代價函數中的一部分來估計梯度。

*   **批量梯度下降 (Batch Gradient Descent, BGD)：** 使用**整個訓練集**來計算每一步的梯度。計算精確，但當訓練集很大時，計算成本**非常高昂**。
*   **隨機梯度下降 (Stochastic Gradient Descent, SGD)：** 每次更新只使用**單個訓練樣本**或**少量樣本**來計算梯度。計算**速度快**但梯度估計**噪聲大**。
*   **小批量隨機梯度下降 (Minibatch Stochastic Gradient Descent, Minibatch SGD)：** 介於兩者之間，每次更新使用訓練數據集的一個**小子集（小批量）**來計算梯度。這是深度學習中**最常用**的方法。它在梯度估計的準確性和計算效率之間取得了較好的平衡。
    *   **小批量大小**會影響：梯度估計的方差（批量越大方差越小）、計算效率（太小無法充分利用並行）、內存消耗、硬體性能偏好。
    *   **重要事實：** 如果數據點獨立同分佈，從小批量計算的梯度期望等於從整個訓練集計算的梯度期望。但由於隨機性，梯度方差較大，可能幫助跳出局部最優，但也可能導致收斂不穩定。
    *   相比 BGD，Minibatch SGD 計算效率高、內存效率高、可能跳出局部最優。缺點是梯度估計有噪聲，收斂可能不穩定。
    *   相比單樣本 SGD，Minibatch SGD 梯度估計方差更小，**更好地利用並行計算能力**（尤其在 GPU 上）。計算量略大，但實際運行時間常因並行而更短。

## 神經網路優化中的挑戰 (8.2)

優化神經網路是一個極其困難的任務，通常是非凸情況。

1.  **非凸性 (Non-convexity)：** 神經網路的損失函數通常是非凸的，存在許多局部極小值、局部極大值和鞍點。傳統機器學習常小心設計目標為凸函數以避免複雜性。

2.  **病態 (Ill-conditioning)：** 指的是損失函數的 Hessian 矩陣條件數**非常大**。這意味著損失函數在某些方向上**非常陡峭**，在另一些方向上**非常平坦**。基於梯度的算法（如梯度下降）在陡峭方向上容易**震盪**需要小學習率，在平坦方向上**進展緩慢**，導致整體收斂速度**極慢**。病態問題在神經網路訓練中普遍存在。動量方法有助於部分緩解 Hessian 病態問題.

3.  **局部極小值 (Local Minima)：** 在非凸函數中，可能存在多個局部極小值。優化算法可能**陷入一個代價較高**（遠離全局最優）的局部極小值而無法逃脫。然而，對於深度神經網路，普遍觀點認為**大多數局部極小值的代價與全局極小值的代價非常接近**。

4.  **模型可辨識性 (Model Identifiability)：** 如果一個模型有多組不同參數能產生完全相同的輸出，則模型不可辨識。這會導致損失函數有**許多等價的局部極小值**（如權重空間對稱性，交換同一層隱藏單元權重）。這些通常代價相同，**不是主要問題**。

5.  **鞍點 (Saddle Points)：** 鞍點是梯度為零但既非局部極小值也非局部極大值的點。其 Hessian 矩陣是不定的，既有正特徵值也有負特徵值。近年來研究表明，在**高維**深度神經網路損失函數中，鞍點比代價高的局部極小值**更普遍且更具挑戰性**。在高維空間中，隨機函數的局部極小值稀少，而鞍點常見。優化算法在鞍點附近**梯度接近零，可能長時間停滯**，構成比局部極小值更大的挑戰. 逃逸鞍點需要沿 Hessian 負特徵值方向移動。

6.  **高原 (Plateaus)：** 指梯度接近零的廣闊平坦區域。它們可以是局部極小值、極大值或鞍點的組合。在高原上，梯度非常小，導致優化算法進展極慢。

## 基本優化算法 (8.3)

### 隨機梯度下降 (Stochastic Gradient Descent, SGD) (8.3.1)

SGD 及其變種是機器學習中應用最多的優化算法，特別是深度學習. 如 8.1.3 節所述，它使用小批量樣本來計算梯度的無偏估計。

*   **學習率 ϵ_k** 的選擇**至關重要**。太小收斂慢，太大可能震盪甚至發散.
*   理論上，SGD 收斂的充分條件是學習率序列滿足：Σ_{k=1}^∞ ϵ_k = ∞ 且 Σ_{k=1}^∞ ϵ_k^2 < ∞ (Robbins-Monro 條件)。
*   實踐中常用學習率**衰減策略**，如線性衰減直到一定迭代次數 τ，然後保持常數。選擇初始和最終學習率很重要。

### 動量 (Momentum) (8.3.2)

動量方法 (Polyak, 1964) 旨在**加速學習**，特別是處理高曲率、小但一致的梯度或帶噪聲的梯度。

*   **核心思想：** 引入一個「速度」向量 v，該向量**積累了過去梯度的指數級衰減移動平均**。參數更新時，**不僅考慮當前梯度方向，也受先前積累的速度方向影響**。
*   **更新規則：**
    v ← αv - ϵ∇_θ L(θ)
    θ ← θ + v
    其中 α ∈ [0,1) 是動量係數，控制之前梯度的衰減速度。v 類比物理速度，αv 模擬阻力。
*   **作用：**
    *   有助於在梯度方向一致的維度上**加速**。
    *   在梯度方向頻繁變化的維度上（如在峽谷壁之間）**抑制震盪**。
    *   部分**緩解 Hessian 病態問題**和**梯度方差問題**.
    *   由於慣性，有時可幫助**衝過較淺的局部極小值或鞍點**.

### Nesterov 動量 (Nesterov Momentum) (8.3.3)

Nesterov 動量 (Nesterov, 1983, 2004) 是動量的一個變種。

*   **核心區別：** 梯度計算的點不同。標準動量在當前位置 θ 計算梯度。Nesterov 動量在「**預測的**」未來位置（基於當前速度前進一步的 θ + αv）計算梯度。
*   這種「**向前看**」的機制可以提供更及時的修正。
*   **更新規則：**
    v ← αv - ϵ∇_θ L(θ + αv)
    θ ← θ + v
*   在凸批量梯度情況下，Nesterov 動量將誤差率從 O(1/k) 改善到 O(1/k^2)。對於 SGD，它沒有改善收斂率的理論保證，但**實踐中通常表現更好**。

*   **算法選擇：** 目前沒有一個公認的「最佳」優化算法。選擇取決於具體問題、用戶對超參數的熟悉程度。不同的數據或模型可能適用不同的優化器。許多實踐觀察缺乏完整的理論根據。實驗和調整通常是必要的。

## 參數初始化策略 (8.4)

參數初始化策略**極為重要**，原因如下：

1.  **打破對稱性 (Symmetry Breaking)：** 如果同一層的所有權重初始化為相同值（例如全零），它們將學習到相同的特徵，喪失網路表達能力。**隨機初始化是必需的**。如果權重都初始化為零，同一層所有單元輸出、梯度、更新都相同。
2.  **影響優化過程：** 好的初始化能讓參數從一個有利於優化、能**更快收斂**且最終效能更好的區域開始；差的初始化可能導致優化困難、收斂緩慢或陷入差的局部極小值/鞍點。
3.  **控制梯度流動：** 不恰當的初始化（權重過大或過小）可能導致前向傳播時激活值過大或過小，進而在反向傳播時引發**梯度爆炸或梯度消失**問題。好的初始化旨在保持激活值和梯度的方差穩定。

*   常用的策略是將權重從一個具有較小方差的**隨機分佈**（如均勻分佈或高斯分佈）中抽取，偏置通常初始化為**零**或小的正值（對於 ReLU）。

*   **Xavier/Glorot 初始化** (Glorot and Bengio, 2010)：一種權重初始化方法，旨在根據層的輸入和輸出單元數量調整權重初始方差，適用於**對稱激活函數**（如 tanh）。目標是前向和反向傳播都保持方差穩定。

*   **He 初始化** (He et al., 2015)：專為 **ReLU** 及其變體設計，考慮 ReLU 對方差的影響。根據輸入單元數量調整方差。目標主要是在前向傳播時保持激活值方差穩定。

*   對於循環網路，初始化循環權重使其接近恆等映射有助於學習長期依賴。

## 自適應學習率算法 (8.5)

自適應學習率算法為**每個參數獨立地調整其學習率**，而不是使用單一全局學習率。它們通常比手動調整全局學習率的 SGD 更容易使用。

1.  **AdaGrad (Adaptive Gradient)** (Duchi et al., 2011)：獨立地適應所有模型參數的學習率。縮放每個參數反比於其**所有梯度歷史平方值總和**的平方根。對於稀疏數據（歷史梯度小）給予較大的更新。**主要缺點是學習率持續單調下降過快**，可能導致學習過早停止。

2.  **RMSProp (Root Mean Square Propagation)** (Hinton, 2012, 未發表)：為了解決 AdaGrad 的問題，RMSProp 使用**梯度平方的指數加權移動平均**來調整學習率，避免了學習率過早過小。

3.  **Adam (Adaptive Moment Estimation)** (Kingma and Ba, 2014)：結合了**動量**（使用梯度的一階矩 m 的移動平均）和**RMSProp**（使用梯度平方的二階矩 v 的移動平均）的思想。使用 m 和 v 的偏差修正後進行參數更新。它通常被認為是一個**非常魯棒且表現良好的預設優化器**，因為它結合了加速收斂和自適應調整學習率的優點，且對超參數**相對不敏感**。

*   **算法選擇：** 沒有單一「最佳」算法。自適應算法通常更容易使用。精心調整的 SGD 帶動量有時也能達到相當或更好的性能，但可能需要更多超參數搜索。Schaul et al. (2014) 的比較研究表明沒有單一算法在所有情況下都顯著優於其他算法。自適應算法通常對初始學習率不那麼敏感。Adam 通常是很好的默認起點。

## 二階近似方法 (8.6)

二階近似方法利用目標函數的**二階導數（Hessian 矩陣）**來指導優化.

*   **牛頓法 (Newton's Method)：** (公式 8.27) 使用 Hessian 矩陣的**逆**來校正梯度方向。更新規則為 θ* = θ_0 - H⁻¹∇_θJ(θ_0)。優點是**收斂快**（對於性質好的函數）。**主要缺點是計算、存儲和求逆 Hessian 成本極高**（對於 k 個參數是 O(k^3) 或 O(k^2)），不適用於大型神經網路。若 Hessian 非正定，可能指向極大值或鞍點。

*   **共軛梯度法 (Conjugate Gradients)：** (公式 8.29) 是一種迭代方法，用於求解線性方程組 Hx=b (等價於最小化二次函數)。它**避免了直接計算或存儲 Hessian 及其逆**，通過構造共軛方向進行線搜索。對於非二次函數，作為迭代線搜索方法，通常比梯度下降快。

*   **BFGS (Broyden-Fletcher-Goldfarb-Shanno) 算法：** 一種**擬牛頓法 (quasi-Newton method)**。它**迭代地近似 Hessian 矩陣的逆**，無需顯式計算 Hessian。

*   **L-BFGS (Limited-memory BFGS)：** **BFGS 的內存受限版本**。它不存儲完整的 Hessian 逆近似，只存儲近期歷史信息隱式表示。這使得 L-BFGS 適用於**參數數量大的問題**，但收斂可能不如 BFGS。

## 優化策略和元算法 (8.7)

### 批標準化 (Batch Normalization, BN) (8.7.1)

批標準化 (Ioffe and Szegedy, 2015) 是在深度神經網路訓練中非常有效的技術。它**不是一個優化算法本身**，而是一種**網絡層的設計**，有助於改善優化過程。

*   **核心思想：** 在網路每一層的仿射變換之後、**非線性激活函數之前**，對該層的輸入（預激活值）進行**標準化處理**，使其具有**零均值和單位方差**。然後再通過**可學習的參數 γ（縮放）和 β（平移）**進行仿射變換，以恢復表示能力.
*   計算：對當前小批量數據在**每個 Feature** 上計算均值和方差，進行標準化。
*   **測試時：** 使用**整個訓練集**（或其移動平均）的均值和方差來進行標準化，而不是測試批次的統計量.
*   **作用：**
    1.  **緩解內部協變量偏移 (Internal Covariate Shift)：** 使每層輸入分布相對穩定，解決前一層參數更新導致後續層輸入分布變化的問題，**加速訓練速度**.
    2.  **加速收斂：** 允許使用**更大**的學習率，減少對參數初始化的敏感性。
    3.  **正則化效果：** 小批量計算均值和方差引入噪聲，具有輕微正則化效果，有時可減少對 Dropout 的依賴。
    4.  **避免梯度飽和：** 將激活值保持在較好範圍，有助於**梯度更好地流動**。

### 坐標下降 (Coordinate Descent) (8.7.2)

坐標下降是一種優化策略，它不是同時更新所有參數，而是一次**只優化一個參數**（或一小組參數，稱為塊坐標下降），同時**保持其他參數固定**。

*   **工作原理：** 迭代地遍歷所有參數（或塊）。對於當前參數（塊），找到使其目標函數最小的值，然後更新。
*   **適用情況：** 對單個參數優化高效，或參數之間存在解耦時。例如某些稀疏編碼問題。
*   **優點：** 實現簡單，對特定問題可能高效。
*   **缺點：** 對參數高度相關問題，收斂**非常緩慢**。不適用所有函數，可能收斂到非駐點（對於非凸非光滑）。

### Polyak 平均 (Polyak Averaging) (8.7.3)

Polyak 平均 (Polyak and Juditsky, 1992) 是一種用於改進 SGD 收斂性的技術，尤其在**凸優化**中。

*   它不是直接使用 SGD 最後一個參數，而是計算 SGD 訓練過程中產生的**參數的平均值**。常用的有簡單平均或**指數移動平均 (EMA)**。
*   **作用：**
    1.  **減少噪聲的影響：** 平滑掉 SGD 軌跡的噪聲，使得平均參數更接近最優解。
    2.  **更好的收斂率（對於凸優化）：** 理論上可以證明對於某些凸問題，平均後的解收斂率優於最後一個迭代點。
    3.  **更穩定的解：** 平均後的參數通常更穩定。
*   在深度學習非凸優化中，Polyak 平均（或 EMA）常用於獲得更穩定平滑的參數估計，並可能在測試集上略好。

### 監督預訓練 (Supervised Pretraining) (8.7.4)

監督預訓練指在訓練最終複雜監督任務之前，**先使用標註數據訓練模型解決一個或多個相關的、通常更簡單的輔助監督任務**。學到的參數用作最終任務訓練的初始值。

*   **與無監督預訓練的區別：** 是否**使用標籤信息**。無監督在無標籤數據上學習表示；監督在帶標籤數據上學習模型。
*   **逐層監督預訓練 (Greedy layer-wise supervised pretraining)：** 逐步訓練深度網路。先訓練第一層解決輔助任務，固定，再在其輸出之上添加並訓練下一層，直到整個網路。最後通常進行**端到端微調**。這種方法貪心地訓練每一層。
*   **遷移學習中的預訓練**（例如 ImageNet 上預訓練）**是監督預訓練**。在 ImageNet（大規模分類任務）上學到通用視覺特徵，這些預訓練權重用於初始化下游任務模型，再在下游任務數據上微調。利用大規模數據學到的通用知識幫助數據量小或任務特定的場景。

### 設計有助於優化的模型 (8.7.5)

改進優化的**最好方法並非總是改進優化算法**。**設計一個更易於優化的模型通常更有效**。

*   這是因為優化算法性能很大程度上取決於損失函數的「景觀」。崎嶇景觀即使先進算法也難找好解。
*   通過改進模型架構，可以**改善損失景觀**（更平滑、接近凸、減少差的局部最優/鞍點），**促進梯度流動**（避免消失/爆炸），**簡化優化問題**。一個易於優化模型架構本身能讓簡單優化算法取得好結果。
*   **線性變換鏈的梯度問題：** 在非常深的線性網路中，梯度容易消失或爆炸。
*   **跳躍連接 (Skip Connections) / 殘差連接 (Residual Connections)** (Srivastava et al., 2015; He et al., 2016 - ResNet)：引入從較淺層到較深層的**直接連接**，允許信息和梯度「跳過」中間層。這使得可以訓練**非常深的網路**，並顯著**緩解梯度消失問題**。更容易學習恆等映射，促進信息流動。ResNet 是重要範例.
*   **批標準化 (Batch Normalization)**：如前所述，也有助於優化。

### 延拓法 (Continuation Method) 和課程學習 (Curriculum Learning) (8.7.6)

**延拓法**是一種通用優化策略，從一個**更容易解決的問題版本**開始，逐漸將問題變形為原始的、更困難的問題，使用前一個較易問題的解作為下一個更難問題的初始值。

**課程學習** (Bengio et al., 2009) 是延拓法在**機器學習中的一個實例**，模仿人類學習，先展示**更容易的樣本或更簡單的任務**，然後逐漸增加難度。

*   **樣本排序：** 按照某種難度度量對訓練樣本排序，循序漸進。
*   **任務簡化：** 先訓練解決簡化任務，再遷移到完整任務。
*   **好處：**
    *   **加速收斂：** 模型更快掌握基本模式。
    *   **改善泛化和最終性能：** 更容易找到泛化能力好的解。
    *   **避免差的局部最優：** 從更容易的景觀開始，有助避開困難問題中易陷入的差局部最優點。

## 詳細時間軸 (基於來源推斷)

這份時間軸主要涵蓋了神經網路優化領域中概念和算法的提出與發展。請注意，來源主要側重於概念解釋和它們之間的關係，具體的年份資訊相對有限，部分時間點是根據概念被討論的順序和已知研究背景推斷。

*   **未知時間點前（理論基礎時期）：**
    *   存在純粹的數學優化理論。
    *   可能已存在批量梯度下降 (Batch Gradient Descent) 和隨機梯度下降 (SGD) 的基本概念。
    *   可能已存在關於非凸優化中局部極小值、鞍點、病態 Hessian 等挑戰的初步認識。
*   **1964年：** Polyak 提出**動量 (Momentum)** 方法。
*   **1983年, 2004年：** Nesterov 提出**Nesterov 動量 (Nesterov Momentum)**。
*   **2010年：** Glorot 和 Bengio 提出 **Xavier/Glorot 初始化**。
*   **2011年：** Duchi 等人提出 **AdaGrad (Adaptive Gradient)**。
*   **2012年：** Hinton（未發表工作）提出 **RMSProp (Root Mean Square Propagation)**。
*   **2014年：** Kingma 和 Ba 提出 **Adam (Adaptive Moment Estimation)**。 Schaul et al. (2014) 對多種優化算法進行比較研究。
*   **2015年：** Ioffe 和 Szegedy 提出**批標準化 (Batch Normalization, BN)**。 Srivastava 等人可能指與引入跳躍連接概念相關工作。 He 等人提出 He 初始化 (專為 ReLU 設計)。
*   **2016年：** He 等人提出**殘差網路 (ResNet)**，推廣了**殘差連接 (Residual Connections)**。
*   **近年來（Ongoing Research）：**
    *   對高維空間中**鞍點**的研究增多。
    *   持續研究各種優化算法的理論行為、收斂性、泛化能力等，許多實踐觀察缺乏完整理論根據。
    *   延拓法和課程學習等元算法的應用探討。
    *   新的優化算法和改進不斷出現.

## 主要人物列表

根據來源提供的資訊：

1.  **Polyak:** 1964年提出了**動量 (Momentum)** 方法。
2.  **Nesterov:** Yurii Nesterov，在凸優化領域有深遠影響。1983年和2004年提出了**Nesterov 動量 (Nesterov Momentum)**。
3.  **Glorot:** Xavier Glorot，與 Bengio 共同在 2010年提出了 **Xavier/Glorot 初始化**方法。
4.  **Bengio:** Yoshua Bengio，深度學習「三巨頭」之一。與 Glorot 共同提出了 Xavier/Glorot 初始化。在深度學習領域有廣泛貢獻。
5.  **Duchi:** John Duchi，與他人共同在 2011年提出了 **AdaGrad (Adaptive Gradient)** 算法。
6.  **Hinton:** Geoffrey Hinton，深度學習「三巨頭」之一，「深度學習教父」。提出了 **RMSProp (Root Mean Square Propagation)** 算法（可能是未發表工作）。
7.  **Kingma:** Diederik P. Kingma，與 Ba 共同在 2014年提出了 **Adam (Adaptive Moment Estimation)** 算法。
8.  **Ba:** Jimmy Ba，與 Kingma 共同在 2014年提出了 **Adam (Adaptive Moment Estimation)** 算法。
9.  **Ioffe:** Sergey Ioffe，與 Szegedy 共同在 2015年提出了**批標準化 (Batch Normalization)** 技術。
10. **Szegedy:** Christian Szegedy，與 Ioffe 共同在 2015年提出了**批標準化 (Batch Normalization)** 技術。
11. **Srivastava:** Rupesh Kumar Srivastava，可能指與 Highway Networks 或類似引入跳躍連接概念相關工作 (2015)。
12. **He:** Kaiming He，在視覺和深度學習領域有貢獻。提出了 He 初始化 (2015)；是 2016年提出**殘差網路 (ResNet)** 的主要貢獻者之一。
13. **Schaul:** Tom Schaul，與他人 (Schaul et al., 2014) 對多種優化算法進行比較研究，結論是沒有單一算法在所有情況下都表現最佳。

## 關鍵討論點與補充

*   來源討論中強調了實踐中選擇優化算法的重要性在於使用者對算法的熟悉程度和調參經驗。不同的數據或模型也可能適用不同的優化器。
*   現階段（指當時）很多關於優化算法的行為**還沒有完整的理論跟根據**，特別是部分自適應學習率算法，因此實際應用常依賴經驗和實驗。
*   批標準化 (BN) 的計算（均值和方差）是針對**每個 Feature** 進行的，而非整個 Input Matrix。在測試時使用訓練集（或其移動平均）的統計量.
*   來源中的討論還涉及了對一些作者（如 Hinton）背景的補充。
*   針對優化算法的比較，有研究表明沒有單一算法在所有情況下都表現最好，自適應算法通常更容易使用，但精心調整的 SGD 帶動量有時也能達到相當性能。Adam 常被視為魯棒的預設選項。
*   實驗不同的優化器通常是推薦的做法，如果計算資源允許的話。
*   在訓練深度模型時，可能需要了解所用函式庫中特定優化器的內部實現細節以便更好地調參。
*   遷移學習中的教師-學生網路也作為一種預訓練概念被提及，其中學生網路除了最終任務，還要預測教師網路的輸出。
*   來源提到在公開分享來自書籍的圖表時需要注意版權問題。

總結來說，深度神經網路的訓練是一個複雜的非凸優化問題，面臨病態、鞍點等挑戰。理解並應用合適的優化算法（如 SGD 變體、自適應方法）、參數初始化策略，以及利用批標準化、殘差連接 等模型設計技巧 對於高效成功訓練模型至關重要。儘管有許多高級算法，但沒有一個萬能最佳選擇，實踐中常需要實驗和調整.